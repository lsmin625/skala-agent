{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프롬프트(시스템 역할 메시지)를 통한 챗봇 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI LLM 준비 \n",
    "* 환경 변수(`.env` 파일)에서 API Key 로딩\n",
    "* 개발 환경에서는 `gpt-4o-mini` 또는 `gpt-3.5-turbo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import gradio as gr\n",
    "\n",
    "# .env 로드 및 API 키 확인\n",
    "load_dotenv()\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프롬프트 - 시스템 역할 메시지 및 사용자 메시지 구성\n",
    "- `system` 역할: LLM에게 '명탐정 코난 전문가' 역할 부여\n",
    "- `human` 역할: 사용자 질문 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 시스템 메시지\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 '명탐정 코난' 전문가입니다. 모든 질문에 친절하고 정확하게 답해주세요.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UI와 LLM 입출력 처리 함수\n",
    "Gradio UI의 입력을 LLM으로 전달하고, LLM의 결과를 UI 출력으로 연동하는 인터페이스 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conan_expert_reply(user_input):\n",
    "    # 사용자 입력(user_input)을 이용해 프롬프트 메시지 구성\n",
    "    prompt_messages = prompt.format_messages(question=user_input)\n",
    "\n",
    "    # LLM으로 프롬프트 메시지 전달하여 응답 수신\n",
    "    ai_message = llm.invoke(prompt_messages)\n",
    "    print(ai_message)\n",
    "\n",
    "    # LLM 전달 메시지 파서\n",
    "    parser = StrOutputParser()\n",
    "    \n",
    "    # UI로 출력할 content 부분만 전달\n",
    "    return parser.invoke(ai_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio 인터페이스 구성\n",
    "\n",
    "패키지 설치 `pip install gradio`\n",
    "\n",
    "Gradio의 Blocks UI 구성 방식을 사용해 명탐정 코난 퀴즈 챗봇 인터페이스를 구성\n",
    "- `with gr.Blocks() as demo `: Gradio의 레이아웃 기반 UI 블록을 시작 - 앱 전체 인스턴스를 `demo`로 선언\n",
    "- `gr.Markdown(...)` : 화면 상단에 표시할 설명 문구 (Markdown 문법 사용)\n",
    "- `gr.Textbox(...)` : 사용자가 입력할 수 있는 텍스트 입력 또는 출력창 (placeholder로 입력 힌트를 표시 가능)\n",
    "- `demo.launch()` : Gradio UI 실행\n",
    "\n",
    "※ 입력 처리 상세 설명\n",
    "- `question.submit(fn=conan_expert_reply, inputs=question, outputs=answer)`\n",
    "    - `question.submit(...)` : 사용자가 텍스트박스에 입력하고 Enter를 누르면 실행\n",
    "    - `conan_expert_reply` : 사용자의 입력을 받아 LLM에 전달하고, LLM의 응답 메시지를 UI로 전달 \n",
    "    - `inputs=question` : 사용자가 입력한 질문 메시지\n",
    "    - `outputs=answer` : 사용자의 질문에 대한 LLM의 응답 메시지\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### 🕵️‍♂️ 명탐정 코난 전문가 (질의 & 응답)\")\n",
    "\n",
    "    # 입/출력 영역 구성\n",
    "    question = gr.Textbox(label=\"질문을 입력하세요\", placeholder=\"코난이 작아진 이유는 뭐죠?\")\n",
    "    answer = gr.Textbox(label=\"코난 전문가의 답변\", lines=5)\n",
    "\n",
    "    # 입력 이벤트 처리\n",
    "    question.submit(fn=conan_expert_reply, inputs=question, outputs=answer)\n",
    "\n",
    "# Gradio 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

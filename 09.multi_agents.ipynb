{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë¬¸ì œì€í–‰ ê¸°ë°˜ í€´ì¦ˆ ì¶œì œ ë° ì±„ì  ì—ì´ì „íŠ¸ (Multi Agents )\n",
    "\n",
    "## ì‹œìŠ¤í…œ ê°œìš”\n",
    "\n",
    "- ë³¸ ì‹œìŠ¤í…œì€ LangGraph ê¸°ë°˜ Agent 3ì¢…ìœ¼ë¡œ êµ¬ì„±ë˜ë©°, ê° AgentëŠ” ì—­í• ë³„ë¡œ ë¶„ë¦¬ë˜ì–´ í˜‘ë ¥í•œë‹¤.\n",
    "- ëª¨ë“  ë°ì´í„°ëŠ” data/ ë””ë ‰í† ë¦¬ í•˜ì— JSON íŒŒì¼ë¡œ ê´€ë¦¬ëœë‹¤.\n",
    "- ì‹œìŠ¤í…œì€ ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ **ì‘ì‹œì(í•™ìƒ)** ì¸ì§€ **êµìˆ˜** ì¸ì§€ ì‹ë³„í•˜ë©°, ì´ì— ë”°ë¼ ë¶„ê¸°ëœ ì²˜ë¦¬ ë¡œì§ì„ ìˆ˜í–‰í•œë‹¤.\n",
    "\n",
    "### íŒŒì¼ ë°ì´í„° êµ¬ì¡°\n",
    "\n",
    "1. `quizzes.json` : ë¬¸ì œì€í–‰ í€´ì¦ˆë¡œ, ì„ ë‹¤í˜•(multiple_choice)ì¸ ê²½ìš° ì„ íƒì§€(choices)ë¥¼ ê°–ê²Œ ëœë‹¤.\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"id\": \"Q001\",\n",
    "    \"type\": \"short_answer\",\n",
    "    \"question\": \"ì½”ë‚œì˜ ë³¸ëª…ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"answer\": \"ì¿ ë„ ì‹ ì´ì¹˜\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"Q002\",\n",
    "    \"type\": \"multiple_choice\",\n",
    "    \"question\": \"ë‹¤ìŒ ì¤‘ ì½”ë‚œì´ ì‚¬ìš©í•˜ëŠ” ìŒì„± ë³€ì¡°ê¸° ë°œëª…ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?\",\n",
    "    \"choices\": [\"ì•„ê°€ì‚¬ íˆë¡œì‹œ ë°•ì‚¬\", \"í•˜ì‹œë°” ë§ˆì‚¬ë£¨\", \"í•˜ì´ë°”ë¼ ì•„ì´\", \"ëª¨ë¦¬ ì½”ê³ ë¡œ\"],\n",
    "    \"answer\": \"ì•„ê°€ì‚¬ íˆë¡œì‹œ ë°•ì‚¬\"\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "2. `applicants.json` : ì‘ì‹œì ì •ë³´\n",
    "\n",
    "```json\n",
    "[\n",
    "\t{\n",
    "\t\t\"class\": \"1ë°˜\",\n",
    "\t\t\"name\": \"í™ê¸¸ë™\",\n",
    "\t\t\"student_id\": \"S25B001\",\n",
    "\t\t\"phone\": \"010-1234-5678\"\n",
    "\t}\n",
    "]\n",
    "```\n",
    "\n",
    "3. `results/{YYYY-MM-DD}/{class}/result.json`: ì‘ì‹œ ê²°ê³¼ ì €ì¥\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"student_id\": \"S25B001\",\n",
    "    \"name\": \"í™ê¸¸ë™\",\n",
    "    \"score\": 8,\n",
    "    \"answers\": [\n",
    "      {\"quiz_id\": \"Q001\", \"user_answer\": \"ì‹ ì´ì¹˜\", \"is_correct\": true},\n",
    "      ...\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "```\n",
    " \n",
    "\n",
    "### ì—ì´ì „íŠ¸ ì •ì˜ ë° ê¸°ëŠ¥\n",
    "\n",
    "1. Applicant Agent : \n",
    "    * ì—­í• : ì‘ì‹œì ì •ë³´ ì²˜ë¦¬ ë° í€´ì¦ˆ ì‹œì‘ ìš”ì²­ ìŠ¹ì¸\n",
    "    * ì…ë ¥: ì‚¬ìš©ì ì…ë ¥ ë¬¸ì¥ (ì˜ˆ: â€œ1ë°˜ ê¹€ì˜í¬ S25B002 010-0000-0000â€)\n",
    "    * ê¸°ëŠ¥:\n",
    "        - LLMì„ í†µí•´ ë¬¸ì¥ì—ì„œ class, name, student_id, phone ì •ë³´ë¥¼ ì¶”ì¶œ\n",
    "        - applicants.jsonê³¼ ëŒ€ì¡°í•˜ì—¬ ì‘ì‹œì ì¡´ì¬ ì—¬ë¶€ ë° ì‘ì‹œ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "        - ì´ë¯¸ ì‘ì‹œí•œ ê²½ìš° results/{ë‚ ì§œ}/{ë°˜}/result.jsonì—ì„œ í•´ë‹¹ í•™ìƒ ID í™•ì¸í•˜ì—¬ ì˜¤ë¥˜ ë©”ì‹œì§€ ì „ì†¡\n",
    "    * ì¶œë ¥: í€´ì¦ˆ Agentë¡œ ì „ë‹¬í•  ì‘ì‹œì ì •ë³´ ê°ì²´ ë°˜í™˜ ë˜ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€\n",
    "\n",
    "2. Quiz Agent : \n",
    "    * ì—­í• : í€´ì¦ˆ ì¶œì œ, ì‘ë‹µ ìˆ˜ì§‘, LLM ì±„ì \n",
    "    * ì…ë ¥: ì¸ì¦ëœ ì‘ì‹œì ì •ë³´\n",
    "    * ê¸°ëŠ¥:\n",
    "        - quizzes.jsonì—ì„œ 10ê°œì˜ ëœë¤ ë¬¸ì œ ì„ íƒ (quiz_id í¬í•¨)\n",
    "        - í€´ì¦ˆ ì‹œì‘ í›„ 10ë¬¸ì œ ìˆœì°¨ ì¶œì œ ë° ì‚¬ìš©ì ì‘ë‹µ ìˆ˜ì§‘\n",
    "        - ì‘ë‹µ ì™„ë£Œ ì‹œ, ë‹¤ìŒ ì •ë³´ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ì±„ì  ìˆ˜í–‰í•˜ê³  ì±„ì  ê²°ê³¼ ì €ì¥: ì ìˆ˜, ì •ì˜¤í‘œ, ì‘ì‹œì ì •ë³´\n",
    "        ```json\n",
    "        {\n",
    "          \"student\": { ... },\n",
    "          \"quiz\": [{ \"id\": \"Q001\", \"question\": \"...\", \"answer\": \"...\", \"user_answer\": \"...\" }, ...]\n",
    "        }\n",
    "\t\t\t\t```\n",
    "    * ì¶œë ¥: results/{YYYY-MM-DD}/{class}/result.jsonì— ëˆ„ì  ì €ì¥\n",
    "\n",
    "3. Report Agent : \n",
    "    * ì—­í• : êµìˆ˜ì˜ ìš”ì²­ì— ë”°ë¼ ë°˜ë³„ ì˜¤ë‹µ ë° ì„±ì  ë¦¬í¬íŠ¸ ì¶œë ¥\n",
    "    * ì…ë ¥: êµìˆ˜ ì…ë ¥ (ì˜ˆ: â€œ2025-07-07 2ë°˜ ë¦¬í¬íŠ¸ ì¶œë ¥â€)\n",
    "    * ê¸°ëŠ¥:\n",
    "\t\t    - ì‘ì‹œì¼ì ë° ë°˜ì— ë”°ë¼ ì €ì¥ëœ ê²°ê³¼ íŒŒì¼ ë¡œë”©\n",
    "        - ë¦¬í¬íŠ¸ ìœ í˜•ì— ë”°ë¼ ë‹¤ìŒ ìˆ˜í–‰: ì˜¤ë‹µ ë¦¬í¬íŠ¸(ë¬¸ì œë³„ ì˜¤ë‹µë¥  ì§‘ê³„ í›„ ë†’ì€ ìˆœì„œë¡œ ì •ë ¬), ì„±ì  ìˆœìœ„ ë¦¬í¬íŠ¸(ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì‘ì‹œì ì •ë ¬)\n",
    "        - LLM ë˜ëŠ” íŒŒì´ì¬ ë‚´ì¥ ë¡œì§ì„ í™œìš©í•˜ì—¬ í‘œ í˜•íƒœ ì¶œë ¥\n",
    "    * ì¶œë ¥: Markdown ë˜ëŠ” Gradio-friendly í‘œ í˜•íƒœì˜ ì‘ë‹µ ë¦¬í¬íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Agent êµ¬í˜„\n",
    "\n",
    "### 1. ì´ˆê¸° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, TypedDict, Literal, Optional\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ ë° í€´ì¦ˆ ê°œìˆ˜ ì„¤ì •\n",
    "QUIZ_FILE = \"data/quizzes.json\"\n",
    "APPLICANTS_FILE = \"data/applicants.json\"\n",
    "RESULTS_DIR = \"results\"\n",
    "QUIZ_COUNT = 3\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ë°ì´í„° ëª¨ë¸ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic ëª¨ë¸ ì •ì˜\n",
    "class UserType(BaseModel):\n",
    "    \"\"\"ì‚¬ìš©ì ìœ í˜• ë¶„ë¥˜ë¥¼ ìœ„í•œ Pydantic ëª¨ë¸\"\"\"\n",
    "    user_type: Literal[\"student\", \"professor\", \"unknown\"] = Field(description=\"ì‚¬ìš©ìì˜ ìœ í˜•. 'student', 'professor', 'unknown' ì¤‘ í•˜ë‚˜\")\n",
    "\n",
    "\n",
    "class ApplicantInfo(BaseModel):\n",
    "    \"\"\"ì‘ì‹œì ì •ë³´ ì¶”ì¶œì„ ìœ„í•œ Pydantic ëª¨ë¸\"\"\"\n",
    "    class_name: str = Field(description=\"ì‘ì‹œìì˜ ë°˜. ì˜ˆ: '1ë°˜'\")\n",
    "    name: str = Field(description=\"ì‘ì‹œìì˜ ì´ë¦„. ì˜ˆ: 'í™ê¸¸ë™'\")\n",
    "    student_id: str = Field(description=\"ì‘ì‹œìì˜ í•™ë²ˆ. ì˜ˆ: 'S25B001'\")\n",
    "    phone: str = Field(description=\"ì‘ì‹œìì˜ ì „í™”ë²ˆí˜¸. ì˜ˆ: '010-1234-5678'\")\n",
    "\n",
    "\n",
    "class ReportRequest(BaseModel):\n",
    "    \"\"\"ë¦¬í¬íŠ¸ ìš”ì²­ ë¶„ì„ì„ ìœ„í•œ Pydantic ëª¨ë¸\"\"\"\n",
    "    date: str = Field(description=\"ì¡°íšŒí•  ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)\")\n",
    "    class_name: str = Field(description=\"ì¡°íšŒí•  ë°˜ ì´ë¦„ (ì˜ˆ: '1ë°˜', '2ë°˜')\")\n",
    "    report_type: Literal[\"ì„±ì \", \"ì˜¤ë‹µ\"] = Field(description=\"ìš”ì²­í•œ ë¦¬í¬íŠ¸ì˜ ì¢…ë¥˜\")\n",
    "\n",
    "\n",
    "class GradingResult(BaseModel):\n",
    "    \"\"\"ê°œë³„ ë¬¸ì œ ì±„ì  ê²°ê³¼\"\"\"\n",
    "    quiz_id: str\n",
    "    question: str\n",
    "    correct_answer: str\n",
    "    user_answer: str\n",
    "    is_correct: bool\n",
    "    explanation: str\n",
    "\n",
    "\n",
    "class FinalReport(BaseModel):\n",
    "    \"\"\"ì „ì²´ í€´ì¦ˆì— ëŒ€í•œ ìµœì¢… ë¦¬í¬íŠ¸\"\"\"\n",
    "    results: List[GradingResult]\n",
    "    total_score: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Graph ìƒíƒœ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraphì˜ ìƒíƒœ(State) ì •ì˜\n",
    "class SystemState(TypedDict):\n",
    "    user_type: Optional[Literal[\"student\", \"professor\", \"unknown\"]]\n",
    "    user_input: str\n",
    "    chat_history: List[tuple]\n",
    "    \n",
    "    # í•™ìƒ ê´€ë ¨ ìƒíƒœ\n",
    "    applicant_info: Optional[ApplicantInfo]\n",
    "    is_applicant_valid: bool\n",
    "    validation_message: str\n",
    "    questions: List[dict]\n",
    "    user_answers: List[str]\n",
    "    quiz_index: int\n",
    "    final_report: Optional[FinalReport]\n",
    "\n",
    "    # êµìˆ˜ ê´€ë ¨ ìƒíƒœ\n",
    "    report_request: Optional[ReportRequest]\n",
    "    report_output: Optional[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ë°ì´í„° ë¡œë”© ë° ì €ì¥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í—¬í¼ í•¨ìˆ˜ (ë°ì´í„° ë¡œë”©/ì €ì¥)\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"JSON íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(data, file_path):\n",
    "    \"\"\"JSON ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def load_quiz():\n",
    "    \"\"\"í€´ì¦ˆ íŒŒì¼ì—ì„œ ëœë¤ ë¬¸ì œë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    all_q = load_json(QUIZ_FILE)\n",
    "    if not all_q: return []\n",
    "    # í€´ì¦ˆ ê°œìˆ˜ê°€ QUIZ_COUNT ë¯¸ë§Œì¼ ê²½ìš° ê°€ëŠ¥í•œ ë§Œí¼ë§Œ ìƒ˜í”Œë§\n",
    "    count = min(len(all_q), QUIZ_COUNT)\n",
    "    return random.sample(all_q, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Agent ë…¸ë“œ í•¨ìˆ˜ ì •ì˜\n",
    "\n",
    "- `route_user_type` : ì‚¬ìš©ì ì…ë ¥ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_user_type(state: SystemState) -> Literal[\"student_flow\", \"professor_flow\", \"unknown_flow\"]:\n",
    "    \"\"\"ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ í•™ìƒ, êµìˆ˜, ë˜ëŠ” ì•Œ ìˆ˜ ì—†ëŠ” ìš”ì²­ìœ¼ë¡œ ë¼ìš°íŒ…\"\"\"\n",
    "    parser = PydanticOutputParser(pydantic_object=UserType)\n",
    "    \n",
    "    # LLMì´ ì—­í• ì„ ë” ì˜ ì´í•´í•˜ë„ë¡ ì˜ˆì‹œ(Few-shot)ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ë¡œ ìˆ˜ì •\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"ë‹¹ì‹ ì€ ì‚¬ìš©ì ìœ í˜•ì„ ë¶„ë¥˜í•˜ëŠ” ë§¤ìš° ì •í™•í•œ ë¼ìš°í„°ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë³´ê³  'student', 'professor', 'unknown' ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "## ë¶„ë¥˜ ê¸°ì¤€:\n",
    "1. 'student': ë°˜, ì´ë¦„, í•™ë²ˆ ë“± ê°œì¸ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ í€´ì¦ˆ ì‘ì‹œë¥¼ ì‹œë„í•˜ëŠ” ê²½ìš°.\n",
    "2. 'professor': ë‚ ì§œ, ë°˜ ì´ë¦„, 'ë¦¬í¬íŠ¸' ë˜ëŠ” 'ì„±ì 'ê³¼ ê°™ì€ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ì—¬ ê²°ê³¼ë¥¼ ì¡°íšŒí•˜ë ¤ëŠ” ê²½ìš°.\n",
    "3. 'unknown': ìœ„ ë‘ ê²½ìš°ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ëª¨ë“  ì• ë§¤í•œ ê²½ìš°.\n",
    "\n",
    "## ì˜ˆì‹œ:\n",
    "- ì…ë ¥: \"1ë°˜ ê¹€ì½”ë‚œ S25B007 010-1111-2222\"\n",
    "  ë¶„ë¥˜: 'student'\n",
    "- ì…ë ¥: \"2025-07-07 2ë°˜ ì„±ì  ìˆœìœ„ ë¦¬í¬íŠ¸ ì¢€ ë³´ì—¬ì¤˜\"\n",
    "  ë¶„ë¥˜: 'professor'\n",
    "- ì…ë ¥: \"ì•ˆë…•í•˜ì„¸ìš”\"\n",
    "  ë¶„ë¥˜: 'unknown'\n",
    "- ì…ë ¥: \"í€´ì¦ˆë¥¼ í’€ê³  ì‹¶ì–´ìš”.\"\n",
    "  ë¶„ë¥˜: 'unknown' (í€´ì¦ˆ ì‘ì‹œë¥¼ ì›í•˜ì§€ë§Œ, ì‹ë³„ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ 'unknown' ì²˜ë¦¬ í›„ ì•ˆë‚´)\n",
    "\"\"\"),\n",
    "        (\"human\", \"ì‚¬ìš©ì ì…ë ¥: {user_input}\\n\\n{format_instructions}\")\n",
    "    ])\n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    try:\n",
    "        result = chain.invoke({\"user_input\": state[\"user_input\"], \"format_instructions\": parser.get_format_instructions()})\n",
    "        user_type = result.user_type\n",
    "    except Exception as e:\n",
    "        print(f\"ë¼ìš°íŒ… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        user_type = \"unknown\"\n",
    "\n",
    "    state[\"user_type\"] = user_type\n",
    "    # state['chat_history'].append(('system', f\"ë¼ìš°íŒ… ê²°ê³¼: {user_type}\")) # ë””ë²„ê¹…ìš© ë¡œê·¸\n",
    "    \n",
    "    if user_type == \"student\":\n",
    "        return \"student_flow\"\n",
    "    elif user_type == \"professor\":\n",
    "        return \"professor_flow\"\n",
    "    else:\n",
    "        return \"unknown_flow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Applicant Agent Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_applicant_info(state: SystemState) -> SystemState:\n",
    "    \"\"\"LLMì„ ì‚¬ìš©í•´ ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì‘ì‹œì ì •ë³´ë¥¼ ì¶”ì¶œ\"\"\"\n",
    "    parser = PydanticOutputParser(pydantic_object=ApplicantInfo)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œê¸°ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì¥ì—ì„œ ë°˜, ì´ë¦„, í•™ë²ˆ, ì „í™”ë²ˆí˜¸ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.\"),\n",
    "        (\"human\", \"ì‚¬ìš©ì ì •ë³´: {user_input}\\n{format_instructions}\")\n",
    "    ])\n",
    "    chain = prompt | llm | parser\n",
    "    try:\n",
    "        info = chain.invoke({\"user_input\": state[\"user_input\"], \"format_instructions\": parser.get_format_instructions()})\n",
    "        state[\"applicant_info\"] = info\n",
    "    except Exception as e:\n",
    "        state[\"validation_message\"] = f\"ì •ë³´ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì…ë ¥ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”. (ì˜¤ë¥˜: {e})\"\n",
    "        state[\"applicant_info\"] = None\n",
    "    return state\n",
    "\n",
    "def validate_applicant(state: SystemState) -> SystemState:\n",
    "    \"\"\"ì¶”ì¶œëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì‹œì ìê²© ê²€ì¦\"\"\"\n",
    "    if not state[\"applicant_info\"]:\n",
    "        state[\"is_applicant_valid\"] = False\n",
    "        return state\n",
    "\n",
    "    info = state[\"applicant_info\"]\n",
    "    applicants = load_json(APPLICANTS_FILE)\n",
    "    if not applicants:\n",
    "        state[\"is_applicant_valid\"] = False\n",
    "        state[\"validation_message\"] = \"ì˜¤ë¥˜: ì‘ì‹œì ëª…ë‹¨ íŒŒì¼(applicants.json)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        return state\n",
    "\n",
    "    is_registered = any(\n",
    "        str(app[\"student_id\"]) == str(info.student_id) and \\\n",
    "        app[\"name\"] == info.name and \\\n",
    "        str(app[\"class\"]) == str(info.class_name)\n",
    "        for app in applicants\n",
    "    )\n",
    "\n",
    "    if not is_registered:\n",
    "        state[\"is_applicant_valid\"] = False\n",
    "        state[\"validation_message\"] = \"ë“±ë¡ë˜ì§€ ì•Šì€ ì‘ì‹œìì…ë‹ˆë‹¤. ë°˜, ì´ë¦„, í•™ë²ˆì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.\"\n",
    "        return state\n",
    "    \n",
    "    today = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "    result_path = os.path.join(RESULTS_DIR, today, str(info.class_name), \"result.json\")\n",
    "    \n",
    "    results_today = load_json(result_path)\n",
    "    if results_today and any(str(res[\"student_id\"]) == str(info.student_id) for res in results_today):\n",
    "        state[\"is_applicant_valid\"] = False\n",
    "        state[\"validation_message\"] = f\"{info.name}ë‹˜ì€ ì˜¤ëŠ˜ ì´ë¯¸ í€´ì¦ˆì— ì‘ì‹œí•˜ì…¨ìŠµë‹ˆë‹¤. ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\"\n",
    "        return state\n",
    "\n",
    "    state[\"is_applicant_valid\"] = True\n",
    "    state[\"validation_message\"] = f\"ì¸ì¦ë˜ì—ˆìŠµë‹ˆë‹¤. {info.name}ë‹˜, í€´ì¦ˆë¥¼ ì‹œì‘í•©ë‹ˆë‹¤!\"\n",
    "    return state\n",
    "\n",
    "def handle_validation_result(state: SystemState) -> SystemState:\n",
    "    \"\"\"ê²€ì¦ ê²°ê³¼ë¥¼ chat_historyì— ì¶”ê°€\"\"\"\n",
    "    state[\"chat_history\"].append((\"assistant\", state[\"validation_message\"]))\n",
    "    return state\n",
    "\n",
    "def decide_to_start_quiz(state: SystemState) -> str:\n",
    "    \"\"\"ì‘ì‹œì ê²€ì¦ ê²°ê³¼ì— ë”°ë¼ í€´ì¦ˆ ì‹œì‘ ì—¬ë¶€ ê²°ì •\"\"\"\n",
    "    return \"start_quiz\" if state[\"is_applicant_valid\"] else \"end_student_flow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quiz Agent Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_quiz(state: SystemState) -> SystemState:\n",
    "    questions = load_quiz()\n",
    "    if not questions:\n",
    "        state[\"chat_history\"].append((\"assistant\", \"í€´ì¦ˆë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\"))\n",
    "        state[\"questions\"] = []\n",
    "    else:\n",
    "        state[\"questions\"] = questions\n",
    "        state[\"quiz_index\"] = 0\n",
    "        state[\"user_answers\"] = []\n",
    "    return state\n",
    "\n",
    "def ask_question(state: SystemState) -> SystemState:\n",
    "    idx = state[\"quiz_index\"]\n",
    "    q = state[\"questions\"][idx]\n",
    "    text = f\"ë¬¸ì œ {idx + 1}/{len(state['questions'])}: {q['question']}\"\n",
    "    if q[\"type\"] == \"multiple_choice\":\n",
    "        choices = [f\"{i + 1}. {c}\" for i, c in enumerate(q[\"choices\"])]\n",
    "        text += \"\\n\" + \"\\n\".join(choices)\n",
    "    state[\"chat_history\"].append((\"assistant\", text))\n",
    "    state[\"user_input\"] = \"\" # ì´ì „ ì‚¬ìš©ì ì…ë ¥ ì´ˆê¸°í™”\n",
    "    return state\n",
    "\n",
    "def process_and_store_answer(state: SystemState) -> SystemState:\n",
    "    \"\"\"í€´ì¦ˆ ë‹µë³€ ì²˜ë¦¬ ë° ì €ì¥\"\"\"\n",
    "    idx = state[\"quiz_index\"]\n",
    "    q = state[\"questions\"][idx]\n",
    "    user_input = state[\"user_input\"].strip()\n",
    "\n",
    "    processed_answer = user_input\n",
    "    if q[\"type\"] == \"multiple_choice\":\n",
    "        try:\n",
    "            sel = int(user_input) - 1\n",
    "            if 0 <= sel < len(q[\"choices\"]):\n",
    "                processed_answer = q[\"choices\"][sel]\n",
    "        except (ValueError, IndexError):\n",
    "            pass # ìˆ«ìê°€ ì•„ë‹ˆê±°ë‚˜ ë²”ìœ„ ë°–ì´ë©´ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë‹µë³€ìœ¼ë¡œ ê°„ì£¼\n",
    "\n",
    "    state[\"user_answers\"].append(processed_answer)\n",
    "    state[\"quiz_index\"] += 1\n",
    "    return state\n",
    "\n",
    "def should_continue_quiz(state: SystemState) -> str:\n",
    "    \"\"\"í€´ì¦ˆ ê³„ì† ì§„í–‰ ë˜ëŠ” ì±„ì  ì‹œì‘ ê²°ì •\"\"\"\n",
    "    if state.get(\"quiz_index\", 0) < len(state.get(\"questions\", [])):\n",
    "        return \"ask_question\"\n",
    "    else:\n",
    "        return \"grade_quiz\"\n",
    "\n",
    "# grade_and_save_results í•¨ìˆ˜ë¥¼ ì•„ë˜ ë‚´ìš©ìœ¼ë¡œ êµì²´\n",
    "\n",
    "def grade_and_save_results(state: SystemState) -> SystemState:\n",
    "    \"\"\"LLMìœ¼ë¡œ ì±„ì í•˜ê³  ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥\"\"\"\n",
    "    # 1. ì±„ì  í”„ë¡¬í”„íŠ¸ ì¤€ë¹„\n",
    "    grading_input_parts = []\n",
    "    for i, (q, a) in enumerate(zip(state[\"questions\"], state[\"user_answers\"])):\n",
    "        part = (f\"ë¬¸ì œ {i+1}:\\n\"\n",
    "                f\"ID: {q['id']}\\n\"\n",
    "                f\"ì§ˆë¬¸: {q['question']}\\n\"\n",
    "                f\"ì •ë‹µ: {q['answer']}\\n\"\n",
    "                f\"ì‚¬ìš©ì ë‹µë³€: {a}\\n---\")\n",
    "        grading_input_parts.append(part)\n",
    "    grading_input_str = \"\\n\".join(grading_input_parts)\n",
    "\n",
    "    # 2. LLM ì±„ì \n",
    "    parser = PydanticOutputParser(pydantic_object=FinalReport)\n",
    "    system_message = \"ë‹¹ì‹ ì€ 'ëª…íƒì • ì½”ë‚œ' í€´ì¦ˆ ì „ë¬¸ ì±„ì ê´€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì œ, ì •ë‹µ, ì‚¬ìš©ì ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ì±„ì í•˜ê³ , ê° ë¬¸ì œì˜ IDë¥¼ í¬í•¨í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì„¸ìš”. ì •ë‹µ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê³  ì¹œì ˆí•œ í•´ì„¤ì„ ë§ë¶™ì—¬ì£¼ì„¸ìš”. ë§ˆì§€ë§‰ì—ëŠ” 'ì´ì : X/Y' í˜•ì‹ìœ¼ë¡œ ìµœì¢… ì ìˆ˜ë¥¼ ìš”ì•½í•´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_message),\n",
    "        (\"human\", \"{grading_data}\\n\\n{format_instructions}\")\n",
    "    ])\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    try:\n",
    "        report = chain.invoke({\n",
    "            \"grading_data\": grading_input_str,\n",
    "            \"format_instructions\": parser.get_format_instructions(),\n",
    "        })\n",
    "        state[\"final_report\"] = report\n",
    "        \n",
    "        # 3. ê²°ê³¼ ì €ì¥\n",
    "        today = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "        info = state[\"applicant_info\"]\n",
    "        result_path = os.path.join(RESULTS_DIR, today, str(info.class_name), \"result.json\")\n",
    "        \n",
    "        all_results = load_json(result_path) or []\n",
    "        score = sum(1 for res in report.results if res.is_correct)\n",
    "\n",
    "        # ìƒˆ ê²°ê³¼ ë°ì´í„° ìƒì„±\n",
    "        new_result = {\n",
    "            \"student_id\": info.student_id,\n",
    "            \"name\": info.name,\n",
    "            \"score\": score,\n",
    "            \"answers\": [res.model_dump() for res in report.results]\n",
    "        }\n",
    "        all_results.append(new_result)\n",
    "        save_json(all_results, result_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ì±„ì  ë° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        state[\"final_report\"] = FinalReport(results=[], total_score=\"ì±„ì  ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "        state[\"chat_history\"].append((\"assistant\", \"ì±„ì  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ê²°ê³¼ë¥¼ ì €ì¥í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\"))\n",
    "\n",
    "    return state\n",
    "\n",
    "def format_final_report(state: SystemState) -> SystemState:\n",
    "    \"\"\"ìµœì¢… ì±„ì  ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ê¸° ìœ„í•´ í¬ë§·íŒ…\"\"\"\n",
    "    report = state[\"final_report\"]\n",
    "    parts = [\"ì±„ì ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰\\n\"]\n",
    "    if report and report.results:\n",
    "        for i, res in enumerate(report.results):\n",
    "            is_correct_text = \"âœ… ì •ë‹µ\" if res.is_correct else \"âŒ ì˜¤ë‹µ\"\n",
    "            parts.append(f\"--- ë¬¸ì œ {i + 1} ---\\n\"\n",
    "                         f\"ë¬¸ì œ: {res.question}\\n\"\n",
    "                         f\"ì •ë‹µ: {res.correct_answer}\\n\"\n",
    "                         f\"ì œì¶œí•œ ë‹µë³€: {res.user_answer}\\n\"\n",
    "                         f\"ê²°ê³¼: {is_correct_text}\\n\"\n",
    "                         f\"í•´ì„¤: {res.explanation}\\n\")\n",
    "        parts.append(f\"**{report.total_score}**\")\n",
    "    else:\n",
    "        parts.append(\"ì±„ì  ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    parts.append(\"\\n\\nìƒˆë¡œìš´ ì‘ì‹œìëŠ” ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: 1ë°˜ í™ê¸¸ë™ S25B001 010-1234-5678)\")\n",
    "    state[\"chat_history\"].append((\"assistant\", \"\\n\".join(parts)))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Report Agent Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate_report(state: SystemState) -> str:\n",
    "    \"\"\"ë¦¬í¬íŠ¸ ìš”ì²­ì´ ìœ íš¨í•œì§€ í™•ì¸í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.\"\"\"\n",
    "    if state.get(\"report_request\"):\n",
    "        return \"generate_report\"\n",
    "    else:\n",
    "        return \"display_report\"\n",
    "\n",
    "def extract_report_request(state: SystemState) -> SystemState:\n",
    "    \"\"\"LLMì„ ì‚¬ìš©í•´ ë¦¬í¬íŠ¸ ìš”ì²­ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "    parser = PydanticOutputParser(pydantic_object=ReportRequest)\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"ë‹¹ì‹ ì€ êµìˆ˜ë‹˜ì˜ ë¦¬í¬íŠ¸ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” ì •í™•í•œ ë¹„ì„œì…ë‹ˆë‹¤.\n",
    "ìš”ì²­ì—ì„œ ë‚ ì§œ(YYYY-MM-DD), ë°˜ ì´ë¦„, ê·¸ë¦¬ê³  ë¦¬í¬íŠ¸ ì¢…ë¥˜ë¥¼ ì •í™•íˆ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "ë¦¬í¬íŠ¸ ì¢…ë¥˜(report_type)ëŠ” ë°˜ë“œì‹œ \"ì„±ì \" ë˜ëŠ” \"ì˜¤ë‹µ\" ë‘ ê°€ì§€ ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì˜ˆì‹œ:\n",
    "- ì…ë ¥: \"ì˜¤ëŠ˜ 2ë°˜ ì„±ì  ìˆœìœ„ ë¦¬í¬íŠ¸ ì¢€ ë³´ì—¬ì¤˜\" (ì˜¤ëŠ˜ì´ 2025-07-07ì´ë¼ê³  ê°€ì •)\n",
    "  ì¶”ì¶œ: {{\"date\": \"2025-07-07\", \"class_name\": \"2ë°˜\", \"report_type\": \"ì„±ì \"}}\n",
    "- ì…ë ¥: \"2025-07-06 1ë°˜ ì˜¤ë‹µ ë¦¬í¬íŠ¸\"\n",
    "  ì¶”ì¶œ: {{\"date\": \"2025-07-06\", \"class_name\": \"1ë°˜\", \"report_type\": \"ì˜¤ë‹µ\"}}\n",
    "- ì…ë ¥: \"1ë°˜ ì„±ì \"\n",
    "  ì¶”ì¶œ: (ë‚ ì§œ ì •ë³´ê°€ ì—†ì–´ ì‹¤íŒ¨í•´ì•¼ í•¨)\n",
    "\"\"\"),\n",
    "        (\"human\", \"ì˜¤ëŠ˜ ë‚ ì§œ: {today}\\nêµìˆ˜ë‹˜ ìš”ì²­: {user_input}\\n\\n{format_instructions}\")\n",
    "    ])\n",
    "    chain = prompt | llm | parser\n",
    "    try:\n",
    "        today_str = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "        req = chain.invoke({\n",
    "            \"today\": today_str,\n",
    "            \"user_input\": state[\"user_input\"], \n",
    "            \"format_instructions\": parser.get_format_instructions()\n",
    "        })\n",
    "        state[\"report_request\"] = req\n",
    "    except Exception as e:\n",
    "        state[\"report_output\"] = f\"ë¦¬í¬íŠ¸ ìš”ì²­ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. 'YYYY-MM-DD Në°˜ [ì„±ì  ìˆœìœ„/ì˜¤ë‹µ ë¦¬í¬íŠ¸]' í˜•ì‹ìœ¼ë¡œ ìš”ì²­í•´ì£¼ì„¸ìš”. (ì˜¤ë¥˜: {e})\"\n",
    "        state[\"report_request\"] = None\n",
    "    return state\n",
    "\n",
    "# generate_report í•¨ìˆ˜ë¥¼ ì•„ë˜ ë‚´ìš©ìœ¼ë¡œ êµì²´í•©ë‹ˆë‹¤.\n",
    "\n",
    "def generate_report(state: SystemState) -> SystemState:\n",
    "    \"\"\"ìš”ì²­ì— ë”°ë¼ ë¦¬í¬íŠ¸ë¥¼ ìƒì„± (ì˜¤ë‹µ ë¦¬í¬íŠ¸ì— 'ì •ë‹µ' ì»¬ëŸ¼ ì¶”ê°€)\"\"\"\n",
    "    # 1. ì–´ë–¤ ê²½ìš°ì—ë„ KeyErrorê°€ ë°œìƒí•˜ì§€ ì•Šë„ë¡ ê¸°ë³¸ ì˜¤ë¥˜ ë©”ì‹œì§€ë¡œ 'report_output'ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "    state[\"report_output\"] = \"ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    try:\n",
    "        # 2. ë¡œì§ ì‹œì‘: report_request í‚¤ê°€ ìˆëŠ”ì§€ ë‹¤ì‹œ í•œë²ˆ í™•ì¸\n",
    "        if not state.get(\"report_request\"):\n",
    "            state[\"report_output\"] = \"ë¦¬í¬íŠ¸ ìš”ì²­ ì •ë³´ê°€ ì—†ì–´ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\"\n",
    "            return state\n",
    "\n",
    "        req = state[\"report_request\"]\n",
    "        result_path = os.path.join(RESULTS_DIR, req.date, req.class_name, \"result.json\")\n",
    "        data = load_json(result_path)\n",
    "\n",
    "        if not data:\n",
    "            state[\"report_output\"] = f\"{req.date}ì˜ {req.class_name} ì‘ì‹œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "            return state\n",
    "\n",
    "        # 3. ë¦¬í¬íŠ¸ ìœ í˜•ì— ë”°ë¼ ìƒì„±\n",
    "        if req.report_type == \"ì„±ì \":\n",
    "            sorted_data = sorted(data, key=lambda x: x[\"score\"], reverse=True)\n",
    "            report_lines = [f\"### {req.date} {req.class_name} ì„±ì  ìˆœìœ„ ë¦¬í¬íŠ¸\\n\",\n",
    "                            \"| ìˆœìœ„ | í•™ë²ˆ | ì´ë¦„ | ì ìˆ˜ |\",\n",
    "                            \"|:---:|:---:|:---:|:---:|\"]\n",
    "            total_questions = len(sorted_data[0]['answers']) if sorted_data else 0\n",
    "            for i, student in enumerate(sorted_data):\n",
    "                report_lines.append(f\"| {i+1} | {student['student_id']} | {student['name']} | {student['score']}/{total_questions} |\")\n",
    "            state[\"report_output\"] = \"\\n\".join(report_lines)\n",
    "\n",
    "        elif req.report_type == \"ì˜¤ë‹µ\":\n",
    "            quiz_errors = {}\n",
    "            total_students = len(data)\n",
    "            for student in data:\n",
    "                for answer in student[\"answers\"]:\n",
    "                    if not answer[\"is_correct\"]:\n",
    "                        qid = answer[\"quiz_id\"]\n",
    "                        if qid not in quiz_errors:\n",
    "                            # [ìˆ˜ì • 1] 'correct_answer'ë„ í•¨ê»˜ ì €ì¥\n",
    "                            quiz_errors[qid] = {\n",
    "                                \"question\": answer[\"question\"],\n",
    "                                \"correct_answer\": answer[\"correct_answer\"], \n",
    "                                \"count\": 0\n",
    "                            }\n",
    "                        quiz_errors[qid][\"count\"] += 1\n",
    "            \n",
    "            sorted_errors = sorted(quiz_errors.items(), key=lambda item: item[1][\"count\"], reverse=True)\n",
    "            \n",
    "            report_lines = [f\"### {req.date} {req.class_name} ì˜¤ë‹µë¥  TOP 3 ë¦¬í¬íŠ¸ (ì´ {total_students}ëª… ì‘ì‹œ)\\n\",\n",
    "                            \"| ìˆœìœ„ | ë¬¸ì œ | ì •ë‹µ | ì˜¤ë‹µì ìˆ˜ | ì˜¤ë‹µë¥  |\",\n",
    "                            \"|:---:|:---|:---|:---:|:---:|\"]\n",
    "            \n",
    "            if not sorted_errors:\n",
    "                report_lines.append(\"| - | ì˜¤ë‹µì´ ê¸°ë¡ëœ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤. | - | - | - |\")\n",
    "            else:\n",
    "                for i, (qid, details) in enumerate(sorted_errors[:3]):\n",
    "                    error_rate = (details['count'] / total_students) * 100\n",
    "                    report_lines.append(f\"| {i+1} | {details['question']} | {details['correct_answer']} | {details['count']}ëª… | {error_rate:.1f}% |\")\n",
    "            \n",
    "            state[\"report_output\"] = \"\\n\".join(report_lines)\n",
    "\n",
    "        else:\n",
    "            state[\"report_output\"] = f\"ì•Œ ìˆ˜ ì—†ëŠ” ë¦¬í¬íŠ¸ ìœ í˜•ì…ë‹ˆë‹¤: '{req.report_type}'. ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}\")\n",
    "        state[\"report_output\"] = f\"ë¦¬í¬íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ì˜¤ë¥˜: {e})\"\n",
    "\n",
    "    return state\n",
    "\n",
    "def display_report(state: SystemState) -> SystemState:\n",
    "    \"\"\"ìƒì„±ëœ ë¦¬í¬íŠ¸ë¥¼ chat_historyì— ì¶”ê°€\"\"\"\n",
    "    state[\"chat_history\"].append((\"assistant\", state[\"report_output\"]))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- handle_unknown_request nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_unknown_request(state: SystemState) -> SystemState:\n",
    "    \"\"\"ì•Œ ìˆ˜ ì—†ëŠ” ìš”ì²­ ì²˜ë¦¬\"\"\"\n",
    "    message = \"ìš”ì²­ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\\n\" \\\n",
    "              \"í€´ì¦ˆì— ì‘ì‹œí•˜ì‹œë ¤ë©´ '1ë°˜ í™ê¸¸ë™ S25B001 010-1234-5678'ê³¼ ê°™ì´ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\\n\" \\\n",
    "              \"ë¦¬í¬íŠ¸ê°€ í•„ìš”í•˜ì‹œë©´ '2025-07-07 1ë°˜ ì„±ì  ìˆœìœ„ ë¦¬í¬íŠ¸'ì™€ ê°™ì´ ìš”ì²­í•´ì£¼ì„¸ìš”.\"\n",
    "    state[\"chat_history\"].append((\"assistant\", message))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(SystemState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"extract_applicant_info\", extract_applicant_info)\n",
    "workflow.add_node(\"validate_applicant\", validate_applicant)\n",
    "workflow.add_node(\"handle_validation_result\", handle_validation_result)\n",
    "workflow.add_node(\"start_quiz\", start_quiz)\n",
    "workflow.add_node(\"ask_question\", ask_question)\n",
    "workflow.add_node(\"process_answer\", process_and_store_answer)\n",
    "workflow.add_node(\"grade_and_save\", grade_and_save_results)\n",
    "workflow.add_node(\"format_final_report\", format_final_report)\n",
    "workflow.add_node(\"extract_report_request\", extract_report_request)\n",
    "workflow.add_node(\"generate_report\", generate_report)\n",
    "workflow.add_node(\"display_report\", display_report)\n",
    "workflow.add_node(\"handle_unknown_request\", handle_unknown_request)\n",
    "\n",
    "# ì§„ì…ì  ì„¤ì • (ì‚¬ìš©ì ìœ í˜•ì— ë”°ë¼ ë¶„ê¸°)\n",
    "workflow.set_conditional_entry_point(\n",
    "    route_user_type,\n",
    "    {\n",
    "        \"student_flow\": \"extract_applicant_info\",\n",
    "        \"professor_flow\": \"extract_report_request\",\n",
    "        \"unknown_flow\": \"handle_unknown_request\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# í•™ìƒ(Student) ì›Œí¬í”Œë¡œìš° ì—£ì§€ ì—°ê²°\n",
    "workflow.add_edge(\"extract_applicant_info\", \"validate_applicant\")\n",
    "workflow.add_edge(\"validate_applicant\", \"handle_validation_result\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"handle_validation_result\",\n",
    "    decide_to_start_quiz,\n",
    "    {\"start_quiz\": \"start_quiz\", \"end_student_flow\": END}\n",
    ")\n",
    "workflow.add_edge(\"start_quiz\", \"ask_question\")\n",
    "# í€´ì¦ˆ ë£¨í”„: ë‹µë³€ì„ ë°›ìœ¼ë©´ ë‹¤ìŒ ë¬¸ì œë¡œ ê°€ê±°ë‚˜ ì±„ì ìœ¼ë¡œ ë„˜ì–´ê°\n",
    "workflow.add_node(\"router_after_answer\", lambda state: state) # Dummy node\n",
    "workflow.add_edge(\"process_answer\", \"router_after_answer\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"router_after_answer\",\n",
    "    should_continue_quiz,\n",
    "    {\"ask_question\": \"ask_question\", \"grade_quiz\": \"grade_and_save\"}\n",
    ")\n",
    "workflow.add_edge(\"ask_question\", END) # í€´ì¦ˆ ì§ˆë¬¸ í›„ ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë‹¤ë¦¼\n",
    "workflow.add_edge(\"grade_and_save\", \"format_final_report\")\n",
    "workflow.add_edge(\"format_final_report\", END)\n",
    "\n",
    "# Professor(êµìˆ˜) ì›Œí¬í”Œë¡œìš° ì—£ì§€ ì—°ê²°\n",
    "workflow.add_conditional_edges(\n",
    "    \"extract_report_request\",  # ì‹œì‘ ë…¸ë“œ\n",
    "    decide_to_generate_report, # íŒë‹¨ í•¨ìˆ˜\n",
    "    {\n",
    "        \"generate_report\": \"generate_report\", # íŒë‹¨ ê²°ê³¼ê°€ \"generate_report\"ì´ë©´ generate_report ë…¸ë“œë¡œ ì´ë™\n",
    "        \"display_report\": \"display_report\",   # íŒë‹¨ ê²°ê³¼ê°€ \"display_report\"ì´ë©´ display_report ë…¸ë“œë¡œ ì´ë™\n",
    "    }\n",
    ")\n",
    "# ì´ì œ generate_reportëŠ” í•­ìƒ ìœ íš¨í•œ ìš”ì²­ì„ ë°›ì„ ë•Œë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤.\n",
    "workflow.add_edge(\"generate_report\", \"display_report\")\n",
    "workflow.add_edge(\"display_report\", END)\n",
    "\n",
    "# ì•Œ ìˆ˜ ì—†ëŠ” ìš”ì²­ ì²˜ë¦¬\n",
    "workflow.add_edge(\"handle_unknown_request\", END)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "multi_agent_app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê·¸ë˜í”„ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(multi_agent_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì´ˆê¸° ìƒíƒœ ì„¤ì • ë° UI ì¸í„°í˜ì´ìŠ¤ ë¡œì§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_state():\n",
    "    \"\"\"ì´ˆê¸° ìƒíƒœë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    return {\"system_state\": {\n",
    "        \"chat_history\": [],\n",
    "        \"user_input\": \"\",\n",
    "        \"user_type\": None\n",
    "    }}\n",
    "\n",
    "def chat_fn(user_input, state):\n",
    "    \"\"\"Gradio ìƒí˜¸ì‘ìš©ì„ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜\"\"\"\n",
    "    system_state = state[\"system_state\"]\n",
    "\n",
    "    # 1. UI ìƒíƒœ(ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸)ì— ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€\n",
    "    # stateì— ì €ì¥ëœ chat_historyëŠ” í•­ìƒ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ë¼ê³  ê°€ì •\n",
    "    chat_history_dicts = system_state.get(\"chat_history\", [])\n",
    "    if not isinstance(chat_history_dicts, list): # í˜¹ì‹œ ëª¨ë¥¼ ë¹„ì •ìƒ ìƒíƒœ ëŒ€ë¹„\n",
    "        chat_history_dicts = []\n",
    "    chat_history_dicts.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # 2. ë‚´ë¶€ ë¡œì§ìš© ìƒíƒœ(íŠœí”Œ ë¦¬ìŠ¤íŠ¸) ìƒì„±\n",
    "    # ë‚´ë¶€ ë¡œì§(LangGraph)ì€ íŠœí”Œ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì˜ ê¸°ë¡ì„ ì‚¬ìš©\n",
    "    internal_history_tuples = [(item['role'], item.get('content', '')) for item in chat_history_dicts]\n",
    "    \n",
    "    # ë‚´ë¶€ ë¡œì§ì— ì „ë‹¬í•  ìƒíƒœ ê°ì²´ ìƒì„±\n",
    "    internal_state = {\n",
    "        **system_state,\n",
    "        \"chat_history\": internal_history_tuples,\n",
    "        \"user_input\": user_input,\n",
    "    }\n",
    "\n",
    "    # 3. í€´ì¦ˆ ì§„í–‰ ì—¬ë¶€ì— ë”°ë¼ ë¶„ê¸°\n",
    "    is_in_quiz = internal_state.get(\"questions\") and not internal_state.get(\"final_report\")\n",
    "    if is_in_quiz:\n",
    "        quiz_state = process_and_store_answer(internal_state)\n",
    "        next_step = should_continue_quiz(quiz_state)\n",
    "        if next_step == \"ask_question\":\n",
    "            final_internal_state = ask_question(quiz_state)\n",
    "        else: # \"grade_quiz\"\n",
    "            graded_state = grade_and_save_results(quiz_state)\n",
    "            final_internal_state = format_final_report(graded_state)\n",
    "    else: # ìƒˆë¡œìš´ ìš”ì²­ (ë¼ìš°íŒ…ë¶€í„° ì‹œì‘)\n",
    "        # ì´ì „ ìƒíƒœ ì´ˆê¸°í™” (ì±„íŒ… ê¸°ë¡ì€ ìœ ì§€)\n",
    "        current_history = internal_state[\"chat_history\"]\n",
    "        clean_state = init_state()['system_state']\n",
    "        clean_state['chat_history'] = current_history\n",
    "        clean_state['user_input'] = user_input\n",
    "        \n",
    "        final_internal_state = multi_agent_app.invoke(clean_state)\n",
    "\n",
    "    # 4. ìµœì¢… ìƒíƒœë¥¼ UI í˜•ì‹(ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸)ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥ ë° ë°˜í™˜\n",
    "    final_chat_history_tuples = final_internal_state.get(\"chat_history\", [])\n",
    "    \n",
    "    final_chat_display = []\n",
    "    for role, content in final_chat_history_tuples:\n",
    "        if role == \"user\":\n",
    "            final_chat_display.append({\"role\": \"user\", \"content\": content})\n",
    "        elif role == \"assistant\":\n",
    "            final_chat_display.append({\"role\": \"assistant\", \"content\": content})\n",
    "    \n",
    "    # UIì— í‘œì‹œë  ê¸°ë¡ê³¼ ë‹¤ìŒ stateì— ì €ì¥ë  ê¸°ë¡ì„ ëª¨ë‘ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ìœ¼ë¡œ í†µì¼\n",
    "    final_internal_state[\"chat_history\"] = final_chat_display\n",
    "    state[\"system_state\"] = final_internal_state\n",
    "\n",
    "    return final_chat_display, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradio UI êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# ë©€í‹° ì—ì´ì „íŠ¸ í€´ì¦ˆ ì‹œìŠ¤í…œ\")\n",
    "    gr.Markdown(\n",
    "        \" **ì‘ì‹œì(í•™ìƒ)** : `1ë°˜ í™ê¸¸ë™ S25B001 010-1234-5678` í˜•ì‹ìœ¼ë¡œ ì •ë³´ë¥¼ ì…ë ¥í•˜ì—¬ í€´ì¦ˆë¥¼ ì‹œì‘í•˜ì„¸ìš”.\\n\\n \"\n",
    "        \" **êµìˆ˜** : `2025-07-07 1ë°˜ ì„±ì  ìˆœìœ„ ë¦¬í¬íŠ¸` í˜•ì‹ìœ¼ë¡œ ë¦¬í¬íŠ¸ë¥¼ ìš”ì²­í•˜ì„¸ìš”.\"\n",
    "    )\n",
    "\n",
    "    chatbot = gr.Chatbot(\n",
    "        label=\"í€´ì¦ˆ ë° ë¦¬í¬íŠ¸ ì±—ë´‡\",\n",
    "        height=400,\n",
    "        type=\"messages\"\n",
    "    )\n",
    "    \n",
    "    chatbot_display = gr.JSON(visible=False)\n",
    "\n",
    "    txt = gr.Textbox(placeholder=\"ì •ë³´ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ë¦¬í¬íŠ¸ë¥¼ ìš”ì²­í•˜ì„¸ìš”...\", show_label=False)\n",
    "    state = gr.State(init_state())\n",
    "\n",
    "    def update_chatbot_ui(json_data):\n",
    "        return json_data\n",
    "\n",
    "    chatbot_display.change(update_chatbot_ui, chatbot_display, chatbot)\n",
    "\n",
    "    txt.submit(chat_fn, inputs=[txt, state], outputs=[chatbot_display, state])\n",
    "    txt.submit(lambda: \"\", None, txt)\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

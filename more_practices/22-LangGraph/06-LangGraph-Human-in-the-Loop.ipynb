{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY Loading\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(\"CH21-LangGraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human-in-the-Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Dict\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_teddynote.graphs import visualize_graph\n",
    "from langchain_teddynote.tools import GoogleNews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## 1. State ##########\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "\n",
    "\n",
    "########## 2. TOOLS ##########\n",
    "# 도구 초기화\n",
    "news_tool = GoogleNews()\n",
    "\n",
    "# 키워드 뉴스 검색 도구 생성\n",
    "@tool\n",
    "def search_keyword(query: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Look up news by keyword\"\"\"\n",
    "    news_tool = GoogleNews()\n",
    "    return news_tool.search_by_keyword(query, k=5)\n",
    "\n",
    "tools = [search_keyword]\n",
    "\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# LLM + 도구 \n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "########## 3. NODE ##########\n",
    "# 챗봇 함수 정의\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# Graph\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# 도구 노드 생성 및 추가\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Conditional Edge\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "\n",
    "########## 4. EDGE ##########\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "\n",
    "########## 5. MEMORY ##########\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "########## 6. COMPILE  ##########\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "########## 7. VISUALIZE ##########\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 도구 호출 흐름 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import pretty_print_messages\n",
    "from langchain_core.runnables import RunnableConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"AI 관련 최신 뉴스를 알려주세요.\"\n",
    "\n",
    "input = State(messages=[(\"user\", question)])\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=10,  \n",
    "    configurable={\"thread_id\": \"001\"},  \n",
    "    tags=[\"MY-TAG\"], \n",
    ")\n",
    "\n",
    "for event in graph.stream(\n",
    "    input=input,\n",
    "    config=config,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"tools\"],  # tools 실행 전 interrupt(tools 노드 실행 전 중단)\n",
    "):\n",
    "    for key, value in event.items():\n",
    "        print(f\"\\n[{key}]\\n\")\n",
    "\n",
    "        # print(value)\n",
    "        pretty_print_messages(value)\n",
    "\n",
    "        # value 에는 state 가 dict 형태로 저장(values 의 key 값)\n",
    "        if \"messages\" in value:\n",
    "            print(f\"메시지 개수: {len(value['messages'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프게 제대로 작동하고 있는지 확인 \n",
    "# 그래프 상태 스냅샷 생성\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# 다음 스냅샷 상태\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "snapshot.next 통해 다음 도구가 무엇인지 확인했고, 실제로도 그러한지 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import display_message_tree\n",
    "\n",
    "# 메시지 스냅샷에서 마지막 메시지 추출\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "\n",
    "# 메시지 트리 표시\n",
    "display_message_tree(existing_message.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[출력 내용]\n",
    "\n",
    "- 중단된 단계의 type은 \"tool_call\" : 도구 실행\n",
    "    - LLM이 도구 실행 요청 -> tool_call 메시지 생성 \n",
    "    - 하지만 도구 실행 결과(tool_message)는 존재하지 않음 : 도구 실행 결과 없음 \n",
    "- 도구 실행 전 단계에서 그래프 실행 중단 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 스트리밍 \n",
    "# input : `None`는 현재 상태에 아무것도 추가하지 않음. 기존에 저장된 thread_id 상태 기반으로 이어서 실행 \n",
    "# config : 실행 설정 정보 (RunnableConfig)\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "# 이벤트 반복 처리\n",
    "for event in events:\n",
    "    # 메시지가 이벤트에 포함된 경우\n",
    "    if \"messages\" in event:\n",
    "        # 마지막 메시지의 예쁜 출력\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중단 지점에서 상태 저장 및 재실행 제어 \n",
    "\n",
    "- 챗봇에 인간이 개입할 수 있는 실행을 추가하여 필요할 때 인간의 감독과 개입을 가능하게 함 \n",
    "- **checkpointer**를 추가했기 때문에, 그래프는 **무기한** 일시 중지되고 언제든지 다시 시작할 수 있음\n",
    "- 아래는 `get_state_history` 메서드를 사용하여 상태 기록을 가져오는 방법 (역순으로 추적)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay = None\n",
    "\n",
    "# 상태 기록 가져오기\n",
    "for state in graph.get_state_history(config):\n",
    "    # 메시지 수 및 다음 상태 출력\n",
    "    print(\"메시지 수: \", len(state.values[\"messages\"]), \"다음 노드: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    # 특정 상태 선택 기준: 채팅 메시지 수\n",
    "    if len(state.values[\"messages\"]) == 3:\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 항목의 다음 요소 출력\n",
    "print(to_replay.next)\n",
    "\n",
    "# 다음 항목의 설정 정보 출력\n",
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `to_replay.config`는 `checkpoint_id`는 체크포인터에 저장된 상태에 해당\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    # 메시지가 이벤트에 포함된 경우\n",
    "    if \"messages\" in event:\n",
    "        # 마지막 메시지 출력\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

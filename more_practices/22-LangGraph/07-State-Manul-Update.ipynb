{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY Loading\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH21-LangGraph\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(\"CH21-LangGraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Manual Update \n",
    "\n",
    "- LangGraph은 중간 단계의 State를 수동으로 업데이트 할 수 있는 방안을 제공함 \n",
    "- 이를 통해 에이전트 행동을 수정하여 경로를 제어할 수 있음 \n",
    "- 또한 에이전트의 실수를 수정하거나, 대체 경로를 탐색하는 것처럼 특정 목표에 따라 에이전트의 동작을 변경할 때 유용함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_teddynote.graphs import visualize_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## 1. State ##########\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "########## 2. TOOLS ##########\n",
    "# 도구 초기화\n",
    "tool = TavilySearch(max_results=3)\n",
    "\n",
    "# 도구 목록 정의\n",
    "tools = [tool]\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# LLM + 도구 \n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "########## 3. NODE ##########\n",
    "# 챗봇 함수 정의\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# Graph\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# 도구 노드 생성 및 추가\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Conditional Edge\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "\n",
    "########## 4. EDGE ##########\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "\n",
    "########## 5. MEMORY ##########\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "########## 6. COMPILE  ##########\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "########## 7. VISUALIZE ##########\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"LangGraph 가 무엇인지 조사하여 알려주세요!\"\n",
    "\n",
    "# 초기 입력 상태를 정의\n",
    "input = State(messages=[(\"user\", question)])\n",
    "\n",
    "# config 설정\n",
    "config = RunnableConfig(\n",
    "    configurable={\"thread_id\": \"001\"},  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**channels**\n",
    "\n",
    "- LangGraph 내부에서 노드 간 데이터가 흐르는 경로(통로) \n",
    "- 각 노드의 입력과 출력을 연결하는 데이터 이동 경로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['messages',\n",
       " '__start__',\n",
       " 'chatbot',\n",
       " 'tools',\n",
       " 'branch:__start__:__self__:chatbot',\n",
       " 'branch:__start__:__self__:tools',\n",
       " 'branch:chatbot:__self__:chatbot',\n",
       " 'branch:chatbot:__self__:tools',\n",
       " 'branch:tools:__self__:chatbot',\n",
       " 'branch:tools:__self__:tools',\n",
       " 'start:chatbot',\n",
       " 'branch:chatbot:tools_condition:tools']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그래프 채널 목록 출력\n",
    "list(graph.channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interrupt 상태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LangGraph 가 무엇인지 조사하여 알려주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_6scw06YFFSQF7R6fBfqnob6e)\n",
      " Call ID: call_6scw06YFFSQF7R6fBfqnob6e\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "# 그래프 스트림 호출\n",
    "# 중단 지점(interrupt_before=[“tools”])에서 중간 상태 확인\n",
    "events = graph.stream(\n",
    "    input=input, config=config, interrupt_before=[\"tools\"], stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "# 이벤트 반복 처리\n",
    "for event in events:\n",
    "    # 메시지가 이벤트에 포함된 경우\n",
    "    if \"messages\" in event:\n",
    "        # 마지막 메시지의 예쁜 출력\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_6scw06YFFSQF7R6fBfqnob6e)\n",
      " Call ID: call_6scw06YFFSQF7R6fBfqnob6e\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "# 그래프 상태 스냅샷 생성\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# 가장 최근 메시지 추출\n",
    "last_message = snapshot.values[\"messages\"][-1]\n",
    "\n",
    "# 메시지 출력\n",
    "last_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 도구 결과 수동 수정\n",
    "\n",
    "- `TavilySearch` 도구에서 검색 결과 수정하여 새로운 ToolMessage 생성\n",
    "- tool_call_id를 기존 메시지에서 추출 후 동일 ID로 새 메시지 생성\n",
    "- 그래프 상태 업데이트 (graph.update_state)로 반영\n",
    "- 이후 흐름 계속 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[수정된 웹 검색 결과] \n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n"
     ]
    }
   ],
   "source": [
    "modified_search_result = \"\"\"[수정된 웹 검색 결과] \n",
    "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
    "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
    "\n",
    "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
    "[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\"\"\"\n",
    "\n",
    "print(modified_search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call_6scw06YFFSQF7R6fBfqnob6e\n"
     ]
    }
   ],
   "source": [
    "# 수정하고자 하는 `ToolMessage` 의 `tool_call_id` 추출\n",
    "tool_call_id = last_message.tool_calls[0][\"id\"]\n",
    "print(tool_call_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**메시지 타입**\n",
    "\n",
    "- HumanMessage : 사용자 입력 전달 \n",
    "- AIMessage : LLM의 텍스트 응답 메시지, 일반적인 대화 응답 \n",
    "- SystemMessage : 대화 설정 또는 시스템 프롬프트 \n",
    "- ToolMessage : 도구 실행 결과 메시지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[수정된 웹 검색 결과] \n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n"
     ]
    }
   ],
   "source": [
    "new_messages = [\n",
    "    # LLM API의 도구 호출과 일치하는 ToolMessage 필요\n",
    "    ToolMessage(\n",
    "        content=modified_search_result,\n",
    "        tool_call_id=tool_call_id,\n",
    "    ),\n",
    "    # LLM의 응답에 직접적으로 내용 추가\n",
    "    # AIMessage(content=modified_search_result),\n",
    "]\n",
    "\n",
    "new_messages[-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StateGraph의 `update_state` \n",
    "\n",
    "- `update_state` : 주어진 값으로 그래프의 상태를 업데이트\n",
    "- 마치 `as_node`에서 값이 온 것처럼 동작함\n",
    "\n",
    "**매개변수**\n",
    "\n",
    "- `config` (RunnableConfig): 실행 구성\n",
    "- `values` (Optional[Union[dict[str, Any], Any]]): 업데이트할 값들\n",
    "- `as_node` (Optional[str]): 값의 출처로 간주할 노드 이름. 기본값은 None\n",
    "\n",
    "**반환값**\n",
    "\n",
    "- RunnableConfig\n",
    "\n",
    "**주요 기능**\n",
    "\n",
    "1. 체크포인터를 통해 이전 상태를 로드하고 새로운 상태를 저장\n",
    "2. 서브그래프에 대한 상태 업데이트를 처리\n",
    "3. `as_node`가 지정되지 않은 경우, 마지막으로 상태를 업데이트한 노드를 찾음\n",
    "4. 지정된 노드의 writer들을 실행하여 상태를 업데이트\n",
    "5. 업데이트된 상태를 체크포인트에 저장\n",
    "\n",
    "**주요 로직**\n",
    "\n",
    "1. 체크포인터를 확인하고, 없으면 ValueError를 발생시킴\n",
    "2. 서브그래프에 대한 업데이트인 경우, 해당 서브그래프의 `update_state` 메서드를 호출\n",
    "3. 이전 체크포인트를 로드하고, 필요한 경우 `as_node`를 결정\n",
    "4. 지정된 노드의 writer들을 사용하여 상태를 업데이트\n",
    "5. 업데이트된 상태를 새로운 체크포인트로 저장\n",
    "\n",
    "**참고**\n",
    "\n",
    "- 이 메서드는 그래프의 상태를 수동으로 업데이트할 때 사용\n",
    "- 체크포인터를 사용하여 상태의 버전 관리와 지속성 보장\n",
    "- `as_node`를 지정하지 않으면 자동으로 결정되지만, 모호한 경우 오류가 발생할 수 있음\n",
    "- 상태 업데이트 중 SharedValues에 쓰기 작업은 허용되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(최근 1개의 메시지 출력)\n",
      "\n",
      "content='[수정된 웹 검색 결과] \\nLangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\\nLangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\\n\\n자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\\n[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.' id='85ce1f34-adc4-4606-b16a-b60aa3e54b92' tool_call_id='call_6scw06YFFSQF7R6fBfqnob6e'\n"
     ]
    }
   ],
   "source": [
    "graph.update_state(\n",
    "    # 업데이트할 상태 지정\n",
    "    config,\n",
    "    # 제공할 업데이트된 값. `State`의 메시지는 \"추가 전용\"으로 기존 상태에 추가됨\n",
    "    {\"messages\": new_messages},\n",
    "    as_node=\"tools\",\n",
    ")\n",
    "\n",
    "print(\"(최근 1개의 메시지 출력)\\n\")\n",
    "print(graph.get_state(config).values[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('chatbot',)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[수정된 웹 검색 결과] \n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 구축할 수 있도록 지원하는 오픈 소스 라이브러리입니다. 이 라이브러리는 LLM(대형 언어 모델)을 활용하여 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공합니다.\n",
      "\n",
      "더 자세한 정보와 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/)과 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785)에서 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "# 이벤트 반복 처리\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANwAAAD5CAIAAADDWcxTAAAAAXNSR0IArs4c6QAAIABJREFUeJztnXl8E9Xax5/se5o03Re6lxZalrJTEbisgkrBiwoCKiiLogjyIgIiIHgBAVEUFRGUC4iAqEABWctOS4GWlu77mi7Z92Qyef8ItyC2tUsmM0nn++GPaWZynl/CL2fOOXPOcyg2mw1ISIgEFW8BJCRPQpqShHCQpiQhHKQpSQgHaUoSwkGakoRw0NasWYO3BnyQmQ03ZFKlxVyu11xqrObRGZ5M9i25lLDHaYq6dEW9J5PFozOsNpRKoeD9FWIFHW8BTgVB0VN1ZUqL+YWAiCyVrEinjAKRFUCHWJQWs8xsVCMWwh6rLCalxVRt0LFp9M0FdwV0xushPXxYHLy/VMdD6TqD5yjYrjTWlGrVgyW+Piwu3nI6S55GIaQzI/geZ+rKpwRE4C3HkXQJU95W1G0vyvyy99N4C8GE09KyNEX9F72HUcBNbujub0qrzbar9MGLQZF4C8EQLWIRM1llOk0vDwneWhyAm5syU9XAozHETDbeQpzBtcYaPzZvkKcv3kI6izsPCe0svt9gMnYRRwLAU14BBiuSpZLhLaSzuG1NKTcb9VaEQ+tawwsAwKBShXQm3io6hXvWlDrEIjXqu6AjAcCCou9kXK436vEW0nHc05Qb8m8zqO750drCnNAeJ+rK8FbRcdzw9p2jllUb9Qkib7yF4IlL38Td0JRGK6KzInirwJk6o75Yr3rOLwxvIR3B3e5xFXrNkeoivFXgjy+be1teJzXq8BbSEdzNlCmN1Tw6w/lxz505/t6CaR1447Sk4dn372CgCMb7hmgRCxYlY4279U9DOIIwntD5cY8d/jGuV0J733Xn9o3SkoKIqFgsJHUXiEUMl2xWulubUm9FDJg1KHU6zdfbN1y7fE7eWC8UeY4dP2nhktVms+lfgyPtX6PEy+fUpfu11ZVfb19/984trVoVEhr55ttLnx45HgBsNtvIQRELFn14/cr5rMw7k16Y8fO+b+0lL/9o8+QXZzlWrQYxX2yomh3Sw7HFOgG3qilVFtOe8txZ3WIwKv+TVYsryos3fb7H1y8gPzd79fIFXj5+02fN37T9h2WLZv9wIDkkNAJBkHfnv+zhIdq47QcPkTj5j0Mr3n/z1+Rbvv6B9dIag0F/7vTvr89b/NEnX3B5/OzM2xIvv+Ufb+bxBQ5Xy6cx7qsaHV6sE3ArUzaajI0mA3blFxflJg4bFduzNwAMeWrkDwdOCYUiKpVaW1PFYrF7xPWlUqk2m23Ljn0CgdBT4g0AzyVN/2n3juKifF//wMLCHAB45tmpicNG2wssKy0eNmK8WIzJLAoKhTLBLxRBUbqrDdm6lSkDuTxMZwONHvf8vh92WBHrhOenxsb16RYSbn+9MD8nIiqWSqUCgF6v+zP51xvXLtbX1SIWM4JYAUDi7W2/jMViPzv5Zfu7pDVVGrUyKhrD2+tTkgCXc6S79b7ZVHokX4xd+XPfXrZ6/Ze5ORmvTRs/e/qE4sJc++tF+TnRMT0BAEXRd9588czJX+fMX7Jnf/J/j5x/LullGo0WFh4NAEX52T17JbBYDyeIFBY8AICoGAxNuS43DbvCscOtTImg6IfZ17Ern0KhjJs4Zff+5F+OX6XRaUvffRUAEAQpKcqLjO4BAPfu3HqQdXfpiv8MGz7WLyDI1y+wrLQgNDyayWQBQEF+TnT3uKbSCvIeiMSe3j7+GKmVm4wouGQv1q1MSadSmVSa1IDJiHFFeUmdtNp+HBoW9e+XZ9dUVei06oryYrPFbB/WaWyoA4Dgbg+fo5QU56enXuseGwcARqOhsrwkqvujerG4MBejwSA7LBptflhcGy4kHG5lSgBYHt1PgM3g3JZPP1zx/ps52ffksoac7HuH/rurT8IgHl+oUioAoKggp7qqPKZHLyqVmvzHIbPFfO/OrR1b1nqIPDlcns1mKy7MtdlskY+ZUqlSKBXy3AeZJpMRC8FCBjOc54FFyVjjbktsuXQGhUJBMRh8HTR0RHbmnT27Pv/vD19dv3qh38Chyz/6jM3heIjEqddTzpw8KvQQjxw1wdvH7/DB3bu/2dpQJ12xZotM1nDi2EEURQ1Gw81rFxd/8AntfxPqrAjyZ/KxC38enzp9DpPp+B/St6XZUXwPvgtOy3C3wXMAWJh5+cPofuwuOZmyiXK9+kh10X96DsVbSEdwQ1P+XFmgtyJJAeEtXbDl0xV6nfaJF40mI5vV/MIJBov14erPHC3zIWWlhft272j2VGck6RCLhMnGZRpA53FDUwKAwYrou/DsNdRmAxt4s101T4G7dXTsaBFLpeHJurDr8FXx/UYLJp0n5+CepvRmcW7Iau4o6vEWggNZqsaxvt1iBRg+RMAa97x920lT1AWwuBzXbFd1jEqDNk7oSae4dl3j2upbZ6DYl02jF2qUeAtxEncV9Xkauas70s1NCQBeLM7Fhsp8jQJvIZhDo1BK9OqXg6LxFuIA3Pn23cRtRV2swDNfowjFY1I61txR1GuslikB4W6T4MrNa0o7A8S+fDrjply6Mf+O2/wIdYgFAAq0yiKdcqJviNs4sqvUlE3kqeXhfA/EZluefSOMJ5zVLcZiQ3NUMgqV0kvohdjQDJWMSdTjbLWcYoPeIi+Z2binLMcKtk09hxpRhEtzt55cl6gpm4gRejKpNC6NPi+sZzhPKGayeTRGnlZxW14vZDCZNNq1xurOH1vN5q8vnHJsmUwaLVejqDBoxEyWH4v7RmiPz+ISqRSK+zmyy9WUzkGr1T777LMpKSl4C3FVulZNSeISkKYkIRykKTEhNhbDKeVuD2lKTMjNzcVbggtDmhITRCIR3hJcGNKUmKBUdpUH7lhAmhITAgIC8JbgwpCmxISamhq8JbgwpCkxIT4+Hm8JLgxpSkzIysrCW4ILQ5qShHCQpsQELy8vvCW4MKQpMaGx0SWzlRIE0pSY4O3dpXfx6SSkKTGhoaEBbwkuDGlKEsJBmhITIiPdec97rCFNiQlFReSuZx2HNCUJ4SBNiQk9erjelkrEgTQlJuTk5OAtwYUhTUlCOEhTYgI5S6gzkKbEBHKWUGcgTUlCOEhTYgK5xLYzkKbEBHKJbWcgTUlCOEhTYgK57rszkKbEBHLdd2cgTYkJUVFReEtwYUhTYkJhYSHeElwY0pQkhIM0JSb4+fnhLcGFIU2JCVKpFG8JLgxpSkyIi4vDW4ILQ5oSE7Kzs/GW4MKQpsQEsqbsDKQpMYGsKTsDaUpMCA4OxluCC0Nu7uQw3njjDalUSqPRrFarTCbz8vKiUqkIgiQnJ+MtzcUga0qHMW3aNLVaXV1dLZVKLRZLbW1tdXU1lUp+w+2G/MocxqhRoyIiIh5/xWazkYt1OgBpSkcyY8YMLpfb9Ke/v//06dNxVeSSkKZ0JKNGjQoNDbUf22y2Pn36kGNDHYA0pYN59dVX7ZWln58fWU12DNKUDmbUqFFhYWEA0LdvXzJ5S8eg4y0AW+pNhnK92uLcYa+hs2fUHD0a9+/nb8idOi2DQ6WGcoViJtuZQbHAbccpC7XK78selOs18UKJzGzEW44z8GAws9SyWIF4aVSCiMHCW07HcU9TVug1K3NuzgzuLnTl/5uOUWvU/V5bui0uUcLi4K2lg7ihKVUW0+t3LiyLTsBbCG4YrcjnxZl/DJ6It5AO4oam/LI4U0BnxAo88RaCJ6lyqQ+LOy04Gm8hHcENe98ZqkZPhss39juJB4OVrZHhraKDuKEpwQaezC7XlHwCCZNttFrxVtFB3NCUDWYD6m5NknaDAigsJrxVdBA3NCWJq0OakoRwkKYkIRykKUkIB2lKEsJBmpKEcJCmJCEcpClJCAdpShLCQZqShHCQpiQhHKQpW+NK8rEZQ2JWzEoiSDldBNKUmCCrq5kxJOb0oR8JVZSrQJoSE26eP03AolwFN1/N2EakFWW/fLPtQfotG4p2i455Yc7CHv0HN52lUmmludl7PltTVVTgFxI276P/hEY/XDubcuLouSMHpFVlPL5H32EjXlqwhMsXfvT6C6V5DwDgwBcbD3yx8fvzd+wXU4ByP/XawR2b6yrK/ELCXl+2Jjq+r/1U0YPMY7t3FGZlImaTT3DIqKQXx/x7BoVCeaKovZczGV1gqihZU4KysWHdvGm3U84Ghob3HjqsMOvexvfm5GXcbroAMZs+/2AhBShUOq2yKP+LD99FURQALp/8dfenq+QNtWOnzuDy+ReOHdqzeS0ADBn7rMTHHwC69+k/7sVZdCbDXo5Wpfx+/cqg8CgPL+/KovzPly0wm4wAUHD/7oYFM+/fuhYSHdNv+Oj66sp92zYc2rn170VRaV2iEiFNCacP/ahWKsJien703cGFn3w+6bX5NCrt9M8/NV1QVVo0/d0P1u05snTLdwDQUFNVXVoEALl3U4PCIv89d/FLC95/delqALhz5QKKohOmve7bLRQA+g8fPXPxCgaDaS9HVl/7zobPF67buvb7X+hMlkapTL98HgAO7dxqsZgTxz+3aud/F36ybf7qjQBw+ue9aoX8iaJoNBp+35Pz6BK/vNbJvZsGAPEDE+1p+154450X3njn8QsEYs/Bo58BgNiEgSwOx2QwKGUNwRHR81dvtl9gMZuEnhIAsJiMOrVKIBI3G8jLPzC6VwIAeEi8ImLj8jPvVBUXmAz6wvt3AWDImGftlw0YMZZKo6FWa0VRXtyAodh/AYSDNCXotGoA4AmELV0gkng3HbM4XJPBgFpRAMi9d/vwN9tK83MQ86OFBzZocSnG42blCT0AQKNW6rRq+4LSprNUKpUvEKqVClldrSM+n+tBmhI8vX3rKsu1GpX9T4vFrFOpKFSqh6fE/gqFQvn7u1Ry2dal84x6/YTpsxOGjVTJZTtWvtd6IJ1a1XSsVasAQCiW8PhCCoVis9m0/9tjFEEQ+1m+sItuhUu2KSGiZ28AyLx51Wq1AsDpgz8ufG7YlysXtf6u6tIio14PAEmvz4/pM8Cg1dhft1lRe0cbAEwGw+Nvqa+uLMnJBgCVrLE0JwsAQqNjWRxubMJAAEi9eMZ+WXrKWRRF6UxW9979WirKvSFrSpgw/fWLvx+uKMxbv2CGT2BQ6oUzFAol6fUFrb/Lr1uIveW3+z+rPcSSjJuXfYND6irLD329ZcobCz29fQDg7OF9DbXVU+cusiKIvSm57YO3eg16Ku/ebYvF7Ont1zdxJABMe/v/1sx9+UryMbVCxhUI0y6dBYDJsxfwPUQA8HhRryxazuXxnfXF4AZZU4JQ5PnRN//tM3R4VXHh3aspET16ffDFD/EDE1t/l6e335sr1nv5B969dqm8KG/Jpq+nzH6bw+XfvX5Jq1FNeGV2YGiETqvJvn0DtaEWiwUAAkMjZi1ZmZ+ZLm+QRvTotWTLTjqDAQBhsXErv/qpR/8heRm30y6dDQqLnLvq00mvzrcHerwoSssNVnfCDdO2PHfz5NLIvqyuMXrSEnUmwx+1JXsSRuEtpCOQNSUJ4SBNSUI4SFOSEA7SlCSEgzQlCeEgTUlCOEhTkhAO0pQkhIM0JQnhIE1JQjhIU5IQDtKUJISDNCUJ4XBDU0bwPNCuMcWrFWyABnNcdealG5qSAlBr1OGtAmeq9To+jYG3ig7ihqZ8WhJQY9DirQJn6k2GRIk/3io6iBuacnJgRL3ZmKaow1sIbpyrqxAzWUNd1pRuOPPcznv3rwayeZ5MViCHD9DMckR3wmw2M5lMqw2tMmhrjDovJvudiN54i+o4bmtKADgtLb+pkFpsaLFaoVarRWLMVqzaQKvV8gXNdyxsNptOp+PzMex2yGVyCoXCUGkFNEaMlfaUJMDLy6t3b1f1pTub0s5PP/107NixLVu2REVFYRQiPT39+++//+6771q6YOLEiT/88IOfnx9GAqZOnVpcXEyhUOxLyBkMBo/HY7PZYrF4//79GAXFDtqaNWvw1oAVUqn0rbfekkgk27dvl0gk2AWyWCyDBw/29Gxxh/H4+HihUMjj8TASIBaLMzIyjEajPXUCiqImk8lsNp86dQqjiJjitjXlgQMHDh48uHnz5p49e+KtxRksWLAgNTXVng7J3ma4c+cO3qI6iBv2vuVy+bJly+rq6pKTk53jyB07dshkre34XlBQsG/fPkw1zJ079/HmAZvNxjQcpribKY8fP/7SSy/NnDlzyZIlzomoUql+++231psHfn5+e/fuxVRG3759ExIS7Md0On3dunX9+/dPSUnBNChGuM/tG0XR9957Lzo6euHChc6MiyCIxWLhcDitX6ZWq/l8ftPtFQtqamrmzp1bU1Nz9+5d+yvr16/X6/WffvopdkExweYWXLt2rX///teuXcNbCM589dVXo0ePfvyVM2fODB48+ObNm/iJajfuUFNu3LjRYrF89NFHuERft27dCy+88I+N17Nnz1ZWVs6ZM8dZuh5hNpvXrVvH5/OXL1/u/OgdwLXblFKpdMqUKREREXg5EkXREydOtKU7FRkZeebMGaeIehImk7l+/fqIiIhp06aVlZXhoqF94F1Vd5zTp09PmDChrKwMbyFtxWQy4SugtrZ2ypQphw4dwlfGP+Kqt+8tW7bo9frVq1fjK8NgMFCpVBarTduIoChqf+iCva7W2Lx5s0ql2rBhA74yWsElb9+zZ88ODAzE3ZEAkJSUpNFo2njxhQsXPvzwQ4wV/TPLli175plnRo4cWVFRgbeWFsC7qm4fdXV18+bNy8jIwFuIzWazZWVlLV68uO3XWyyWJ7rGOKJSqZKSkpKTk/EW0gyudPu+d+/eihUrTp482UW2k3ECa9euFYlEixb9Q4J3J+Myt+8zZ858/fXXp0+fJo4jr127Zs/d33aUSmVVVRVmitrNxx9/LBaLly5direQv+Aapjx8+HBubu7u3bvxFvKIkydPnjt3rr2/EJFINHnyZPsuegRh1qxZEydOfPnll/EW8hh4tx/+mQMHDmzcuBFvFU/y888/S6XSDrzxyJEjt27dwkBRpygoKBg3bhzeKh5C9DblkSNHKioq3n//fbyFuD9yuXzy5MmXL1/GWwixb9/p6emZmZkEdOTx48c7M55y/vz5hoYGhypyAJ6ensnJyZMmTcJbCIFNeeHChcOHD69fvx5vIU+SmZn5+++/d+vWrcMlcDicTz75xKGiHAOfz//uu+/Gjh2Lsw682w/Nk5eXN23aNLxVNE9tba3BYOhkIampqWq12kGKHExWVtasWbNwFEDENqVWq126dOm3336Lt5BmMBqNer2+leU47sHly5dv3LiB1/MnIt6+Fy1aNH/+fLxVNE9SUlJ7xyZbYuXKlffu3XNIUQ5n+PDhAHD06FF8wuNYSzfL/v37t27direK5rl06VJKSoqjSquurp4zZ46jSsOCCRMm1NbWOj8usUxZXV09efJkvFWQPKSkpKRdD/cdBbFu3xs3biTgAJCdnTt31tU5Pj/Rb7/9ptUSNB1XWFgYn89PTk52clwCmTI3N1culycm/sOexriwa9cuoVDo6+vr8JLj4+NxWSPRRubNm9dK5g+MIFDve8mSJZMmTbI3sbsUjY2NKIr6+PjgLaR5tm/fHhMTM378eKdFJEpNWVFRQaFQiOnIAwcOYFq+l5cXgiAGgwHTKB1m6NChf/zxhzMjEsWUly5dCgkJwVtFM7zyyiv9+vXDOkpAQMCECRPUajXWgTrAwIED8/LynKmNQKYcOXIk3iqeRKlUfv/99zExMU6IdfLkyRs3bjghUAeYOnXqlStXnBaOEKZsbGzk8Xjx8fF4C/kLVVVVCoWCy+U6JxyPxxszZozJZHJOuHYRFBTkzHRZhDBlbm4ug0GsrPGXL1/etm1bWFiYM4PSaLTjx49v3LjRmUHbQnR0dEFBgdPCEcKURUVFkZGReKt4hNFo9PX13bZtm/NDT5069Zlnnnnw4IHzQ7dCTEyM0+4YRDFlcXExdml22wuCIA8ePHBOO7JZevfuHRwcbM+AShxKSkqUSqVzYhHClLW1tViMS3eMxMRE3LOFC4XCjz/++Pz58/jKeByRSNS1TKnRaAQCAd4qAADy8vKuX79Op9PxFgKbNm3icDhSqRRvIQ+Ji4vT6Zy0ZRYhTKlWq4VCId4qIDU1NSgoiAiOtJOYmOjn50eQLNFFRUVOW9xMCFN6eHjgng55+vTpIpEI041FOsaJEycqKyvxVgEWi8VpIySEMKVarcb3IZtCodi3b1/37t1x1NASa9asycvLw1uFU5tYhDAlk8k0m814RbfP2yXOXfvvjBkzBgCc/AD6CRoaGry9vZ0TixCm9PPzw2tO4WuvvSaRSFxizU1+fn5GRsbjryQlJTkntEwmGzp0qNOSGBLClFwut76+3vlxLRbL3r17ifZ4syWWLVtmNpub9kYZNmyYXq9PS0tzQuji4mKLxeKEQHYIYcqwsDCVSuXkoKtWrWIwGLinMG0XAwcOpNFo69atGzlypMFgkMvlztlTTCqVOmGqVBOEMKVEIiksLHRmxJ07dxJ2wWTriESi8+fPN2VqvXv3rhN+z/fu3XPmHGRCmDIsLKy0tNSZEadPnx4UFOTMiI5iwoQJer2+6c/6+non7OCkUCic+dyVEKaMjIx8/IvGDgRBZs+eba9vnBDO4YwZM+aJxjeCICdOnMA0qNVqvXHjRnR0NKZRHocQpvTx8SkvL1coFFgHWrVq1a5du7COgh3nzp3r06dPYGAgi8VqWlxVVVVVVFSEXdDc3NzY2Fjsyv87RBmcGzJkSEFBwaBBg5KSklAUPX78uGPLLy0tDQsLI+BUxfaye/fu+vr69PT0tLS03NISnRVpbGw8dvH8q8GBGEVMK8gL69u7zuSApxsedCa7Dc8qCbGacfz48QqFAkEQ+3bVQUFBv//+e2cKvHr16urVqy9dumT/s76+fuvWrZs2bXKQXvw5UJmfLC1jUWlqk8FitnB5GE52RCwWCpXqkAffVtTGpzOmBEQ859/a7Gmca8rJkyc3PdhtGp3p/OjDyZMnNRpN//7909PTjUZjTk6OOzlybW4ah0afGRwjZrZp/x5CITcbr8tqKw3at8JbHB7GuU25efPmgICAx19hMpmDBw/uTJkNDQ05OTn24/79+5tMphEjRnROJoFYm5smpDOf9gpwRUcCgCeT/Zx/mMxs/LrkfkvX4GzKqKioOXPmPP6k38PDo0ePHp0p88qVK4/nybU/OHYPUuV1FIAhEr82XEtoxvgEVxt0hdrmZw3j3/ueNGnSmDFj7Bth22w2Hx+fwMBOtdlPnjxpb57aQVF00KBBjlCKP4VaJR3LHcOdTJG2+WF/QnzCFStWNA06DBw4sDNF5ebmVldXN/2JoiiTyQwKCpo6dWqnZeKP0mIKYDtvARemBHL49S306IkyJLR9+/YZM2ZotdqEhITOlJOcnCyXy202m33uj1gsTkxMjI+Px33ZjUNQWExMwuxt1UnMqFULzY/8dNaURivCptEPVRU0mAwAYELRt8LjuTT6N6VZOgRp+/EhZVXPFe9mbNzRp0+f9r738eMUNuI375V+DfohCf2yAj0obPaU8Hgujb6zJItNo80O6VRrlcQ5dHyc8ouizGvymu58sdxsrDPpDQiCgA0o8Mj9RDpmUqhMKtWfww/nClIaqod7By6N6lSVjAuf5N32ZXN7CSV4C3EAN+VSJpX6dnivv59qd02ZKpdWGrT31bJbcikApCn+mkfURtBjsw01W9FCrdLe47vQUIXYbP/yDhLRmdECcbOflAQv2mfK32pKfq0uqjcTNGld27HabBcbqi41VPmxuNO7dR/n0/FNcUgcTlt731rEck1W80PZAzdwZBM2gFqT/tuSrAIt5nNBSNpOm2pKk9W6IOOSQx7JExCdFXk/63oQm/dNX8LlIuya/HNNabQiO0uz3NWRdkyotUSvXp1zC28hJNAmU95TNZyt7/jmmK6CDeC+WlZp0OAthOSfTLmp4M6GvHQrAaa3OQG9FXn//vVkaRneQro6rZmyTK8u0CrNNtSJenBGiZh+LM9VmomYTrfr0JopERStNBB03yHsMKCItYXHXyTOoUVT1hp1mwvvOldMu0mZOLPkpyOOLdOMojtL7lu70v2hLTTUVM0YEjNjSIxOg/mK3hZNebK2tEJP6Fa/QVpvUWkEUY5PS56havyzzk36dldP/TFjSExZQQ7eQtpBi6Y021CC1xWaglIAwMKUGsSS38L8U5cj9YIzUmg4lhYHzxEse9w2q7X8l+NVf/xpapRzgwNDpyf5j32419i9//uE4SEURIVV/nbaLFN49IyOW72E5SkCAE1RacFXe9V5xVQmI/SVKYhOzxAJ2d6YzE7wZ/OwKNaZoCg6K/HhrKhVr04Ji+n5yd5fAaDoQeax3TsKszIRs8knOGRU0otj/j2jaYHU9TPHz/zyU1VpMY1GDe3e8/lX5/Ua9NTfC0cQ5MS+XTfOnmiU1nI4nJiEQS8uWOIX5Jintc2bslCrTJVjmNj4wac7ZGn3YhbPFXSPkKXezV73OUMo8BqcAAC68iqrycwPCx7y03aLUnPztUUVh09EzZ9pkivvLFotiosZsPNTG4rmfvatRa0RRGK1pcgdZf0k/zAOjSjzTTsAhUIZ9+KsPw/vA4AhY58Ni+kJAAX37/5n4WsWizmm7wCRxPvO1Yv7tm2Q1ddNe3spACQf3PPzjs1UGq3/06ONBt39W9fyM9IXb96Z8NSTz7p+273jj5++C47sPmryS/L6urSLZ4qyMrb9eo7uiMSqzX/p+VqlFsEqy1bjrTu1f6YkbPtYMrAvAHCnTKhLuVmTfMFrcAKi0xtq6wMm/Cv0lSkAQPNlcYMCjHUNAFDxyx8AEL92KY3NAoCo+TPT31nl/VSnpqm3QpVBW6BR9hZ5YVS+E6BQKDMXrzh3dD+KohNfmR0a3QMADu3carGYE8c/t+DjzwAg9eKZHSvfO/3z3onTZzOYjGPyWEshAAAGx0lEQVS7dwDA7GVrRjw/FQB+3LLu/K8Hj+764u+mzEq7AQAz31vRo98gADh39KDZbDTqdXwPB6Qead6UcQJPBLMmZc2pi7zQILsj7XD8fbUl5QCgKS4Dmy3wuUdLvUwNMs+EOACou3zLO3GA3ZEAwBB5YNSgtEMDCofuJnO8mzAZ9IX37wLAkDHP2l8ZMGIslUZDrdaKojyr1WoyGABgyJiJ9rODRj1z/teDlUX5FsuTKW0DQsNLcrO+XLmo//Ax3Xv37z98tNjbYRmwmjdlKE/IpNEQK9Ls2U6izisySBsu/OvRohkUsUoG9AYAbVEZlckQxjzcU8ei1pga5fyIUItaa6iqDZ32KEeosb4RU1PyGYxovrvNs9Rp1fY53QLRw49GpVL5AqFaqZDV1dLpDABgsNgszsNlQPbLbDaboqGOAn/JmfjKu8t1GvW9a5dSjh9JOX6ESqONnjxt5pKVDkmt2Lwpr8tqmVSq3tr58psB0epDXno+8NnRf9HB4wKApqiMFxpM/V8VpSkqszvP2CADALbPo5upMiuXymTyumGVq4RBodab9D4sN1mlZYfHF1IoFJvNpv3fjjgIgmjVKgDgC0V0BhMALCaj2WhgsjkAoJY/TNDKF3ro/rqLrUAkfv+zb9QKeV7G7ezbN64k/3726P5eQ4b1GeqAzbGbHxKiAjzxy3AgLG8JhUbjhQTZ/9H5PBqHzfLytNeUgsjQpis1RWV251EZdABA/pes32ow1iRf4Id3o2C2ikplMVuIPibWNigU+40bAFgcbmzCQHtT0n4yPeUsiqJ0Jqt7735R8b25fCEA3Lr4p/3srQunACA8Nt7+ehMmg/7Uz3t/+WabUOw5cOS42cvWPv3MJABQNNQ1p6DdNF9T9hP79BV5XWyobvZsJ/EfN7xs/zGPntGCyDBdeVXBjj3CHtFxK9+12Wza0grfUY8GILTFZXbncQL8WF6eFYdPcAP8LBpt2f5jVoOR/5h9HU4wlx/IIdz2JR1A7O0rk9bs/Wxdr4GJ09/9YNrb/7dm7stXko+pFTKuQJh26SwATJ69wN5BeeHNhf/9/NM9mz7OSb+hUSoyb16l0ekvv730iTJZHO6tc6dKcrNKcrLDe/TUqlTX/zxOZ7Ji+gxwiObmTcmk0kZ5d8PIlN1efB41Wwp27DE1Kti+Xv7jRoTOeAEADFW1VoORH/FoK3pNUZkwOhwAqHRa/Nqledt23X7rQ15IUPf33sz4YAM/HMNN65dE9sGucGcy7e2l+z7fUFdRVib2BICw2LiVX/10dPdXeRm3EcQaFBY5duorT0+cYr943IuzWBzu2SP7U8+foTEY8QMTJ895O7pXMyvslm777tDXW+/fupKXkcbl86PjEya9vsA/xDFN/BZXM/5cmb+vIr9rTk3wY3E/ihkQxSdcYtWuvpqxv9j315oSNdLi9jb6qtpmJ0NQqNSWnlAKosJCXnyuzbL/mewNX7Z0ymow0DicZk9FzZthb8K2BGqzhXAJsVdk16S1dd8ZqoYPsm90taqSTaV9HDOwn9h5eefbThepKVubT9lD4PmUxB9LYURkenB3Yjqy69CaKZlUmoTB4dOctE0kERDTmRKGS+Z9dCf+YY3OWxHxo32CCZGaDXt4NPpQif8YXzIxAc788yyYt8Lju3EFXxZnOkUPblAB1sYO6uXhwjMw3IY2VYLP+oV6MzmutF9cO2FRqCO8gkhHEoS23pl/7Dd6nG+IgO6G7csgNj9B7LO8u/P2HiRpnbZOYmVQqUsi+8wOiV18/2q1UYexKidBB8pQL///i0pgUd1tlppL074+jIjBWtV9QJxQMtTTtYeKmFRqL6FklE/Q+5F9SUcSjXZP94/ge2yLfwoAaoy6ZdnXERsqZrCVFpPSbLISJ0fqk8fApFA9mWw6lWqyIuE8j1UxA8yoVUBntvfjkziBjq9BCWDz9vcfW23QBnL4SrPpTF25gMGc6BdabdQdry0JYPMm+YcT5PhCfUU3jmCEd1CDyYDaUF82DwDICpKwEGIbPJI20kUeM7rwar0uiCeDxaC4yaMMJpUmbOFhoZt8wi6CJ5Nd4y5DH5V6jW8LewKRpnQlYgRi7FaZOhkKBboLmp+xSprSlegr8ubR6ZcaqvAW0llO1JbG8j1DuMJmz5IdHdfjq+JMhdnUUygJ4LhYbhmrDa016m/J6waJfaYGRbV0GWlKl+SUtOyEtFSDWDQWrBKZYAGdSgnm8KcERD7tFdDKZaQpXRgUQG91JVPyaIy2TOshTUlCOMiODgnhIE1JQjhIU5IQDtKUJISDNCUJ4SBNSUI4/h+ASi12E/EwrgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LangGraph 가 무엇인지 조사하여 알려주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_6scw06YFFSQF7R6fBfqnob6e)\n",
      " Call ID: call_6scw06YFFSQF7R6fBfqnob6e\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[수정된 웹 검색 결과] \n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 구축할 수 있도록 지원하는 오픈 소스 라이브러리입니다. 이 라이브러리는 LLM(대형 언어 모델)을 활용하여 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공합니다.\n",
      "\n",
      "더 자세한 정보와 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/)과 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785)에서 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# 최근 세 개의 메시지 출력\n",
    "for message in snapshot.values[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "# 다음 상태 출력\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interrupt 후 메시지 상태 업데이트 \n",
    "\n",
    "- `TavilySearch` 도구에서 검색 쿼리 수정\n",
    "- `thread_id` : 랜덤한 해시값을 생성하는 `generate_random_hash` 함수를 사용하여 적용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread_id: ba9282\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import generate_random_hash\n",
    "\n",
    "thread_id = generate_random_hash()\n",
    "print(f\"thread_id: {thread_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LangGraph 에 대해서 배워보고 싶습니다. 유용한 자료를 추천해 주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_v1hmwYsw44mZXKJQVpa2XAvK)\n",
      " Call ID: call_v1hmwYsw44mZXKJQVpa2XAvK\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "question = \"LangGraph 에 대해서 배워보고 싶습니다. 유용한 자료를 추천해 주세요!\"\n",
    "\n",
    "input = State(messages=[(\"user\", question)])\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "events = graph.stream(\n",
    "    input=input,\n",
    "    config=config,\n",
    "    interrupt_before=[\"tools\"],\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 를 복사\n",
    "config_copy = config.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message ID run-c3f00d8c-d525-4985-b370-baa7d3653b40-0\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# 스냅샷 상태 \n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# messages 의 마지막 메시지 \n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "\n",
    "# 메시지 ID 출력\n",
    "print(\"Message ID\", existing_message.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'tavily_web_search', 'args': {'query': 'LangGraph'}, 'id': 'call_v1hmwYsw44mZXKJQVpa2XAvK', 'type': 'tool_call'}\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 도구 호출 출력\n",
    "print(existing_message.tool_calls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tavily_web_search',\n",
       " 'args': {'query': 'LangGraph Studio'},\n",
       " 'id': 'call_v1hmwYsw44mZXKJQVpa2XAvK',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tool_calls 를 복사하여 새로운 도구 호출 생성\n",
    "new_tool_call = existing_message.tool_calls[0].copy()\n",
    "\n",
    "# 쿼리 매개변수 업데이트\n",
    "new_tool_call[\"args\"] = {\"query\": \"LangGraph Studio\"}\n",
    "new_tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-c3f00d8c-d525-4985-b370-baa7d3653b40-0\n"
     ]
    }
   ],
   "source": [
    "# AIMessage 생성\n",
    "new_message = AIMessage(\n",
    "    content=existing_message.content,\n",
    "    tool_calls=[new_tool_call],\n",
    "    id=existing_message.id,  # ID는 메시지를 상태에 추가하는 대신 교체하는 방법으로 처리 (별5개)\n",
    ")\n",
    "\n",
    "print(new_message.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_v1hmwYsw44mZXKJQVpa2XAvK)\n",
      " Call ID: call_v1hmwYsw44mZXKJQVpa2XAvK\n",
      "  Args:\n",
      "    query: LangGraph Studio\n"
     ]
    }
   ],
   "source": [
    "# 수정한 메시지 출력\n",
    "new_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'tavily_web_search', 'args': {'query': 'LangGraph Studio'}, 'id': 'call_v1hmwYsw44mZXKJQVpa2XAvK', 'type': 'tool_call'}\n",
      "\n",
      "Message ID run-c3f00d8c-d525-4985-b370-baa7d3653b40-0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': 'ba9282',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f00b88a-6d95-6874-8002-27a43068d0a7'}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 업데이트된 도구 호출 출력\n",
    "print(new_message.tool_calls[0])\n",
    "\n",
    "# 메시지 ID 출력\n",
    "print(\"\\nMessage ID\", new_message.id)\n",
    "\n",
    "# 상태 업데이트\n",
    "graph.update_state(config, {\"messages\": [new_message]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_web_search',\n",
       "  'args': {'query': 'LangGraph Studio'},\n",
       "  'id': 'call_v1hmwYsw44mZXKJQVpa2XAvK',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 마지막 메시지의 도구 호출 가져오기\n",
    "graph.get_state(config).values[\"messages\"][-1].tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_v1hmwYsw44mZXKJQVpa2XAvK)\n",
      " Call ID: call_v1hmwYsw44mZXKJQVpa2XAvK\n",
      "  Args:\n",
      "    query: LangGraph Studio\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"title\": \"langchain-ai/langgraph-studio - GitHub\", \"url\": \"https://github.com/langchain-ai/langgraph-studio\", \"content\": \"Once you select a valid project, LangGraph Studio will start a LangGraph API server and you should see a UI with your graph rendered. LangGraph Studio lets you run your graph with different inputs and configurations. LangGraph Studio allows you to edit the thread state and fork the threads to create alternative graph execution with the updated state. An interrupt in LangGraph Studio means that the graph execution will be interrupted both before and after a given node runs. In addition to interrupting on a node and editing the graph state, you might want to support human-in-the-loop workflows with the ability to manually update state. With LangGraph Studio you can modify your graph code and sync the changes live to the interactive graph.\", \"score\": 0.88705814, \"raw_content\": \"GitHub - langchain-ai/langgraph-studio: Desktop app for prototyping and debugging LangGraph applications locally.\\nSkip to content \\nNavigation Menu\\nToggle navigation\\n\\nSign in\\n\\n\\nProduct\\n\\nGitHub Copilot Write better code with AI\\nSecurity Find and fix vulnerabilities\\nActions Automate any workflow\\nCodespaces Instant dev environments\\nIssues Plan and track work\\nCode Review Manage code changes\\nDiscussions Collaborate outside of code\\nCode Search Find more, search less\\n\\nExplore\\n\\nAll features\\nDocumentation\\nGitHub Skills\\nBlog\\n\\n\\n\\nSolutions\\nBy company size\\n\\nEnterprises\\nSmall and medium teams\\nStartups\\nNonprofits\\n\\nBy use case\\n\\nDevSecOps\\nDevOps\\nCI/CD\\nView all use cases\\n\\nBy industry\\n\\nHealthcare\\nFinancial services\\nManufacturing\\nGovernment\\nView all industries\\n\\nView all solutions\\n\\n\\nResources\\nTopics\\n\\nAI\\nDevOps\\nSecurity\\nSoftware Development\\nView all\\n\\nExplore\\n\\nLearning Pathways\\nWhite papers, Ebooks, Webinars\\nCustomer Stories\\nPartners\\nExecutive Insights\\n\\n\\n\\nOpen Source\\n\\n\\nGitHub Sponsors Fund open source developers\\n\\n\\nThe ReadME Project GitHub community articles\\n\\n\\nRepositories\\n\\nTopics\\nTrending\\nCollections\\n\\n\\n\\nEnterprise\\n\\nEnterprise platform AI-powered developer platform\\n\\nAvailable add-ons\\n\\nAdvanced Security Enterprise-grade security features\\nGitHub Copilot Enterprise-grade AI features\\nPremium Support Enterprise-grade 24/7 support\\n\\n\\n\\nPricing\\n\\n\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\nSearch\\nClear\\nSearch syntax tips\\nProvide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancel Submit feedback\\nSaved searches\\nUse saved searches to filter your results more quickly\\nName  \\nQuery \\nTo see all available qualifiers, see our documentation.\\nCancel Create saved search\\nSign in\\nSign up Reseting focus\\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\\n{{ message }}\\nlangchain-ai / langgraph-studio Public\\n\\nNotifications You must be signed in to change notification settings\\nFork 158\\nStar 2.4k\\n\\nDesktop app for prototyping and debugging LangGraph applications locally.\\nstudio.langchain.com\\n2.4k stars 158 forks Branches Tags Activity\\nStar\\nNotifications You must be signed in to change notification settings\\n\\nCode\\nIssues 50\\nPull requests 0\\nDiscussions\\nActions\\nSecurity\\nInsights\\n\\nAdditional navigation options\\n\\nCode\\nIssues\\nPull requests\\nDiscussions\\nActions\\nSecurity\\nInsights\\n\\nlangchain-ai/langgraph-studio\\nmain\\nBranchesTags\\n\\nGo to file\\nCode\\nFolders and files\\n| Name | Name | \\nLast commit message\\n| \\nLast commit date\\n|\\n| --- | --- | --- | --- |\\n| \\nLatest commit\\nHistory\\n52 Commits\\n\\n|\\n| \\nimg\\n| \\nimg\\n| \\n| \\n|\\n| \\nREADME.md\\n| \\nREADME.md\\n| \\n| \\n|\\n| \\ncover.svg\\n| \\ncover.svg\\n| \\n| \\n|\\n| \\nView all files\\n|\\nRepository files navigation\\n\\nREADME\\n\\n\\nLangGraph Studio Desktop (Beta)\\n\\nLangGraph Studio offers a new way to develop LLM applications by providing a specialized agent IDE that enables visualization, interaction, and debugging of complex agentic applications\\nWith visual graphs and the ability to edit state, you can better understand agent workflows and iterate faster. LangGraph Studio integrates with LangSmith so you can collaborate with teammates to debug failure modes.\\nWhile in Beta, LangGraph Studio is available for free to all LangSmith users on any plan tier. Sign up for LangSmith here.\\nNote\\nWe recommend that users run a local LangGraph server and use the web version of LangGraph Studio instead of using the LangGraph Studio Desktop application. This is a newer feature that improves the development experience, as it works without Docker, significantly shortens startup times, supports code hot-reloading, and works across all platforms.\\n\\nDownload\\n\\nDownload the latest .dmg file of LangGraph Studio by clicking here or by visiting the releases page.\\nThe desktop application only supports macOS. Other users can run a local LangGraph server and use the web studio. We also depend on Docker Engine to be running, currently we only support the following runtimes:\\n\\nDocker Desktop\\nOrbstack\\n\\nSetup\\n\\nLangGraph Studio requires docker-compose version 2.22.0+ or higher. Please make sure you have Docker Desktop or Orbstack installed and running before continuing.\\nTo use LangGraph Studio, make sure you have a project with a LangGraph app set up.\\nFor this example, we will use this example repository here which uses a requirements.txt file for dependencies:\\nshell\\ngit clone https://github.com/langchain-ai/langgraph-example.git\\nIf you would like to use a pyproject.toml file instead for managing dependencies, you can use this example repository.\\nshell\\ngit clone https://github.com/langchain-ai/langgraph-example-pyproject.git\\nYou will then want to create a .env file with the relevant environment variables:\\nshell\\ncp .env.example .env\\nYou should then open up the .env file and fill in with relevant OpenAI, Anthropic, and Tavily API keys.\\nIf you already have them set in your environment, you can save them to this .env file with the following commands:\\nshell\\necho \\\"OPENAI_API_KEY=\\\\\\\"$OPENAI_API_KEY\\\\\\\"\\\" > .env\\necho \\\"ANTHROPIC_API_KEY=\\\\\\\"$ANTHROPIC_API_KEY\\\\\\\"\\\" >> .env\\necho \\\"TAVILY_API_KEY=\\\\\\\"$TAVILY_API_KEY\\\\\\\"\\\" >> .env\\nNote: do NOT add a LANGSMITH_API_KEY to the .env file. We will do this automatically for you when you authenticate, and manually setting this may cause errors.\\nOnce you've set up the project, you can use it in LangGraph Studio. Let's dive in!\\nOpen a project\\n\\nWhen you open LangGraph Studio desktop app for the first time, you need to login via LangSmith.\\n\\nOnce you have successfully authenticated, you can choose the LangGraph application folder to use — you can either drag and drop or manually select it in the file picker. If you are using the example project, the folder would be langgraph-example.\\nImportant\\nThe application directory you select needs to contain correctly configured langgraph.json file. See more information on how to configure it here and how to set up a LangGraph app here.\\n\\nOnce you select a valid project, LangGraph Studio will start a LangGraph API server and you should see a UI with your graph rendered.\\n\\nInvoke graph\\n\\nNow we can run the graph! LangGraph Studio lets you run your graph with different inputs and configurations.\\nStart a new run\\n\\nTo start a new run:\\n\\nIn the dropdown menu (top-left corner of the left-hand pane), select a graph. In our example the graph is called agent. The list of graphs corresponds to the graphs keys in your langgraph.json configuration.\\nIn the bottom of the left-hand pane, edit the Input section.\\nClick Submit to invoke the selected graph.\\nView output of the invocation in the right-hand pane.\\n\\nThe following video shows how to start a new run:\\ngraph_invoke.mp4\\nConfigure graph run\\n\\nTo change configuration for a given graph run, press Configurable button in the Input section. Then click Submit to invoke the graph.\\nImportant\\nIn order for the Configurable menu to be visible, make sure to specify config schema when creating StateGraph. You can read more about how to add config schema to your graph here.\\nThe following video shows how to edit configuration and start a new run:\\ngraph_config.mp4\\nCreate and edit threads\\n\\nCreate a thread\\n\\nWhen you open LangGraph Studio, you will automatically be in a new thread window. If you have an existing thread open, follow these steps to create a new thread:\\n\\nIn the top-right corner of the right-hand pane, press + to open a new thread menu.\\n\\nThe following video shows how to create a thread:\\ncreate_thread.mp4\\nSelect a thread\\n\\nTo select a thread:\\n\\nClick on New Thread / Thread <thread-id> label at the top of the right-hand pane to open a thread list dropdown.\\nSelect a thread that you wish to view / edit.\\n\\nThe following video shows how to select a thread:\\nselect_thread.mp4\\nEdit thread state\\n\\nLangGraph Studio allows you to edit the thread state and fork the threads to create alternative graph execution with the updated state. To do it:\\n\\nSelect a thread you wish to edit.\\nIn the right-hand pane hover over the step you wish to edit and click on \\\"pencil\\\" icon to edit.\\nMake your edits.\\nClick Fork to update the state and create a new graph execution with the updated state.\\n\\nThe following video shows how to edit a thread in the studio:\\nfork_thread.mp4\\nHow to add interrupts to your graph\\n\\nYou might want to execute your graph step by step, or stop graph execution before/after a specific node executes. You can do so by adding interrupts. Interrupts can be set for all nodes (i.e. walk through the agent execution step by step) or for specific nodes. An interrupt in LangGraph Studio means that the graph execution will be interrupted both before and after a given node runs.\\nAdd interrupts to a list of nodes\\n\\nTo walk through the agent execution step by step, you can add interrupts to a all or a subset of nodes in the graph:\\n\\nIn the dropdown menu (top-right corner of the left-hand pane), click Interrupt.\\nSelect a subset of nodes to interrupt on, or click Interrupt on all.\\n\\nThe following video shows how to add interrupts to all nodes:\\ngraph_interrupts_all.mp4\\nAdd interrupt to a specific node\\n\\n\\nNavigate to the left-hand pane with the graph visualization.\\nHover over a node you want to add an interrupt to. You should see a + button show up on the left side of the node.\\nClick + to invoke the selected graph.\\nRun the graph by adding Input / configuration and clicking Submit\\n\\nThe following video shows how to add interrupts to a specific node:\\ngraph_interrupts.mp4To remove the interrupt, simply follow the same step and press x button on the left side of the node.\\nHuman-in-the-loop\\n\\nIn addition to interrupting on a node and editing the graph state, you might want to support human-in-the-loop workflows with the ability to manually update state. Here is a modified version of agent.py with agent and human nodes, where the graph execution will be interrupted on human node. This will let you send input as part of the human node. This can be useful when you want the agent to get user input. This essentially replaces how you might use input() if you were running this from the command line.\\n```python\\nfrom typing import Literal\\nfrom langchain_openai import ChatOpenAI\\nfrom langgraph.graph import MessagesState, StateGraph, END\\nfrom langgraph.types import Command, interrupt\\nmodel = ChatOpenAI(temperature=0, model_name=\\\"gpt-4o\\\")\\ndef call_model(state: MessagesState) -> Command[Literal[\\\"human\\\", END]]:\\n    messages = state[\\\"messages\\\"]\\n    response = model.invoke(messages)\\nreturn Command(\\n    goto=\\\"human\\\",\\n    update={\\\"messages\\\": [response]},\\n)\\n\\ndef human_feedback(state: MessagesState) -> Command[Literal[\\\"agent\\\"]]:\\n    \\\"\\\"\\\"A node for collecting user input.\\\"\\\"\\\"\\n    print(\\\"Waiting for user input...\\\")\\n    user_input = interrupt(value=\\\"Ready for user input.\\\")\\nprint(\\\"user input:\\\", user_input)\\n\\nreturn Command(\\n    goto=\\\"agent\\\",\\n    update={\\n        \\\"messages\\\": [\\n            {\\n                \\\"role\\\": \\\"human\\\",\\n                \\\"content\\\": user_input,\\n            }\\n        ]\\n    },\\n)\\n\\nworkflow = StateGraph(MessagesState)\\nworkflow.set_entry_point(\\\"agent\\\")\\nworkflow.add_node(\\\"agent\\\", call_model)\\nworkflow.add_node(\\\"human\\\", human_feedback)\\ngraph = workflow.compile()\\n```\\nThe following video shows how to manually send state updates (i.e. messages in our example) when interrupted:\\ngraph_hitl.mp4\\nEdit project config\\n\\nLangGraph Studio allows you to modify your project config (langgraph.json) interactively.\\nTo modify the config from the studio, follow these steps:\\n\\nClick Configure on the bottom right. This will open an interactive config menu with the values that correspond to the existing langgraph.json.\\nMake your edits.\\nClick Save and Restart to reload the LangGraph API server with the updated config.\\n\\nThe following video shows how to edit project config from the studio:\\ngraph_edit_json.mp4\\nEdit graph code\\n\\nWith LangGraph Studio you can modify your graph code and sync the changes live to the interactive graph.\\nTo modify your graph from the studio, follow these steps:\\n\\nClick Open in VS Code on the bottom right. This will open the project that is currently opened in LangGraph studio.\\nMake changes to the .py files where the compiled graph is defined or associated dependencies.\\nLangGraph studio will automatically reload once the changes are saved in the project directory.\\n\\nThe following video shows how to open code editor from the studio:\\ngraph_edit_code.mp4After you modify the underlying code you can also replay a node in the graph. For example, if an agent responds poorly, you can update the agent node implementation in your code editor and rerun it. This can make it much easier to iterate on long-running agents.\\nreplay.mp4\\nTroubleshooting\\n\\nHow do I access local services and models such as Ollama, Chroma, etc?\\n\\nLangGraph Studio relies on Docker Compose to run the API, Redis and Postgres, which in turn creates its own network. Thus, to access local services you need to use host.docker.internal as the hostname instead of localhost. See #112 for more details.\\nFailing to install native dependencies during build\\n\\nBy default, we try to make the image as small as possible, thus some dependencies such as gcc or build-essentials are missing from the base image. If you need to install additional dependencies, you can do so by adding additional Dockerfile instructions in the dockerfile_lines section of your langgraph.json file:\\n{\\n    \\\"dockerfile_lines\\\": [\\n        \\\"RUN apt-get update && apt-get install -y gcc\\\"\\n    ]\\n}\\nSee How to customize Dockerfile for more details.\\nAbout\\nDesktop app for prototyping and debugging LangGraph applications locally.\\nstudio.langchain.com\\nTopics\\nai desktop agents langgraph\\nResources\\nReadme\\nActivity\\nCustom properties\\nStars\\n2.4k stars\\nWatchers\\n29 watching\\nForks\\n158 forks\\nReport repository\\nReleases 30\\n0.0.36 Latest Jan 29, 2025\\n+ 29 releases\\nContributors 9\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFooter\\n© 2025 GitHub, Inc.\\nFooter navigation\\n\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact\\nManage cookies\\nDo not share my personal information\\n\\nYou can’t perform that action at this time.\"}, {\"title\": \"Local Deploy - langchain-ai.github.io\", \"url\": \"https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-1-1)langgraphnewpath/to/your/app--templatereact-agent-python [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-2-1)langgraphnewpath/to/your/app--templatereact-agent-js [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-4-1)LANGSMITH_API_KEY=lsv2... [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-4-2)TAVILY_API_KEY=tvly-... [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-4-3)ANTHROPIC_API_KEY=sk- [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-4-4)OPENAI_API_KEY=sk-... [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-6-1)pipinstalllanggraph-sdk [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-2) [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-3)client = get_client(url=\\\"http://localhost:8123\\\") [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-4) [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-5)async for chunk in client.runs.stream( [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-6)    None,  # Threadless run [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-7)    \\\"agent\\\", # Name of assistant. [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-9)        \\\"messages\\\": [{ [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-11)            \\\"content\\\": \\\"What is LangGraph?\\\", [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-12)        }], [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-13)    }, [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-14)    stream_mode=\\\"updates\\\", [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-15)): [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-8-1)pipinstalllanggraph-sdk [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-2) [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-3)client = get_sync_client(url=\\\"http://localhost:8123\\\") [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-4) [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-5)for chunk in client.runs.stream( [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-6)    None,  # Threadless run [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-7)    \\\"agent\\\", # Name of assistant. [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-9)        \\\"messages\\\": [{ [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-11)            \\\"content\\\": \\\"What is LangGraph?\\\", [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-12)        }], [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-13)    }, [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-14)    stream_mode=\\\"updates\\\", [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-15)): [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-2) [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-5) [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-6)conststreamResponse=client.runs.stream( [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-7)null,// Threadless run [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-8)\\\"agent\\\",// Assistant ID [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-9){ [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-12){\\\"role\\\":\\\"user\\\",\\\"content\\\":\\\"What is LangGraph?\\\"} [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-13)] [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-14)}, [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-16)} [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-17)); [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-18) [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-23)} [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-2)--url\\\"http://localhost:8123/runs/stream\\\"\\\\ [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-4)--data\\\"{ [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-5)        \\\\\\\"assistant_id\\\\\\\": \\\\\\\"agent\\\\\\\", [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-8)                { [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-10)                    \\\\\\\"content\\\\\\\": \\\\\\\"What is LangGraph?\\\\\\\" [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-11)                } [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-12)            ] [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-13)        }, [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-14)        \\\\\\\"stream_mode\\\\\\\": \\\\\\\"updates\\\\\\\" [](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-15)    }\\\"\", \"score\": 0.6847074, \"raw_content\": \"Quick Start: Launch Local LangGraph Server\\nSkip to content\\n \\nQuick Start: Launch Local LangGraph Server\\n\\nInitializing search\\nGitHub\\n\\nHome\\nTutorials\\nHow-to Guides\\nConceptual Guides\\nReference\\n\\n \\nGitHub\\n\\nHome\\n\\n[ ] \\nTutorials\\nTutorials\\n\\n\\n[ ]  Quick Start\\nQuick Start\\n\\nQuick Start\\n🚀 LangGraph Quick Start\\n\\n[ ]  Quick Start: Launch Local LangGraph Server Quick Start: Launch Local LangGraph Server\\nTable of contents\\n\\nInstall the LangGraph CLI\\n🌱 Create a LangGraph App\\nInstall Dependencies\\nCreate a .env file\\n🚀 Launch LangGraph Server\\nLangGraph Studio Web UI\\nTest the API\\n\\nNext Steps\\n\\n🌐 Deploy to LangGraph Cloud\\n📚 Learn More about LangGraph Platform\\n🛠️ Developer References\\n\\n\\n\\n\\n\\nLangGraph Cloud Quick Start\\n\\n\\n\\n\\n[ ]  Chatbots\\nChatbots\\n\\nChatbots\\nBuild a Customer Support Bot\\nPrompt Generation from User Requirements\\nCode generation with RAG and self-correction\\n\\n\\n\\n[ ]  RAG\\nRAG\\n\\nRAG\\nAdaptive RAG\\nLanggraph adaptive rag local\\nAgentic RAG\\nCorrective RAG (CRAG)\\nCorrective RAG (CRAG) using local LLMs\\nSelf-RAG\\nSelf-RAG using local LLMs\\nAn agent for interacting with a SQL database\\n\\n\\n\\n[ ]  Agent Architectures\\nAgent Architectures\\n\\nAgent Architectures\\nMulti-Agent Systems\\nPlanning Agents\\nReflection & Critique\\n\\n\\n\\n[ ]  Evaluation & Analysis\\nEvaluation & Analysis\\n\\nEvaluation & Analysis\\nChat Bot Evaluation as Multi-agent Simulation\\nChat Bot Benchmarking using Simulation\\n\\n\\n\\n[ ]  Experimental\\nExperimental\\n\\nExperimental\\nWeb Research (STORM)\\nTNT-LLM: Text Mining at Scale\\nWeb Voyager\\nCompetitive Programming\\nComplex data extraction with function calling\\n\\n\\n\\n\\n\\nHow-to Guides\\n\\nConceptual Guides\\nReference\\n\\nTable of contents\\n\\nInstall the LangGraph CLI\\n🌱 Create a LangGraph App\\nInstall Dependencies\\nCreate a .env file\\n🚀 Launch LangGraph Server\\nLangGraph Studio Web UI\\nTest the API\\n\\nNext Steps\\n\\n🌐 Deploy to LangGraph Cloud\\n📚 Learn More about LangGraph Platform\\n🛠️ Developer References\\n\\n\\n\\nHome\\n\\nTutorials\\nQuick Start\\n\\nQuick Start: Launch Local LangGraph Server¶\\nThis is a quick start guide to help you get a LangGraph app up and running locally.\\nRequirements\\n\\nPython >\\\\= 3.11\\nLangGraph CLI: Requires langchain-cli[inmem] >\\\\= 0.1.58\\n\\nInstall the LangGraph CLI¶\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-0-1)pipinstall\\\"langgraph-cli[inmem]==0.1.58\\\"python-dotenv\\n🌱 Create a LangGraph App¶\\nCreate a new app from the react-agent template. This template is a simple agent that can be flexibly extended to many tools.\\nPython ServerNode Server\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-1-1)langgraphnewpath/to/your/app--templatereact-agent-python\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-2-1)langgraphnewpath/to/your/app--templatereact-agent-js\\nAdditional Templates\\nIf you use langgraph new without specifying a template, you will be presented with an interactive menu that will allow you to choose from a list of available templates.\\nInstall Dependencies¶\\nIn the root of your new LangGraph app, install the dependencies:\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-3-1)pipinstall.\\nCreate a .env file¶\\nYou will find a .env.example in the root of your new LangGraph app. Create a .env file in the root of your new LangGraph app and copy the contents of the .env.example file into it, filling in the necessary API keys:\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-4-1)LANGSMITH_API_KEY=lsv2...\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-4-2)TAVILY_API_KEY=tvly-...\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-4-3)ANTHROPIC_API_KEY=sk-\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-4-4)OPENAI_API_KEY=sk-...\\nGet API Keys\\n\\nLANGSMITH_API_KEY: Go to the LangSmith Settings page. Then clck Create API Key.\\nANTHROPIC_API_KEY: Get an API key from Anthropic.\\nOPENAI_API_KEY: Get an API key from OpenAI.\\nTAVILY_API_KEY: Get an API key on the Tavily website.\\n\\n🚀 Launch LangGraph Server¶\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-5-1)langgraphdev\\nThis will start up the LangGraph API server locally. If this runs successfully, you should see something like:\\n\\nReady!\\n\\n\\nAPI: http://localhost:8123\\n\\n\\nDocs: http://localhost:8123/docs\\n\\n\\nLangGraph Studio Web UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:8123\\n\\n\\n\\n\\nIn-Memory Mode\\nThe langgraph dev command starts LangGraph Server in an in-memory mode. This mode is suitable for development and testing purposes. For production use, you should deploy LangGraph Server with access to a persistent storage backend.\\nIf you want to test your application with a persistent storage backend, you can use the langgraph up command instead of langgraph dev. You will need to have docker installed on your machine to use this command.\\nLangGraph Studio Web UI¶\\nTest your graph in the LangGraph Studio Web UI by visiting the URL provided in the output of the langgraph up command.\\n\\n\\nLangGraph Studio Web UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:8123\\n\\n\\nSafari Compatibility\\nCurrently, LangGraph Studio Web does not support Safari when running a server locally.\\nTest the API¶\\nPython SDK (Async)Python SDK (Sync)Javascript SDKRest API\\nInstall the LangGraph Python SDK\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-6-1)pipinstalllanggraph-sdk\\nSend a message to the assistant (threadless run)\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-1)from langgraph_sdk import get_client\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-3)client = get_client(url=\\\"http://localhost:8123\\\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-5)async for chunk in client.runs.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-6)    None,  # Threadless run\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-7)    \\\"agent\\\", # Name of assistant. Defined in langgraph.json.\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-8)    input={\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-9)        \\\"messages\\\": [{\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-10)            \\\"role\\\": \\\"human\\\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-11)            \\\"content\\\": \\\"What is LangGraph?\\\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-12)        }],\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-13)    },\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-14)    stream_mode=\\\"updates\\\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-15)):\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-16)    print(f\\\"Receiving new event of type: {chunk.event}...\\\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-17)    print(chunk.data)\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-7-18)    print(\\\"\\\\n\\\\n\\\")\\nInstall the LangGraph Python SDK\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-8-1)pipinstalllanggraph-sdk\\nSend a message to the assistant (threadless run)\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-1)from langgraph_sdk import get_sync_client\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-3)client = get_sync_client(url=\\\"http://localhost:8123\\\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-5)for chunk in client.runs.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-6)    None,  # Threadless run\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-7)    \\\"agent\\\", # Name of assistant. Defined in langgraph.json.\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-8)    input={\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-9)        \\\"messages\\\": [{\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-10)            \\\"role\\\": \\\"human\\\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-11)            \\\"content\\\": \\\"What is LangGraph?\\\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-12)        }],\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-13)    },\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-14)    stream_mode=\\\"updates\\\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-15)):\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-16)    print(f\\\"Receiving new event of type: {chunk.event}...\\\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-17)    print(chunk.data)\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-9-18)    print(\\\"\\\\n\\\\n\\\")\\nInstall the LangGraph JS SDK\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-10-1)npminstall@langchain/langgraph-sdk\\nSend a message to the assistant (threadless run)\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-1)const{Client}=awaitimport(\\\"@langchain/langgraph-sdk\\\");\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-3)// only set the apiUrl if you changed the default port when calling langgraph up\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-4)constclient=newClient({apiUrl:\\\"http://localhost:8123\\\"});\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-6)conststreamResponse=client.runs.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-7)null,// Threadless run\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-8)\\\"agent\\\",// Assistant ID\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-9){\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-10)input:{\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-11)\\\"messages\\\":[\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-12){\\\"role\\\":\\\"user\\\",\\\"content\\\":\\\"What is LangGraph?\\\"}\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-13)]\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-14)},\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-15)streamMode:\\\"messages\\\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-16)}\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-17));\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-19)forawait(constchunkofstreamResponse){\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-20)console.log(`Receiving new event of type: ${chunk.event}...`);\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-21)console.log(JSON.stringify(chunk.data));\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-22)console.log(\\\"\\\\n\\\\n\\\");\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-11-23)}\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-1)curl-s--requestPOST\\\\\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-2)--url\\\"http://localhost:8123/runs/stream\\\"\\\\\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-3)--header'Content-Type: application/json'\\\\\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-4)--data\\\"{\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-5)        \\\\\\\"assistant_id\\\\\\\": \\\\\\\"agent\\\\\\\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-6)        \\\\\\\"input\\\\\\\": {\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-7)            \\\\\\\"messages\\\\\\\": [\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-8)                {\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-9)                    \\\\\\\"role\\\\\\\": \\\\\\\"human\\\\\\\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-10)                    \\\\\\\"content\\\\\\\": \\\\\\\"What is LangGraph?\\\\\\\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-11)                }\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-12)            ]\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-13)        },\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-14)        \\\\\\\"stream_mode\\\\\\\": \\\\\\\"updates\\\\\\\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-12-15)    }\\\"\\nAuth\\nIf you're connecting to a remote server, you will need to provide a LangSmith API Key for authorization. Please see the API Reference for the clients for more information.\\nNext Steps¶\\nNow that you have a LangGraph app running locally, take your journey further by exploring deployment and advanced features:\\n🌐 Deploy to LangGraph Cloud¶\\n\\nLangGraph Cloud QuickStart: Deploy your LangGraph app using LangGraph Cloud.\\n\\n📚 Learn More about LangGraph Platform¶\\nExpand your knowledge with these resources:\\n\\nLangGraph Platform Concepts: Understand the foundational concepts of the LangGraph Platform.\\nLangGraph Platform How-to Guides: Discover step-by-step guides to build and deploy applications.\\n\\n🛠️ Developer References¶\\nAccess detailed documentation for development and API usage:\\n\\nLangGraph Server API Reference: Explore the LangGraph Server API documentation.\\nPython SDK Reference: Explore the Python SDK API Reference.\\nJS/TS SDK Reference: Explore the Python SDK API Reference.\\n\\nComments\\nBack to top\\nPrevious 🚀 LangGraph Quick StartNext LangGraph Cloud Quick Start\\nMade with Material for MkDocs Insiders\\n\"}, {\"title\": \"LangGraph Studio\", \"url\": \"https://studio.langchain.com/\", \"content\": \"Memory management is done in the \\\"hot-path\\\", meaning your agent or chatbot must decide to save memories in addition to chatting or doing other work.langchain-ai/memory-agent-jsLangGraph RAG Research Agent TemplateThis LangGraph template implements a RAG research agent that creates a research plan to answer a question and conducts research using a retriever.langchain-ai/rag-research-agent-templateLangGraph.js RAG Research Agent TemplateThis LangGraph template implements a RAG research agent that creates a research plan to answer a question and conducts research using a retriever.langchain-ai/rag-research-agent-template-jsLangGraph ReAct Agent TemplateLangGraph template for a simple ReAct agentlangchain-ai/react-agentNew LangGraph ProjectThis template demonstrates a simple chatbot implemented using LangGraph, designed for LangGraph Studio.\", \"score\": 0.63316137, \"raw_content\": \"LangGraph Studio\\nLangGraph Studio\\nTool for prototyping and debugging LangGraph applications locally.\\npip install \\\"langgraph-cli[inmem]\\\"\\nnpx @langchain/langgraph-cli@latest dev\\nor download desktop app (macOS only)\\nGet started from a template\\nLangGraph.js Memory AgentBuild a memory agent that saves memories about the user with a tool call. Memory management is done in the \\\"hot-path\\\", meaning your agent or chatbot must decide to save memories in addition to chatting or doing other work.langchain-ai/memory-agent-jsLangGraph RAG Research Agent TemplateThis LangGraph template implements a RAG research agent that creates a research plan to answer a question and conducts research using a retriever.langchain-ai/rag-research-agent-templateLangGraph.js RAG Research Agent TemplateThis LangGraph template implements a RAG research agent that creates a research plan to answer a question and conducts research using a retriever.langchain-ai/rag-research-agent-template-jsLangGraph ReAct Agent TemplateLangGraph template for a simple ReAct agentlangchain-ai/react-agentNew LangGraph ProjectThis template demonstrates a simple chatbot implemented using LangGraph, designed for LangGraph Studio. The chatbot maintains persistent chat memory, allowing for coherent conversations across multiple interactions.langchain-ai/new-langgraph-projectLangGraph Data Enrichment TemplateThis is a starter project to help you get started with developing a data enrichment agent using LangGraph in LangGraph Studio.langchain-ai/data-enrichmentLangGraph Retrieval Agent TemplateThis LangGraph template implements a simple, extensible agent that answers questions based on a retriever.langchain-ai/retrieval-agent-templateLangGraph.js Data Enrichment TemplateThis is a starter project to help you get started with developing a data enrichment agent using LangGraph.js in LangGraph Studio.langchain-ai/data-enrichment-jsLangGraph.js Retrieval Agent TemplateThis repo offers the basic code structure to get started building LangGraph workflows in JavaScript within LangGraph studio.langchain-ai/retrieval-agent-template-jsLangGraph.js ReAct Agent TemplateThis LangGraph template implements a simple, extensible agent that answers questions based on a retriever.langchain-ai/react-agent-jsNew LangGraph.js ProjectThis is a (mostly empty) starter project to help you get started with developing LangGraph.js projects in LangGraph Studio.langchain-ai/new-langgraphjs-projectLangGraph Memory AgentBuild a memory agent that saves memories about the user with a tool call. Memory management is done in the \\\"hot-path\\\", meaning your agent or chatbot must decide to save memories in addition to chatting or doing other work.langchain-ai/memory-agent\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph에 대한 유용한 자료를 아래에 정리했습니다. 이 자료들은 LangGraph의 개념, 사용법, 그리고 개발 환경 설정에 대한 정보를 포함하고 있습니다.\n",
      "\n",
      "1. **LangGraph Studio GitHub Repository**:\n",
      "   - [LangGraph Studio GitHub](https://github.com/langchain-ai/langgraph-studio)\n",
      "   - LangGraph Studio는 LangGraph 애플리케이션을 프로토타입하고 디버깅할 수 있는 데스크탑 애플리케이션입니다. 이 저장소에서는 설치 방법, 사용법, 그리고 다양한 기능에 대한 설명을 제공합니다.\n",
      "\n",
      "2. **LangGraph Studio 웹사이트**:\n",
      "   - [LangGraph Studio](https://studio.langchain.com/)\n",
      "   - LangGraph Studio의 공식 웹사이트로, 다양한 템플릿과 프로젝트를 통해 LangGraph를 시작할 수 있는 방법을 제공합니다.\n",
      "\n",
      "3. **로컬 서버 설정 가이드**:\n",
      "   - [Local Deploy - LangGraph](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/)\n",
      "   - LangGraph 애플리케이션을 로컬에서 실행하는 방법에 대한 단계별 가이드를 제공합니다. 필요한 의존성 설치, 환경 변수 설정, 서버 실행 방법 등을 설명합니다.\n",
      "\n",
      "4. **LangGraph Quick Start**:\n",
      "   - [LangGraph Quick Start](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-0-1)\n",
      "   - LangGraph 애플리케이션을 빠르게 시작할 수 있는 가이드로, 필요한 도구와 설정 방법을 안내합니다.\n",
      "\n",
      "이 자료들을 통해 LangGraph의 기본 개념과 사용법을 익히고, 실제로 애플리케이션을 개발하는 데 필요한 정보를 얻을 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 그래프 스트림에서 이벤트 수신\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "# 각 이벤트에 대한 처리\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "내가 지금까지 배운 내용에 대해서 매우 친절하고 정성스럽게 답변해 주세요. 출처를 반드시 포함해 주세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "당신이 지금까지 배운 LangGraph에 대한 내용은 다음과 같습니다:\n",
      "\n",
      "1. **LangGraph Studio**:\n",
      "   - LangGraph Studio는 LangGraph 애플리케이션을 프로토타입하고 디버깅할 수 있는 데스크탑 애플리케이션입니다. 이 도구는 복잡한 에이전트 애플리케이션의 시각화, 상호작용 및 디버깅을 가능하게 하여 개발자들이 더 나은 이해를 바탕으로 작업할 수 있도록 돕습니다. 사용자는 그래프를 수정하고 상태를 업데이트하며, 다양한 입력과 구성으로 그래프를 실행할 수 있습니다. [출처: LangGraph Studio GitHub](https://github.com/langchain-ai/langgraph-studio)\n",
      "\n",
      "2. **로컬 서버 설정**:\n",
      "   - LangGraph 애플리케이션을 로컬에서 실행하기 위해서는 LangGraph CLI를 설치하고, 필요한 의존성을 설정한 후, 환경 변수를 구성해야 합니다. 이 과정은 LangGraph의 기능을 테스트하고 개발하는 데 필수적입니다. [출처: Local Deploy - LangGraph](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/)\n",
      "\n",
      "3. **LangGraph Studio 웹사이트**:\n",
      "   - LangGraph Studio의 공식 웹사이트에서는 다양한 템플릿과 프로젝트를 통해 LangGraph를 시작할 수 있는 방법을 제공합니다. 이 사이트는 사용자가 LangGraph의 기능을 쉽게 탐색하고 활용할 수 있도록 돕습니다. [출처: LangGraph Studio](https://studio.langchain.com/)\n",
      "\n",
      "4. **빠른 시작 가이드**:\n",
      "   - LangGraph 애플리케이션을 빠르게 시작할 수 있는 가이드는 필요한 도구와 설정 방법을 안내합니다. 이 가이드는 개발자가 LangGraph를 신속하게 이해하고 사용할 수 있도록 돕습니다. [출처: LangGraph Quick Start](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-0-1)\n",
      "\n",
      "이러한 자료들은 LangGraph의 기본 개념과 사용법을 익히고, 실제 애플리케이션을 개발하는 데 필요한 정보를 제공합니다. LangGraph를 통해 복잡한 에이전트 애플리케이션을 효과적으로 개발하고 디버깅할 수 있는 능력을 키울 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 이벤트 스트림 생성\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": (\n",
    "            \"user\",\n",
    "            \"내가 지금까지 배운 내용에 대해서 매우 친절하고 정성스럽게 답변해 주세요. 출처를 반드시 포함해 주세요.\",\n",
    "        )\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "# 메시지 이벤트 처리\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "당신이 지금까지 배운 LangGraph에 대한 내용은 다음과 같습니다:\n",
      "\n",
      "1. **LangGraph Studio**:\n",
      "   - LangGraph Studio는 LangGraph 애플리케이션을 프로토타입하고 디버깅할 수 있는 데스크탑 애플리케이션입니다. 이 도구는 복잡한 에이전트 애플리케이션의 시각화, 상호작용 및 디버깅을 가능하게 하여 개발자들이 더 나은 이해를 바탕으로 작업할 수 있도록 돕습니다. 사용자는 그래프를 수정하고 상태를 업데이트하며, 다양한 입력과 구성으로 그래프를 실행할 수 있습니다. [출처: LangGraph Studio GitHub](https://github.com/langchain-ai/langgraph-studio)\n",
      "\n",
      "2. **로컬 서버 설정**:\n",
      "   - LangGraph 애플리케이션을 로컬에서 실행하기 위해서는 LangGraph CLI를 설치하고, 필요한 의존성을 설정한 후, 환경 변수를 구성해야 합니다. 이 과정은 LangGraph의 기능을 테스트하고 개발하는 데 필수적입니다. [출처: Local Deploy - LangGraph](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/)\n",
      "\n",
      "3. **LangGraph Studio 웹사이트**:\n",
      "   - LangGraph Studio의 공식 웹사이트에서는 다양한 템플릿과 프로젝트를 통해 LangGraph를 시작할 수 있는 방법을 제공합니다. 이 사이트는 사용자가 LangGraph의 기능을 쉽게 탐색하고 활용할 수 있도록 돕습니다. [출처: LangGraph Studio](https://studio.langchain.com/)\n",
      "\n",
      "4. **빠른 시작 가이드**:\n",
      "   - LangGraph 애플리케이션을 빠르게 시작할 수 있는 가이드는 필요한 도구와 설정 방법을 안내합니다. 이 가이드는 개발자가 LangGraph를 신속하게 이해하고 사용할 수 있도록 돕습니다. [출처: LangGraph Quick Start](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#__codelineno-0-1)\n",
      "\n",
      "이러한 자료들은 LangGraph의 기본 개념과 사용법을 익히고, 실제 애플리케이션을 개발하는 데 필요한 정보를 제공합니다. LangGraph를 통해 복잡한 에이전트 애플리케이션을 효과적으로 개발하고 디버깅할 수 있는 능력을 키울 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 최종 응답 \n",
    "# 최종 상태에서 `messages` 의 마지막 메시지로 확인 \n",
    "graph.get_state(config).values[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay\n",
    "\n",
    "- 지난 스냅샷을 확인 후 특정 노드로 되돌아가, State를 수정한 뒤 해당 노드부터 다시 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-f666fe69-9399-4528-8a17-7267c70adf2f-0\n",
      "메시지 수:  6 다음 노드:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "92aceec7-85b7-4c6a-ad61-fd6a63eb4f10\n",
      "메시지 수:  5 다음 노드:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "run-ec7ac560-6c77-4988-9d14-cb77bf572530-0\n",
      "메시지 수:  4 다음 노드:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "run-ec7ac560-6c77-4988-9d14-cb77bf572530-0\n",
      "메시지 수:  4 다음 노드:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "6c0f19ce-d2d2-4814-9ce2-c0d3b9742d31\n",
      "메시지 수:  3 다음 노드:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "run-c3f00d8c-d525-4985-b370-baa7d3653b40-0\n",
      "메시지 수:  2 다음 노드:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "run-c3f00d8c-d525-4985-b370-baa7d3653b40-0\n",
      "메시지 수:  2 다음 노드:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "a5a3c650-716a-4c10-a65a-f22a007116e6\n",
      "메시지 수:  1 다음 노드:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay_state = None\n",
    "\n",
    "# 상태 기록 가져오기\n",
    "for state in graph.get_state_history(config):\n",
    "\n",
    "    messages = state.values[\"messages\"]\n",
    "\n",
    "    if len(messages) > 0:\n",
    "        print(state.values[\"messages\"][-1].id)\n",
    "        # 메시지 수 및 다음 상태 출력\n",
    "        print(\"메시지 수: \", len(state.values[\"messages\"]), \"다음 노드: \", state.next)\n",
    "        print(\"-\" * 80)\n",
    "        # 특정 상태 선택 기준: 채팅 메시지 수\n",
    "        if len(state.values[\"messages\"]) == 2:\n",
    "            # 특정 메시지 ID 선택\n",
    "            to_replay_state = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \u001b[93mcontent\u001b[0m: \"\"\n",
      "    \u001b[93madditional_kwargs\u001b[0m:\n",
      "        \u001b[94mtool_calls\u001b[0m:\n",
      "            \u001b[94mindex [0]\u001b[0m\n",
      "                \u001b[92mid\u001b[0m: \"call_v1hmwYsw44mZXKJQVpa2XAvK\"\n",
      "                \u001b[92mfunction\u001b[0m: {\"arguments\": \"{\"query\":\"LangGraph\"}\", \"name\": \"tavily_web_search\"}\n",
      "                \u001b[92mtype\u001b[0m: \"function\"\n",
      "        \u001b[94mrefusal\u001b[0m: None\n",
      "    \u001b[93mresponse_metadata\u001b[0m:\n",
      "        \u001b[94mtoken_usage\u001b[0m:\n",
      "            \u001b[95mcompletion_tokens\u001b[0m: 19\n",
      "            \u001b[95mprompt_tokens\u001b[0m: 110\n",
      "            \u001b[95mtotal_tokens\u001b[0m: 129\n",
      "            \u001b[95mcompletion_tokens_details\u001b[0m: {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}\n",
      "            \u001b[95mprompt_tokens_details\u001b[0m: {\"audio_tokens\": 0, \"cached_tokens\": 0}\n",
      "        \u001b[94mmodel_name\u001b[0m: \"gpt-4o-mini-2024-07-18\"\n",
      "        \u001b[94msystem_fingerprint\u001b[0m: \"fp_b376dfbbd5\"\n",
      "        \u001b[94mfinish_reason\u001b[0m: \"tool_calls\"\n",
      "        \u001b[94mlogprobs\u001b[0m: None\n",
      "    \u001b[93mtype\u001b[0m: \"ai\"\n",
      "    \u001b[93mname\u001b[0m: None\n",
      "    \u001b[93mid\u001b[0m: \"run-c3f00d8c-d525-4985-b370-baa7d3653b40-0\"\n",
      "    \u001b[93mexample\u001b[0m: False\n",
      "    \u001b[93mtool_calls\u001b[0m:\n",
      "        \u001b[93mindex [0]\u001b[0m\n",
      "            \u001b[95mname\u001b[0m: \"tavily_web_search\"\n",
      "            \u001b[95margs\u001b[0m: {\"query\": \"LangGraph\"}\n",
      "            \u001b[95mid\u001b[0m: \"call_v1hmwYsw44mZXKJQVpa2XAvK\"\n",
      "            \u001b[95mtype\u001b[0m: \"tool_call\"\n",
      "    \u001b[93minvalid_tool_calls\u001b[0m:\n",
      "    \u001b[93musage_metadata\u001b[0m:\n",
      "        \u001b[94minput_tokens\u001b[0m: 110\n",
      "        \u001b[94moutput_tokens\u001b[0m: 19\n",
      "        \u001b[94mtotal_tokens\u001b[0m: 129\n",
      "        \u001b[94minput_token_details\u001b[0m: {\"audio\": 0, \"cache_read\": 0}\n",
      "        \u001b[94moutput_token_details\u001b[0m: {\"audio\": 0, \"reasoning\": 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import display_message_tree\n",
    "\n",
    "# 선택한 메시지 가져오기\n",
    "existing_message = to_replay_state.values[\"messages\"][-1]\n",
    "\n",
    "# 메시지 트리 출력\n",
    "display_message_tree(existing_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tavily_web_search',\n",
       " 'args': {'query': 'LangGraph human-in-the-loop workflow site:reddit.com'},\n",
       " 'id': 'call_v1hmwYsw44mZXKJQVpa2XAvK',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검색 쿼리 업데이트 \n",
    "tool_call = existing_message.tool_calls[0].copy()\n",
    "tool_call[\"args\"] = {\"query\": \"LangGraph human-in-the-loop workflow site:reddit.com\"}\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'LangGraph human-in-the-loop workflow site:reddit.com'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 업데이트된 AIMessage 생성\n",
    "new_message = AIMessage(\n",
    "    content=existing_message.content,\n",
    "    tool_calls=[tool_call],\n",
    "    id=existing_message.id,\n",
    ")\n",
    "\n",
    "# 수정한 메시지 출력\n",
    "new_message.tool_calls[0][\"args\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_web_search',\n",
       "  'args': {'query': 'LangGraph'},\n",
       "  'id': 'call_v1hmwYsw44mZXKJQVpa2XAvK',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 업데이트 전 메시지 확인\n",
    "graph.get_state(to_replay_state.config).values[\"messages\"][-1].tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': 'ba9282',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f00b893-d12b-6aec-8002-3f0e8bb0b265'}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상태 업데이트\n",
    "updated_state = graph.update_state(\n",
    "    to_replay_state.config,\n",
    "    {\"messages\": [new_message]},\n",
    ")\n",
    "updated_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_v1hmwYsw44mZXKJQVpa2XAvK)\n",
      " Call ID: call_v1hmwYsw44mZXKJQVpa2XAvK\n",
      "  Args:\n",
      "    query: LangGraph human-in-the-loop workflow site:reddit.com\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"title\": \"Human intervention in agent workflows : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/\", \"content\": \"Reddit - Dive into anything Open menu Open navigation  Go to Reddit Home Go to LangChain r/LangChain r/LangChain When building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? Top Posts Reddit Reddit Reddit Action Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion Communities Best of Reddit Topics Reddit Rules Privacy Policy User Agreement Reddit, Inc.\", \"score\": 0.65359193, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\ntisi3000\\nHuman intervention in agent workflows\\nWhen building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? I know there is a Human-in-the-loop component in LangGraph that will prompt the user for input. But what if I'm not creating a user-initiated chat conversation, but a flow that reacts to e.g. incoming emails?\\nI guess I'd have to design my UI so that it's not only a simple single-threaded chat interface, but some sort of inbox, right? Or is there any standard way that comes to mind?\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of March 20, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of March 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"Human intervention in agent workflows : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/\", \"content\": \"Reddit - Dive into anything Open menu Open navigation  Go to Reddit Home Go to LangChain r/LangChain r/LangChain When building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? Top Posts Reddit Reddit Reddit Action Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion Communities Best of Reddit Topics Reddit Rules Privacy Policy User Agreement Reddit, Inc.\", \"score\": 0.65359193, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\ntisi3000\\nHuman intervention in agent workflows\\nWhen building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? I know there is a Human-in-the-loop component in LangGraph that will prompt the user for input. But what if I'm not creating a user-initiated chat conversation, but a flow that reacts to e.g. incoming emails?\\nI guess I'd have to design my UI so that it's not only a simple single-threaded chat interface, but some sort of inbox, right? Or is there any standard way that comes to mind?\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of March 20, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of March 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"LangGraph Workflow for Quality Assurance : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/\", \"content\": \"Reddit - Dive into anything Go to LangChain I've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval. Document Submission (Manual User Action): Entry point for examiners to submit documents. Policy Compliance Checker Node (PCCN): Checks documents against policy rules. Quality Assurance Node (QAN): Final review to ensure document quality. Approval and Compliance Marking Node (ACMN): Marks documents as approved. Has anyone automated a Quality Assurance process with langchain/graph? Reddit Reddit Reddit Communities Best of Reddit Topics Reddit, Inc.\", \"score\": 0.6347929, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\nSwimminInIt\\nLangGraph Workflow for Quality Assurance\\nQuestion | Help\\nI've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval.\\nI see a ton of people talking about document chat and integration with knowledge repos. Rather than just providing information I am looking to perform QA on the documents itself.\\nHere's a brief overview of the workflow:\\n\\n\\nDocument Submission (Manual User Action): Entry point for examiners to submit documents.\\n\\n\\nPre-Processing Node (Script for Data Manipulation): Handles initial formatting and basic validation.\\n\\n\\nPolicy Compliance Checker Node (PCCN): Checks documents against policy rules.\\n\\n\\nError Suggestion Node (ESN): Identifies compliance issues and suggests corrections.\\n\\n\\nQuality Assurance Node (QAN): Final review to ensure document quality.\\n\\n\\nFeedback and Interaction Node (FIN): Where examiners review AI suggestions and apply corrections.\\n\\n\\nApproval and Compliance Marking Node (ACMN): Marks documents as approved.\\n\\n\\nSome questions I have are:\\n\\n\\nHas anyone automated a Quality Assurance process with langchain/graph?\\n\\n\\nIf yes, what was successful or what did not work?\\n\\n\\nAny suggestions on how to improve my approach?\\n\\n\\nAre there any examples you are aware of I could use as a reference?\\n\\n\\nI appreciate any help and thoughts on the topic!\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of March 31, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of March 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"LangGraph Workflow for Quality Assurance : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/\", \"content\": \"Reddit - Dive into anything Go to LangChain I've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval. Document Submission (Manual User Action): Entry point for examiners to submit documents. Policy Compliance Checker Node (PCCN): Checks documents against policy rules. Quality Assurance Node (QAN): Final review to ensure document quality. Approval and Compliance Marking Node (ACMN): Marks documents as approved. Has anyone automated a Quality Assurance process with langchain/graph? Reddit Reddit Reddit Communities Best of Reddit Topics Reddit, Inc.\", \"score\": 0.6347929, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\nSwimminInIt\\nLangGraph Workflow for Quality Assurance\\nQuestion | Help\\nI've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval.\\nI see a ton of people talking about document chat and integration with knowledge repos. Rather than just providing information I am looking to perform QA on the documents itself.\\nHere's a brief overview of the workflow:\\n\\n\\nDocument Submission (Manual User Action): Entry point for examiners to submit documents.\\n\\n\\nPre-Processing Node (Script for Data Manipulation): Handles initial formatting and basic validation.\\n\\n\\nPolicy Compliance Checker Node (PCCN): Checks documents against policy rules.\\n\\n\\nError Suggestion Node (ESN): Identifies compliance issues and suggests corrections.\\n\\n\\nQuality Assurance Node (QAN): Final review to ensure document quality.\\n\\n\\nFeedback and Interaction Node (FIN): Where examiners review AI suggestions and apply corrections.\\n\\n\\nApproval and Compliance Marking Node (ACMN): Marks documents as approved.\\n\\n\\nSome questions I have are:\\n\\n\\nHas anyone automated a Quality Assurance process with langchain/graph?\\n\\n\\nIf yes, what was successful or what did not work?\\n\\n\\nAny suggestions on how to improve my approach?\\n\\n\\nAre there any examples you are aware of I could use as a reference?\\n\\n\\nI appreciate any help and thoughts on the topic!\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of March 31, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of March 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"Tool-calling agents: Human approval before tool invocation?\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/\", \"content\": \"Reddit - Dive into anything Open menu Open navigation  Go to Reddit Home Get App Get the Reddit app Log In Log in to Reddit Go to LangChain r/LangChain r/LangChain I'd like to be able to ask for human confirmation before the agent executor invokes a certain tool. I can actually put the confirmation logic in the tool function itself and get it to work, but that doesn't seem right. Reddit Reddit Reddit Action Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion About Reddit Advertise Help Blog Careers*   Press Communities Best of Reddit Topics Reddit, Inc.\", \"score\": 0.20606238, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\ntranswarpconduit1\\nTool-calling agents: Human approval before tool invocation?\\nQuestion | Help\\nI'd like to be able to ask for human confirmation before the agent executor invokes a certain tool. For example, let's say I have asend_emailtool, and I'd like to confirm before it is run.\\nDoes the Langchain agent framework provide a way to hook into the lifecycle in order to do this? Ideally, a hook that would run before the invocation, has tool name and arguments passed in, and then you can return True or False (or an *Exception for an error). I could have the email displayed to standard out there, and collect input.\\nIt doesn't seem like callback handlers work, and they weren't intended for that anyway. They are for introspection (like logging, instrumentation, etc.).\\nI can actually put the confirmation logic in the tool function itself and get it to work, but that doesn't seem right. I could create a special wrapper function \\\"add_human_approval(tool_func)\\\" that returns a new function that asks for human approval, and if it passes invokes the passed in func, otherwise returns. Again, that's still at the tool level, instead as part of the lifecycle.\\nThoughts?\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of May 2, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of May 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"Tool-calling agents: Human approval before tool invocation?\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/\", \"content\": \"Reddit - Dive into anything Open menu Open navigation  Go to Reddit Home Get App Get the Reddit app Log In Log in to Reddit Go to LangChain r/LangChain r/LangChain I'd like to be able to ask for human confirmation before the agent executor invokes a certain tool. I can actually put the confirmation logic in the tool function itself and get it to work, but that doesn't seem right. Reddit Reddit Reddit Action Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion About Reddit Advertise Help Blog Careers*   Press Communities Best of Reddit Topics Reddit, Inc.\", \"score\": 0.20606238, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\ntranswarpconduit1\\nTool-calling agents: Human approval before tool invocation?\\nQuestion | Help\\nI'd like to be able to ask for human confirmation before the agent executor invokes a certain tool. For example, let's say I have asend_emailtool, and I'd like to confirm before it is run.\\nDoes the Langchain agent framework provide a way to hook into the lifecycle in order to do this? Ideally, a hook that would run before the invocation, has tool name and arguments passed in, and then you can return True or False (or an *Exception for an error). I could have the email displayed to standard out there, and collect input.\\nIt doesn't seem like callback handlers work, and they weren't intended for that anyway. They are for introspection (like logging, instrumentation, etc.).\\nI can actually put the confirmation logic in the tool function itself and get it to work, but that doesn't seem right. I could create a special wrapper function \\\"add_human_approval(tool_func)\\\" that returns a new function that asks for human approval, and if it passes invokes the passed in func, otherwise returns. Again, that's still at the tool level, instead as part of the lifecycle.\\nThoughts?\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of May 2, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of May 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph에 대한 유용한 자료를 찾았습니다. 다음은 관련된 Reddit 게시물 링크입니다:\n",
      "\n",
      "1. **[Human intervention in agent workflows](https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/)**: LangGraph를 사용하여 LLM 워크플로우에서 인간이 개입할 수 있는 노드를 만드는 방법에 대한 논의입니다. 이 게시물에서는 사용자 입력을 요청하는 Human-in-the-loop 구성 요소에 대해 설명하고 있습니다.\n",
      "\n",
      "2. **[LangGraph Workflow for Quality Assurance](https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/)**: LangGraph를 사용하여 복잡한 법적 문서의 품질 보증 프로세스를 자동화하는 개념에 대한 논의입니다. 이 게시물에서는 문서 제출, 정책 준수 검사, 품질 보증 및 승인 마킹 노드에 대한 워크플로우를 설명합니다.\n",
      "\n",
      "3. **[Tool-calling agents: Human approval before tool invocation?](https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/)**: 특정 도구를 호출하기 전에 인간의 확인을 요청하는 방법에 대한 질문입니다. LangChain 에이전트 프레임워크에서 이 기능을 구현하는 방법에 대한 논의가 포함되어 있습니다.\n",
      "\n",
      "이 자료들은 LangGraph의 다양한 활용 사례와 워크플로우 설계에 대한 통찰을 제공할 것입니다. 추가적인 질문이 있으면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# config에 updated_state 전달\n",
    "for event in graph.stream(None, updated_state, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LangGraph 에 대해서 배워보고 싶습니다. 유용한 자료를 추천해 주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_v1hmwYsw44mZXKJQVpa2XAvK)\n",
      " Call ID: call_v1hmwYsw44mZXKJQVpa2XAvK\n",
      "  Args:\n",
      "    query: LangGraph human-in-the-loop workflow site:reddit.com\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"title\": \"Human intervention in agent workflows : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/\", \"content\": \"Reddit - Dive into anything Open menu Open navigation  Go to Reddit Home Go to LangChain r/LangChain r/LangChain When building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? Top Posts Reddit Reddit Reddit Action Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion Communities Best of Reddit Topics Reddit Rules Privacy Policy User Agreement Reddit, Inc.\", \"score\": 0.65359193, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\ntisi3000\\nHuman intervention in agent workflows\\nWhen building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? I know there is a Human-in-the-loop component in LangGraph that will prompt the user for input. But what if I'm not creating a user-initiated chat conversation, but a flow that reacts to e.g. incoming emails?\\nI guess I'd have to design my UI so that it's not only a simple single-threaded chat interface, but some sort of inbox, right? Or is there any standard way that comes to mind?\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of March 20, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of March 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"Human intervention in agent workflows : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/\", \"content\": \"Reddit - Dive into anything Open menu Open navigation  Go to Reddit Home Go to LangChain r/LangChain r/LangChain When building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? Top Posts Reddit Reddit Reddit Action Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion Communities Best of Reddit Topics Reddit Rules Privacy Policy User Agreement Reddit, Inc.\", \"score\": 0.65359193, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\ntisi3000\\nHuman intervention in agent workflows\\nWhen building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? I know there is a Human-in-the-loop component in LangGraph that will prompt the user for input. But what if I'm not creating a user-initiated chat conversation, but a flow that reacts to e.g. incoming emails?\\nI guess I'd have to design my UI so that it's not only a simple single-threaded chat interface, but some sort of inbox, right? Or is there any standard way that comes to mind?\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of March 20, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of March 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"LangGraph Workflow for Quality Assurance : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/\", \"content\": \"Reddit - Dive into anything Go to LangChain I've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval. Document Submission (Manual User Action): Entry point for examiners to submit documents. Policy Compliance Checker Node (PCCN): Checks documents against policy rules. Quality Assurance Node (QAN): Final review to ensure document quality. Approval and Compliance Marking Node (ACMN): Marks documents as approved. Has anyone automated a Quality Assurance process with langchain/graph? Reddit Reddit Reddit Communities Best of Reddit Topics Reddit, Inc.\", \"score\": 0.6347929, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\nSwimminInIt\\nLangGraph Workflow for Quality Assurance\\nQuestion | Help\\nI've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval.\\nI see a ton of people talking about document chat and integration with knowledge repos. Rather than just providing information I am looking to perform QA on the documents itself.\\nHere's a brief overview of the workflow:\\n\\n\\nDocument Submission (Manual User Action): Entry point for examiners to submit documents.\\n\\n\\nPre-Processing Node (Script for Data Manipulation): Handles initial formatting and basic validation.\\n\\n\\nPolicy Compliance Checker Node (PCCN): Checks documents against policy rules.\\n\\n\\nError Suggestion Node (ESN): Identifies compliance issues and suggests corrections.\\n\\n\\nQuality Assurance Node (QAN): Final review to ensure document quality.\\n\\n\\nFeedback and Interaction Node (FIN): Where examiners review AI suggestions and apply corrections.\\n\\n\\nApproval and Compliance Marking Node (ACMN): Marks documents as approved.\\n\\n\\nSome questions I have are:\\n\\n\\nHas anyone automated a Quality Assurance process with langchain/graph?\\n\\n\\nIf yes, what was successful or what did not work?\\n\\n\\nAny suggestions on how to improve my approach?\\n\\n\\nAre there any examples you are aware of I could use as a reference?\\n\\n\\nI appreciate any help and thoughts on the topic!\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of March 31, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of March 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"LangGraph Workflow for Quality Assurance : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/\", \"content\": \"Reddit - Dive into anything Go to LangChain I've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval. Document Submission (Manual User Action): Entry point for examiners to submit documents. Policy Compliance Checker Node (PCCN): Checks documents against policy rules. Quality Assurance Node (QAN): Final review to ensure document quality. Approval and Compliance Marking Node (ACMN): Marks documents as approved. Has anyone automated a Quality Assurance process with langchain/graph? Reddit Reddit Reddit Communities Best of Reddit Topics Reddit, Inc.\", \"score\": 0.6347929, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\nSwimminInIt\\nLangGraph Workflow for Quality Assurance\\nQuestion | Help\\nI've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval.\\nI see a ton of people talking about document chat and integration with knowledge repos. Rather than just providing information I am looking to perform QA on the documents itself.\\nHere's a brief overview of the workflow:\\n\\n\\nDocument Submission (Manual User Action): Entry point for examiners to submit documents.\\n\\n\\nPre-Processing Node (Script for Data Manipulation): Handles initial formatting and basic validation.\\n\\n\\nPolicy Compliance Checker Node (PCCN): Checks documents against policy rules.\\n\\n\\nError Suggestion Node (ESN): Identifies compliance issues and suggests corrections.\\n\\n\\nQuality Assurance Node (QAN): Final review to ensure document quality.\\n\\n\\nFeedback and Interaction Node (FIN): Where examiners review AI suggestions and apply corrections.\\n\\n\\nApproval and Compliance Marking Node (ACMN): Marks documents as approved.\\n\\n\\nSome questions I have are:\\n\\n\\nHas anyone automated a Quality Assurance process with langchain/graph?\\n\\n\\nIf yes, what was successful or what did not work?\\n\\n\\nAny suggestions on how to improve my approach?\\n\\n\\nAre there any examples you are aware of I could use as a reference?\\n\\n\\nI appreciate any help and thoughts on the topic!\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of March 31, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of March 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"Tool-calling agents: Human approval before tool invocation?\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/\", \"content\": \"Reddit - Dive into anything Open menu Open navigation  Go to Reddit Home Get App Get the Reddit app Log In Log in to Reddit Go to LangChain r/LangChain r/LangChain I'd like to be able to ask for human confirmation before the agent executor invokes a certain tool. I can actually put the confirmation logic in the tool function itself and get it to work, but that doesn't seem right. Reddit Reddit Reddit Action Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion About Reddit Advertise Help Blog Careers*   Press Communities Best of Reddit Topics Reddit, Inc.\", \"score\": 0.20606238, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\ntranswarpconduit1\\nTool-calling agents: Human approval before tool invocation?\\nQuestion | Help\\nI'd like to be able to ask for human confirmation before the agent executor invokes a certain tool. For example, let's say I have asend_emailtool, and I'd like to confirm before it is run.\\nDoes the Langchain agent framework provide a way to hook into the lifecycle in order to do this? Ideally, a hook that would run before the invocation, has tool name and arguments passed in, and then you can return True or False (or an *Exception for an error). I could have the email displayed to standard out there, and collect input.\\nIt doesn't seem like callback handlers work, and they weren't intended for that anyway. They are for introspection (like logging, instrumentation, etc.).\\nI can actually put the confirmation logic in the tool function itself and get it to work, but that doesn't seem right. I could create a special wrapper function \\\"add_human_approval(tool_func)\\\" that returns a new function that asks for human approval, and if it passes invokes the passed in func, otherwise returns. Again, that's still at the tool level, instead as part of the lifecycle.\\nThoughts?\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of May 2, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of May 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"Tool-calling agents: Human approval before tool invocation?\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/\", \"content\": \"Reddit - Dive into anything Open menu Open navigation  Go to Reddit Home Get App Get the Reddit app Log In Log in to Reddit Go to LangChain r/LangChain r/LangChain I'd like to be able to ask for human confirmation before the agent executor invokes a certain tool. I can actually put the confirmation logic in the tool function itself and get it to work, but that doesn't seem right. Reddit Reddit Reddit Action Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion About Reddit Advertise Help Blog Careers*   Press Communities Best of Reddit Topics Reddit, Inc.\", \"score\": 0.20606238, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\ntranswarpconduit1\\nTool-calling agents: Human approval before tool invocation?\\nQuestion | Help\\nI'd like to be able to ask for human confirmation before the agent executor invokes a certain tool. For example, let's say I have asend_emailtool, and I'd like to confirm before it is run.\\nDoes the Langchain agent framework provide a way to hook into the lifecycle in order to do this? Ideally, a hook that would run before the invocation, has tool name and arguments passed in, and then you can return True or False (or an *Exception for an error). I could have the email displayed to standard out there, and collect input.\\nIt doesn't seem like callback handlers work, and they weren't intended for that anyway. They are for introspection (like logging, instrumentation, etc.).\\nI can actually put the confirmation logic in the tool function itself and get it to work, but that doesn't seem right. I could create a special wrapper function \\\"add_human_approval(tool_func)\\\" that returns a new function that asks for human approval, and if it passes invokes the passed in func, otherwise returns. Again, that's still at the tool level, instead as part of the lifecycle.\\nThoughts?\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of May 2, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of May 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph에 대한 유용한 자료를 찾았습니다. 다음은 관련된 Reddit 게시물 링크입니다:\n",
      "\n",
      "1. **[Human intervention in agent workflows](https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/)**: LangGraph를 사용하여 LLM 워크플로우에서 인간이 개입할 수 있는 노드를 만드는 방법에 대한 논의입니다. 이 게시물에서는 사용자 입력을 요청하는 Human-in-the-loop 구성 요소에 대해 설명하고 있습니다.\n",
      "\n",
      "2. **[LangGraph Workflow for Quality Assurance](https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/)**: LangGraph를 사용하여 복잡한 법적 문서의 품질 보증 프로세스를 자동화하는 개념에 대한 논의입니다. 이 게시물에서는 문서 제출, 정책 준수 검사, 품질 보증 및 승인 마킹 노드에 대한 워크플로우를 설명합니다.\n",
      "\n",
      "3. **[Tool-calling agents: Human approval before tool invocation?](https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/)**: 특정 도구를 호출하기 전에 인간의 확인을 요청하는 방법에 대한 질문입니다. LangChain 에이전트 프레임워크에서 이 기능을 구현하는 방법에 대한 논의가 포함되어 있습니다.\n",
      "\n",
      "이 자료들은 LangGraph의 다양한 활용 사례와 워크플로우 설계에 대한 통찰을 제공할 것입니다. 추가적인 질문이 있으면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 최종 결과 출력\n",
    "for msg in graph.get_state(config).values[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

#!/usr/bin/env python
# coding: utf-8

# # ë¬¸ì œì€í–‰ ê¸°ë°˜ í€´ì¦ˆ ì¶œì œ ë° ì±„ì  ì—ì´ì „íŠ¸ (Multi Agents )
# 
# ## ì‹œìŠ¤í…œ ê°œìš”
# 
# - ë³¸ ì‹œìŠ¤í…œì€ LangGraph ê¸°ë°˜ Agent 3ì¢…ìœ¼ë¡œ êµ¬ì„±ë˜ë©°, ê° AgentëŠ” ì—­í• ë³„ë¡œ ë¶„ë¦¬ë˜ì–´ í˜‘ë ¥í•œë‹¤.
# - ëª¨ë“  ë°ì´í„°ëŠ” data/ ë””ë ‰í† ë¦¬ í•˜ì— JSON íŒŒì¼ë¡œ ê´€ë¦¬ëœë‹¤.
# - ì‹œìŠ¤í…œì€ ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ **ì‘ì‹œì(í•™ìƒ)**ì¸ì§€ êµìˆ˜ì¸ì§€ ì‹ë³„í•˜ë©°, ì´ì— ë”°ë¼ ë¶„ê¸°ëœ ì²˜ë¦¬ ë¡œì§ì„ ìˆ˜í–‰í•œë‹¤.
# 
# ### íŒŒì¼ ë°ì´í„° êµ¬ì¡°
# 
# 1. `quizzes.json` : ë¬¸ì œì€í–‰ í€´ì¦ˆë¡œ, ì„ ë‹¤í˜•(multiple_choice)ì¸ ê²½ìš° ì„ íƒì§€(choices)ë¥¼ ê°–ê²Œ ëœë‹¤.
# 
# ```json
# [
#   {
#     "id": "Q001",
#     "type": "short_answer",
#     "question": "ì½”ë‚œì˜ ë³¸ëª…ì€ ë¬´ì—‡ì¸ê°€ìš”?",
#     "answer": "ì¿ ë„ ì‹ ì´ì¹˜"
#   },
#   {
#     "id": "Q002",
#     "type": "multiple_choice",
#     "question": "ë‹¤ìŒ ì¤‘ ì½”ë‚œì´ ì‚¬ìš©í•˜ëŠ” ìŒì„± ë³€ì¡°ê¸° ë°œëª…ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?",
#     "choices": ["ì•„ê°€ì‚¬ íˆë¡œì‹œ ë°•ì‚¬", "í•˜ì‹œë°” ë§ˆì‚¬ë£¨", "í•˜ì´ë°”ë¼ ì•„ì´", "ëª¨ë¦¬ ì½”ê³ ë¡œ"],
#     "answer": "ì•„ê°€ì‚¬ íˆë¡œì‹œ ë°•ì‚¬"
#   }
# ]
# ```
# 
# 2. `applicants.json` : ì‘ì‹œì ì •ë³´
# 
# ```json
# [
# 	{
# 		"class": "1ë°˜",
# 		"name": "í™ê¸¸ë™",
# 		"student_id": "S25B001",
# 		"phone": "010-1234-5678"
# 	}
# ]
# ```
# 
# 3. `results/{YYYY-MM-DD}/{class}/result.json`: ì‘ì‹œ ê²°ê³¼ ì €ì¥
# 
# ```json
# [
#   {
#     "student_id": "S25B001",
#     "name": "í™ê¸¸ë™",
#     "score": 8,
#     "answers": [
#       {"quiz_id": "Q001", "user_answer": "ì‹ ì´ì¹˜", "is_correct": true},
#       ...
#     ]
#   }
# ]
# ```
#  
# 
# ### ì—ì´ì „íŠ¸ ì •ì˜ ë° ê¸°ëŠ¥
# 
# 1. Applicant Agent : 
#     * ì—­í• : ì‘ì‹œì ì •ë³´ ì²˜ë¦¬ ë° í€´ì¦ˆ ì‹œì‘ ìš”ì²­ ìŠ¹ì¸
#     * ì…ë ¥: ì‚¬ìš©ì ì…ë ¥ ë¬¸ì¥ (ì˜ˆ: â€œ1ë°˜ ê¹€ì˜í¬ S25B002 010-0000-0000â€)
#     * ê¸°ëŠ¥:
#         - LLMì„ í†µí•´ ë¬¸ì¥ì—ì„œ class, name, student_id, phone ì •ë³´ë¥¼ ì¶”ì¶œ
#         - applicants.jsonê³¼ ëŒ€ì¡°í•˜ì—¬ ì‘ì‹œì ì¡´ì¬ ì—¬ë¶€ ë° ì‘ì‹œ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
#         - ì´ë¯¸ ì‘ì‹œí•œ ê²½ìš° results/{ë‚ ì§œ}/{ë°˜}/result.jsonì—ì„œ í•´ë‹¹ í•™ìƒ ID í™•ì¸í•˜ì—¬ ì˜¤ë¥˜ ë©”ì‹œì§€ ì „ì†¡
#     * ì¶œë ¥: í€´ì¦ˆ Agentë¡œ ì „ë‹¬í•  ì‘ì‹œì ì •ë³´ ê°ì²´ ë°˜í™˜ ë˜ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€
# 
# 2. Quiz Agent : 
#     * ì—­í• : í€´ì¦ˆ ì¶œì œ, ì‘ë‹µ ìˆ˜ì§‘, LLM ì±„ì 
#     * ì…ë ¥: ì¸ì¦ëœ ì‘ì‹œì ì •ë³´
#     * ê¸°ëŠ¥:
#         - quizzes.jsonì—ì„œ 10ê°œì˜ ëœë¤ ë¬¸ì œ ì„ íƒ (quiz_id í¬í•¨)
#         - í€´ì¦ˆ ì‹œì‘ í›„ 10ë¬¸ì œ ìˆœì°¨ ì¶œì œ ë° ì‚¬ìš©ì ì‘ë‹µ ìˆ˜ì§‘
#         - ì‘ë‹µ ì™„ë£Œ ì‹œ, ë‹¤ìŒ ì •ë³´ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ì±„ì  ìˆ˜í–‰í•˜ê³  ì±„ì  ê²°ê³¼ ì €ì¥: ì ìˆ˜, ì •ì˜¤í‘œ, ì‘ì‹œì ì •ë³´
#         ```json
#         {
#           "student": { ... },
#           "quiz": [{ "id": "Q001", "question": "...", "answer": "...", "user_answer": "..." }, ...]
#         }
# 				```
#     * ì¶œë ¥: results/{YYYY-MM-DD}/{class}/result.jsonì— ëˆ„ì  ì €ì¥
# 
# 3. Report Agent : 
#     * ì—­í• : êµìˆ˜ì˜ ìš”ì²­ì— ë”°ë¼ ë°˜ë³„ ì˜¤ë‹µ ë° ì„±ì  ë¦¬í¬íŠ¸ ì¶œë ¥
#     * ì…ë ¥: êµìˆ˜ ì…ë ¥ (ì˜ˆ: â€œ2025-07-07 2ë°˜ ë¦¬í¬íŠ¸ ì¶œë ¥â€)
#     * ê¸°ëŠ¥:
# 		    - ì‘ì‹œì¼ì ë° ë°˜ì— ë”°ë¼ ì €ì¥ëœ ê²°ê³¼ íŒŒì¼ ë¡œë”©
#         - ë¦¬í¬íŠ¸ ìœ í˜•ì— ë”°ë¼ ë‹¤ìŒ ìˆ˜í–‰: ì˜¤ë‹µ ë¦¬í¬íŠ¸(ë¬¸ì œë³„ ì˜¤ë‹µë¥  ì§‘ê³„ í›„ ë†’ì€ ìˆœì„œë¡œ ì •ë ¬), ì„±ì  ìˆœìœ„ ë¦¬í¬íŠ¸(ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì‘ì‹œì ì •ë ¬)
#         - LLM ë˜ëŠ” íŒŒì´ì¬ ë‚´ì¥ ë¡œì§ì„ í™œìš©í•˜ì—¬ í‘œ í˜•íƒœ ì¶œë ¥
#     * ì¶œë ¥: Markdown ë˜ëŠ” Gradio-friendly í‘œ í˜•íƒœì˜ ì‘ë‹µ ë¦¬í¬íŠ¸

# ## AI Agent êµ¬í˜„
# 
# ### 1. ì´ˆê¸° ì„¤ì •

# In[40]:


import gradio as gr
import random
import json
import os
import datetime
from dotenv import load_dotenv
from typing import List, TypedDict, Literal, Optional

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
from langchain_core.output_parsers import PydanticOutputParser
from langgraph.graph import StateGraph, END

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# íŒŒì¼ ê²½ë¡œ ë° í€´ì¦ˆ ê°œìˆ˜ ì„¤ì •
QUIZ_FILE = "data/quizzes.json"
APPLICANTS_FILE = "data/applicants.json"
RESULTS_DIR = "results"
QUIZ_COUNT = 3  # ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ 10ë¬¸ì œë¡œ ì„¤ì •

# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)


# ### 2. ë°ì´í„° ëª¨ë¸ ì •ì˜

# In[41]:


# Pydantic ëª¨ë¸ ì •ì˜
class UserType(BaseModel):
    """ì‚¬ìš©ì ìœ í˜• ë¶„ë¥˜ë¥¼ ìœ„í•œ Pydantic ëª¨ë¸"""
    user_type: Literal["student", "professor", "unknown"] = Field(description="ì‚¬ìš©ìì˜ ìœ í˜•. 'student', 'professor', 'unknown' ì¤‘ í•˜ë‚˜")


class ApplicantInfo(BaseModel):
    """ì‘ì‹œì ì •ë³´ ì¶”ì¶œì„ ìœ„í•œ Pydantic ëª¨ë¸"""
    class_name: str = Field(description="ì‘ì‹œìì˜ ë°˜. ì˜ˆ: '1ë°˜'")
    name: str = Field(description="ì‘ì‹œìì˜ ì´ë¦„. ì˜ˆ: 'í™ê¸¸ë™'")
    student_id: str = Field(description="ì‘ì‹œìì˜ í•™ë²ˆ. ì˜ˆ: 'S25B001'")
    phone: str = Field(description="ì‘ì‹œìì˜ ì „í™”ë²ˆí˜¸. ì˜ˆ: '010-1234-5678'")


class ReportRequest(BaseModel):
    """ë¦¬í¬íŠ¸ ìš”ì²­ ë¶„ì„ì„ ìœ„í•œ Pydantic ëª¨ë¸"""
    date: str = Field(description="ì¡°íšŒí•  ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)")
    class_name: str = Field(description="ì¡°íšŒí•  ë°˜ ì´ë¦„ (ì˜ˆ: '1ë°˜', '2ë°˜')")
    report_type: Literal["ì„±ì ", "ì˜¤ë‹µ"] = Field(description="ìš”ì²­í•œ ë¦¬í¬íŠ¸ì˜ ì¢…ë¥˜")


class GradingResult(BaseModel):
    """ê°œë³„ ë¬¸ì œ ì±„ì  ê²°ê³¼"""
    quiz_id: str
    question: str
    correct_answer: str
    user_answer: str
    is_correct: bool
    explanation: str


class FinalReport(BaseModel):
    """ì „ì²´ í€´ì¦ˆì— ëŒ€í•œ ìµœì¢… ë¦¬í¬íŠ¸"""
    results: List[GradingResult]
    total_score: str


# ### 3. Graph ìƒíƒœ ì •ì˜

# In[42]:


# LangGraphì˜ ìƒíƒœ(State) ì •ì˜
class SystemState(TypedDict):
    user_type: Optional[Literal["student", "professor", "unknown"]]
    user_input: str
    chat_history: List[tuple]
    
    # í•™ìƒ ê´€ë ¨ ìƒíƒœ
    applicant_info: Optional[ApplicantInfo]
    is_applicant_valid: bool
    validation_message: str
    questions: List[dict]
    user_answers: List[str]
    quiz_index: int
    final_report: Optional[FinalReport]

    # êµìˆ˜ ê´€ë ¨ ìƒíƒœ
    report_request: Optional[ReportRequest]
    report_output: Optional[str]


# ### 4. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ë°ì´í„° ë¡œë”© ë° ì €ì¥)

# In[43]:


# í—¬í¼ í•¨ìˆ˜ (ë°ì´í„° ë¡œë”©/ì €ì¥)

def load_json(file_path):
    """JSON íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    if not os.path.exists(file_path):
        return None
    with open(file_path, "r", encoding="utf-8") as f:
        return json.load(f)

def save_json(data, file_path):
    """JSON ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    os.makedirs(os.path.dirname(file_path), exist_ok=True)
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def load_quiz():
    """í€´ì¦ˆ íŒŒì¼ì—ì„œ ëœë¤ ë¬¸ì œë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    all_q = load_json(QUIZ_FILE)
    if not all_q: return []
    # í€´ì¦ˆ ê°œìˆ˜ê°€ QUIZ_COUNT ë¯¸ë§Œì¼ ê²½ìš° ê°€ëŠ¥í•œ ë§Œí¼ë§Œ ìƒ˜í”Œë§
    count = min(len(all_q), QUIZ_COUNT)
    return random.sample(all_q, count)


# ### 5. Agent ë…¸ë“œ í•¨ìˆ˜ ì •ì˜
# 
# - `route_user_type` : ì‚¬ìš©ì ì…ë ¥ ë¶„ì„

# In[44]:


def route_user_type(state: SystemState) -> Literal["student_flow", "professor_flow", "unknown_flow"]:
    """ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ í•™ìƒ, êµìˆ˜, ë˜ëŠ” ì•Œ ìˆ˜ ì—†ëŠ” ìš”ì²­ìœ¼ë¡œ ë¼ìš°íŒ…"""
    parser = PydanticOutputParser(pydantic_object=UserType)
    
    # LLMì´ ì—­í• ì„ ë” ì˜ ì´í•´í•˜ë„ë¡ ì˜ˆì‹œ(Few-shot)ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ë¡œ ìˆ˜ì •
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ì‚¬ìš©ì ìœ í˜•ì„ ë¶„ë¥˜í•˜ëŠ” ë§¤ìš° ì •í™•í•œ ë¼ìš°í„°ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë³´ê³  'student', 'professor', 'unknown' ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

## ë¶„ë¥˜ ê¸°ì¤€:
1. 'student': ë°˜, ì´ë¦„, í•™ë²ˆ ë“± ê°œì¸ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ í€´ì¦ˆ ì‘ì‹œë¥¼ ì‹œë„í•˜ëŠ” ê²½ìš°.
2. 'professor': ë‚ ì§œ, ë°˜ ì´ë¦„, 'ë¦¬í¬íŠ¸' ë˜ëŠ” 'ì„±ì 'ê³¼ ê°™ì€ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ì—¬ ê²°ê³¼ë¥¼ ì¡°íšŒí•˜ë ¤ëŠ” ê²½ìš°.
3. 'unknown': ìœ„ ë‘ ê²½ìš°ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ëª¨ë“  ì• ë§¤í•œ ê²½ìš°.

## ì˜ˆì‹œ:
- ì…ë ¥: "1ë°˜ ê¹€ì½”ë‚œ S25B007 010-1111-2222"
  ë¶„ë¥˜: 'student'
- ì…ë ¥: "2025-07-07 2ë°˜ ì„±ì  ìˆœìœ„ ë¦¬í¬íŠ¸ ì¢€ ë³´ì—¬ì¤˜"
  ë¶„ë¥˜: 'professor'
- ì…ë ¥: "ì•ˆë…•í•˜ì„¸ìš”"
  ë¶„ë¥˜: 'unknown'
- ì…ë ¥: "í€´ì¦ˆë¥¼ í’€ê³  ì‹¶ì–´ìš”."
  ë¶„ë¥˜: 'unknown' (í€´ì¦ˆ ì‘ì‹œë¥¼ ì›í•˜ì§€ë§Œ, ì‹ë³„ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ 'unknown' ì²˜ë¦¬ í›„ ì•ˆë‚´)
"""),
        ("human", "ì‚¬ìš©ì ì…ë ¥: {user_input}\n\n{format_instructions}")
    ])
    chain = prompt | llm | parser
    
    try:
        result = chain.invoke({"user_input": state["user_input"], "format_instructions": parser.get_format_instructions()})
        user_type = result.user_type
    except Exception as e:
        print(f"ë¼ìš°íŒ… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        user_type = "unknown"

    state["user_type"] = user_type
    # state['chat_history'].append(('system', f"ë¼ìš°íŒ… ê²°ê³¼: {user_type}")) # ë””ë²„ê¹…ìš© ë¡œê·¸
    
    if user_type == "student":
        return "student_flow"
    elif user_type == "professor":
        return "professor_flow"
    else:
        return "unknown_flow"


# - Applicant Agent Nodes

# In[45]:


def extract_applicant_info(state: SystemState) -> SystemState:
    """LLMì„ ì‚¬ìš©í•´ ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì‘ì‹œì ì •ë³´ë¥¼ ì¶”ì¶œ"""
    parser = PydanticOutputParser(pydantic_object=ApplicantInfo)
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ë‹¹ì‹ ì€ ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œê¸°ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì¥ì—ì„œ ë°˜, ì´ë¦„, í•™ë²ˆ, ì „í™”ë²ˆí˜¸ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”."),
        ("human", "ì‚¬ìš©ì ì •ë³´: {user_input}\n{format_instructions}")
    ])
    chain = prompt | llm | parser
    try:
        info = chain.invoke({"user_input": state["user_input"], "format_instructions": parser.get_format_instructions()})
        state["applicant_info"] = info
    except Exception as e:
        state["validation_message"] = f"ì •ë³´ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì…ë ¥ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”. (ì˜¤ë¥˜: {e})"
        state["applicant_info"] = None
    return state

def validate_applicant(state: SystemState) -> SystemState:
    """ì¶”ì¶œëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì‹œì ìê²© ê²€ì¦"""
    if not state["applicant_info"]:
        state["is_applicant_valid"] = False
        return state

    info = state["applicant_info"]
    applicants = load_json(APPLICANTS_FILE)
    if not applicants:
        state["is_applicant_valid"] = False
        state["validation_message"] = "ì˜¤ë¥˜: ì‘ì‹œì ëª…ë‹¨ íŒŒì¼(applicants.json)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        return state

    is_registered = any(
        str(app["student_id"]) == str(info.student_id) and \
        app["name"] == info.name and \
        str(app["class"]) == str(info.class_name)
        for app in applicants
    )

    if not is_registered:
        state["is_applicant_valid"] = False
        state["validation_message"] = "ë“±ë¡ë˜ì§€ ì•Šì€ ì‘ì‹œìì…ë‹ˆë‹¤. ë°˜, ì´ë¦„, í•™ë²ˆì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”."
        return state
    
    today = datetime.date.today().strftime("%Y-%m-%d")
    result_path = os.path.join(RESULTS_DIR, today, str(info.class_name), "result.json")
    
    results_today = load_json(result_path)
    if results_today and any(str(res["student_id"]) == str(info.student_id) for res in results_today):
        state["is_applicant_valid"] = False
        state["validation_message"] = f"{info.name}ë‹˜ì€ ì˜¤ëŠ˜ ì´ë¯¸ í€´ì¦ˆì— ì‘ì‹œí•˜ì…¨ìŠµë‹ˆë‹¤. ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        return state

    state["is_applicant_valid"] = True
    state["validation_message"] = f"ì¸ì¦ë˜ì—ˆìŠµë‹ˆë‹¤. {info.name}ë‹˜, í€´ì¦ˆë¥¼ ì‹œì‘í•©ë‹ˆë‹¤!"
    return state

def handle_validation_result(state: SystemState) -> SystemState:
    """ê²€ì¦ ê²°ê³¼ë¥¼ chat_historyì— ì¶”ê°€"""
    state["chat_history"].append(("assistant", state["validation_message"]))
    return state

def decide_to_start_quiz(state: SystemState) -> str:
    """ì‘ì‹œì ê²€ì¦ ê²°ê³¼ì— ë”°ë¼ í€´ì¦ˆ ì‹œì‘ ì—¬ë¶€ ê²°ì •"""
    return "start_quiz" if state["is_applicant_valid"] else "end_student_flow"


# - Quiz Agent Nodes

# In[46]:


def start_quiz(state: SystemState) -> SystemState:
    questions = load_quiz()
    if not questions:
        state["chat_history"].append(("assistant", "í€´ì¦ˆë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."))
        state["questions"] = []
    else:
        state["questions"] = questions
        state["quiz_index"] = 0
        state["user_answers"] = []
    return state

def ask_question(state: SystemState) -> SystemState:
    idx = state["quiz_index"]
    q = state["questions"][idx]
    text = f"ë¬¸ì œ {idx + 1}/{len(state['questions'])}: {q['question']}"
    if q["type"] == "multiple_choice":
        choices = [f"{i + 1}. {c}" for i, c in enumerate(q["choices"])]
        text += "\n" + "\n".join(choices)
    state["chat_history"].append(("assistant", text))
    state["user_input"] = "" # ì´ì „ ì‚¬ìš©ì ì…ë ¥ ì´ˆê¸°í™”
    return state

def process_and_store_answer(state: SystemState) -> SystemState:
    """í€´ì¦ˆ ë‹µë³€ ì²˜ë¦¬ ë° ì €ì¥"""
    idx = state["quiz_index"]
    q = state["questions"][idx]
    user_input = state["user_input"].strip()

    processed_answer = user_input
    if q["type"] == "multiple_choice":
        try:
            sel = int(user_input) - 1
            if 0 <= sel < len(q["choices"]):
                processed_answer = q["choices"][sel]
        except (ValueError, IndexError):
            pass # ìˆ«ìê°€ ì•„ë‹ˆê±°ë‚˜ ë²”ìœ„ ë°–ì´ë©´ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë‹µë³€ìœ¼ë¡œ ê°„ì£¼

    state["user_answers"].append(processed_answer)
    state["quiz_index"] += 1
    return state

def should_continue_quiz(state: SystemState) -> str:
    """í€´ì¦ˆ ê³„ì† ì§„í–‰ ë˜ëŠ” ì±„ì  ì‹œì‘ ê²°ì •"""
    if state.get("quiz_index", 0) < len(state.get("questions", [])):
        return "ask_question"
    else:
        return "grade_quiz"

# grade_and_save_results í•¨ìˆ˜ë¥¼ ì•„ë˜ ë‚´ìš©ìœ¼ë¡œ êµì²´

def grade_and_save_results(state: SystemState) -> SystemState:
    """LLMìœ¼ë¡œ ì±„ì í•˜ê³  ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥"""
    # 1. ì±„ì  í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
    grading_input_parts = []
    for i, (q, a) in enumerate(zip(state["questions"], state["user_answers"])):
        part = (f"ë¬¸ì œ {i+1}:\n"
                f"ID: {q['id']}\n"
                f"ì§ˆë¬¸: {q['question']}\n"
                f"ì •ë‹µ: {q['answer']}\n"
                f"ì‚¬ìš©ì ë‹µë³€: {a}\n---")
        grading_input_parts.append(part)
    grading_input_str = "\n".join(grading_input_parts)

    # 2. LLM ì±„ì 
    parser = PydanticOutputParser(pydantic_object=FinalReport)
    system_message = "ë‹¹ì‹ ì€ 'ëª…íƒì • ì½”ë‚œ' í€´ì¦ˆ ì „ë¬¸ ì±„ì ê´€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì œ, ì •ë‹µ, ì‚¬ìš©ì ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ì±„ì í•˜ê³ , ê° ë¬¸ì œì˜ IDë¥¼ í¬í•¨í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì„¸ìš”. ì •ë‹µ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê³  ì¹œì ˆí•œ í•´ì„¤ì„ ë§ë¶™ì—¬ì£¼ì„¸ìš”. ë§ˆì§€ë§‰ì—ëŠ” 'ì´ì : X/Y' í˜•ì‹ìœ¼ë¡œ ìµœì¢… ì ìˆ˜ë¥¼ ìš”ì•½í•´ì•¼ í•©ë‹ˆë‹¤."
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_message),
        ("human", "{grading_data}\n\n{format_instructions}")
    ])
    chain = prompt | llm | parser

    try:
        report = chain.invoke({
            "grading_data": grading_input_str,
            "format_instructions": parser.get_format_instructions(),
        })
        state["final_report"] = report
        
        # 3. ê²°ê³¼ ì €ì¥
        today = datetime.date.today().strftime("%Y-%m-%d")
        info = state["applicant_info"]
        result_path = os.path.join(RESULTS_DIR, today, str(info.class_name), "result.json")
        
        all_results = load_json(result_path) or []
        score = sum(1 for res in report.results if res.is_correct)

        # ìƒˆ ê²°ê³¼ ë°ì´í„° ìƒì„±
        new_result = {
            "student_id": info.student_id,
            "name": info.name,
            "score": score,
            "answers": [res.model_dump() for res in report.results]
        }
        all_results.append(new_result)
        save_json(all_results, result_path)

    except Exception as e:
        print(f"ì±„ì  ë° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        state["final_report"] = FinalReport(results=[], total_score="ì±„ì  ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        state["chat_history"].append(("assistant", "ì±„ì  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ê²°ê³¼ë¥¼ ì €ì¥í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."))

    return state

def format_final_report(state: SystemState) -> SystemState:
    """ìµœì¢… ì±„ì  ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ê¸° ìœ„í•´ í¬ë§·íŒ…"""
    report = state["final_report"]
    parts = ["ì±„ì ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰\n"]
    if report and report.results:
        for i, res in enumerate(report.results):
            is_correct_text = "âœ… ì •ë‹µ" if res.is_correct else "âŒ ì˜¤ë‹µ"
            parts.append(f"--- ë¬¸ì œ {i + 1} ---\n"
                         f"ë¬¸ì œ: {res.question}\n"
                         f"ì •ë‹µ: {res.correct_answer}\n"
                         f"ì œì¶œí•œ ë‹µë³€: {res.user_answer}\n"
                         f"ê²°ê³¼: {is_correct_text}\n"
                         f"í•´ì„¤: {res.explanation}\n")
        parts.append(f"**{report.total_score}**")
    else:
        parts.append("ì±„ì  ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    parts.append("\n\nìƒˆë¡œìš´ ì‘ì‹œìëŠ” ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: 1ë°˜ í™ê¸¸ë™ S25B001 010-1234-5678)")
    state["chat_history"].append(("assistant", "\n".join(parts)))
    return state


# - Report Agent Nodes

# In[47]:


def decide_to_generate_report(state: SystemState) -> str:
    """ë¦¬í¬íŠ¸ ìš”ì²­ì´ ìœ íš¨í•œì§€ í™•ì¸í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
    if state.get("report_request"):
        return "generate_report"
    else:
        return "display_report"

def extract_report_request(state: SystemState) -> SystemState:
    """LLMì„ ì‚¬ìš©í•´ ë¦¬í¬íŠ¸ ìš”ì²­ ì •ë³´ ì¶”ì¶œ"""
    parser = PydanticOutputParser(pydantic_object=ReportRequest)
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ êµìˆ˜ë‹˜ì˜ ë¦¬í¬íŠ¸ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” ì •í™•í•œ ë¹„ì„œì…ë‹ˆë‹¤.
ìš”ì²­ì—ì„œ ë‚ ì§œ(YYYY-MM-DD), ë°˜ ì´ë¦„, ê·¸ë¦¬ê³  ë¦¬í¬íŠ¸ ì¢…ë¥˜ë¥¼ ì •í™•íˆ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
ë¦¬í¬íŠ¸ ì¢…ë¥˜(report_type)ëŠ” ë°˜ë“œì‹œ "ì„±ì " ë˜ëŠ” "ì˜¤ë‹µ" ë‘ ê°€ì§€ ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.

## ì˜ˆì‹œ:
- ì…ë ¥: "ì˜¤ëŠ˜ 2ë°˜ ì„±ì  ìˆœìœ„ ë¦¬í¬íŠ¸ ì¢€ ë³´ì—¬ì¤˜" (ì˜¤ëŠ˜ì´ 2025-07-07ì´ë¼ê³  ê°€ì •)
  ì¶”ì¶œ: {{"date": "2025-07-07", "class_name": "2ë°˜", "report_type": "ì„±ì "}}
- ì…ë ¥: "2025-07-06 1ë°˜ ì˜¤ë‹µ ë¦¬í¬íŠ¸"
  ì¶”ì¶œ: {{"date": "2025-07-06", "class_name": "1ë°˜", "report_type": "ì˜¤ë‹µ"}}
- ì…ë ¥: "1ë°˜ ì„±ì "
  ì¶”ì¶œ: (ë‚ ì§œ ì •ë³´ê°€ ì—†ì–´ ì‹¤íŒ¨í•´ì•¼ í•¨)
"""),
        ("human", "ì˜¤ëŠ˜ ë‚ ì§œ: {today}\nêµìˆ˜ë‹˜ ìš”ì²­: {user_input}\n\n{format_instructions}")
    ])
    chain = prompt | llm | parser
    try:
        today_str = datetime.date.today().strftime("%Y-%m-%d")
        req = chain.invoke({
            "today": today_str,
            "user_input": state["user_input"], 
            "format_instructions": parser.get_format_instructions()
        })
        state["report_request"] = req
    except Exception as e:
        state["report_output"] = f"ë¦¬í¬íŠ¸ ìš”ì²­ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. 'YYYY-MM-DD Në°˜ [ì„±ì  ìˆœìœ„/ì˜¤ë‹µ ë¦¬í¬íŠ¸]' í˜•ì‹ìœ¼ë¡œ ìš”ì²­í•´ì£¼ì„¸ìš”. (ì˜¤ë¥˜: {e})"
        state["report_request"] = None
    return state

# generate_report í•¨ìˆ˜ë¥¼ ì•„ë˜ ë‚´ìš©ìœ¼ë¡œ êµì²´í•©ë‹ˆë‹¤.

def generate_report(state: SystemState) -> SystemState:
    """ìš”ì²­ì— ë”°ë¼ ë¦¬í¬íŠ¸ë¥¼ ìƒì„± (ì˜¤ë‹µ ë¦¬í¬íŠ¸ì— 'ì •ë‹µ' ì»¬ëŸ¼ ì¶”ê°€)"""
    # 1. ì–´ë–¤ ê²½ìš°ì—ë„ KeyErrorê°€ ë°œìƒí•˜ì§€ ì•Šë„ë¡ ê¸°ë³¸ ì˜¤ë¥˜ ë©”ì‹œì§€ë¡œ 'report_output'ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    state["report_output"] = "ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    try:
        # 2. ë¡œì§ ì‹œì‘: report_request í‚¤ê°€ ìˆëŠ”ì§€ ë‹¤ì‹œ í•œë²ˆ í™•ì¸ (ë°©ì–´ì  ì½”ë”©)
        if not state.get("report_request"):
            state["report_output"] = "ë¦¬í¬íŠ¸ ìš”ì²­ ì •ë³´ê°€ ì—†ì–´ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            return state

        req = state["report_request"]
        result_path = os.path.join(RESULTS_DIR, req.date, req.class_name, "result.json")
        data = load_json(result_path)

        if not data:
            state["report_output"] = f"{req.date}ì˜ {req.class_name} ì‘ì‹œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            return state

        # 3. ë¦¬í¬íŠ¸ ìœ í˜•ì— ë”°ë¼ ìƒì„±
        if req.report_type == "ì„±ì ":
            sorted_data = sorted(data, key=lambda x: x["score"], reverse=True)
            report_lines = [f"### {req.date} {req.class_name} ì„±ì  ìˆœìœ„ ë¦¬í¬íŠ¸\n",
                            "| ìˆœìœ„ | í•™ë²ˆ | ì´ë¦„ | ì ìˆ˜ |",
                            "|:---:|:---:|:---:|:---:|"]
            total_questions = len(sorted_data[0]['answers']) if sorted_data else 0
            for i, student in enumerate(sorted_data):
                report_lines.append(f"| {i+1} | {student['student_id']} | {student['name']} | {student['score']}/{total_questions} |")
            state["report_output"] = "\n".join(report_lines)

        elif req.report_type == "ì˜¤ë‹µ":
            # --- 'ì˜¤ë‹µ ë¦¬í¬íŠ¸' ë¡œì§ ìˆ˜ì • ì‹œì‘ ---
            quiz_errors = {}
            total_students = len(data)
            for student in data:
                for answer in student["answers"]:
                    if not answer["is_correct"]:
                        qid = answer["quiz_id"]
                        if qid not in quiz_errors:
                            # [ìˆ˜ì • 1] 'correct_answer'ë„ í•¨ê»˜ ì €ì¥
                            quiz_errors[qid] = {
                                "question": answer["question"],
                                "correct_answer": answer["correct_answer"], 
                                "count": 0
                            }
                        quiz_errors[qid]["count"] += 1
            
            sorted_errors = sorted(quiz_errors.items(), key=lambda item: item[1]["count"], reverse=True)
            
            # [ìˆ˜ì • 2] í…Œì´ë¸” í—¤ë”ì— 'ì •ë‹µ' ì»¬ëŸ¼ ì¶”ê°€
            report_lines = [f"### {req.date} {req.class_name} ì˜¤ë‹µë¥  TOP 3 ë¦¬í¬íŠ¸ (ì´ {total_students}ëª… ì‘ì‹œ)\n",
                            "| ìˆœìœ„ | ë¬¸ì œ | ì •ë‹µ | ì˜¤ë‹µì ìˆ˜ | ì˜¤ë‹µë¥  |",
                            "|:---:|:---|:---|:---:|:---:|"]
            
            if not sorted_errors:
                report_lines.append("| - | ì˜¤ë‹µì´ ê¸°ë¡ëœ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤. | - | - | - |")
            else:
                for i, (qid, details) in enumerate(sorted_errors[:3]):
                    error_rate = (details['count'] / total_students) * 100
                    # [ìˆ˜ì • 3] í…Œì´ë¸” í–‰ì— 'correct_answer' ë‚´ìš© ì¶”ê°€
                    report_lines.append(f"| {i+1} | {details['question']} | {details['correct_answer']} | {details['count']}ëª… | {error_rate:.1f}% |")
            
            state["report_output"] = "\n".join(report_lines)
            # --- 'ì˜¤ë‹µ ë¦¬í¬íŠ¸' ë¡œì§ ìˆ˜ì • ë ---

        else:
            state["report_output"] = f"ì•Œ ìˆ˜ ì—†ëŠ” ë¦¬í¬íŠ¸ ìœ í˜•ì…ë‹ˆë‹¤: '{req.report_type}'. ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."

    except Exception as e:
        print(f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        state["report_output"] = f"ë¦¬í¬íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ì˜¤ë¥˜: {e})"

    return state

def display_report(state: SystemState) -> SystemState:
    """ìƒì„±ëœ ë¦¬í¬íŠ¸ë¥¼ chat_historyì— ì¶”ê°€"""
    state["chat_history"].append(("assistant", state["report_output"]))
    return state


# - handle_unknown_request nodes

# In[48]:


def handle_unknown_request(state: SystemState) -> SystemState:
    """ì•Œ ìˆ˜ ì—†ëŠ” ìš”ì²­ ì²˜ë¦¬"""
    message = "ìš”ì²­ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n" \
              "í€´ì¦ˆì— ì‘ì‹œí•˜ì‹œë ¤ë©´ '1ë°˜ í™ê¸¸ë™ S25B001 010-1234-5678'ê³¼ ê°™ì´ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n" \
              "ë¦¬í¬íŠ¸ê°€ í•„ìš”í•˜ì‹œë©´ '2025-07-07 1ë°˜ ì„±ì  ìˆœìœ„ ë¦¬í¬íŠ¸'ì™€ ê°™ì´ ìš”ì²­í•´ì£¼ì„¸ìš”."
    state["chat_history"].append(("assistant", message))
    return state


# ### LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±

# In[49]:


workflow = StateGraph(SystemState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("extract_applicant_info", extract_applicant_info)
workflow.add_node("validate_applicant", validate_applicant)
workflow.add_node("handle_validation_result", handle_validation_result)
workflow.add_node("start_quiz", start_quiz)
workflow.add_node("ask_question", ask_question)
workflow.add_node("process_answer", process_and_store_answer)
workflow.add_node("grade_and_save", grade_and_save_results)
workflow.add_node("format_final_report", format_final_report)
workflow.add_node("extract_report_request", extract_report_request)
workflow.add_node("generate_report", generate_report)
workflow.add_node("display_report", display_report)
workflow.add_node("handle_unknown_request", handle_unknown_request)

# ì§„ì…ì  ì„¤ì • (ì‚¬ìš©ì ìœ í˜•ì— ë”°ë¼ ë¶„ê¸°)
workflow.set_conditional_entry_point(
    route_user_type,
    {
        "student_flow": "extract_applicant_info",
        "professor_flow": "extract_report_request",
        "unknown_flow": "handle_unknown_request",
    }
)

# í•™ìƒ(Student) ì›Œí¬í”Œë¡œìš° ì—£ì§€ ì—°ê²°
workflow.add_edge("extract_applicant_info", "validate_applicant")
workflow.add_edge("validate_applicant", "handle_validation_result")
workflow.add_conditional_edges(
    "handle_validation_result",
    decide_to_start_quiz,
    {"start_quiz": "start_quiz", "end_student_flow": END}
)
workflow.add_edge("start_quiz", "ask_question")
# í€´ì¦ˆ ë£¨í”„: ë‹µë³€ì„ ë°›ìœ¼ë©´ ë‹¤ìŒ ë¬¸ì œë¡œ ê°€ê±°ë‚˜ ì±„ì ìœ¼ë¡œ ë„˜ì–´ê°
workflow.add_node("router_after_answer", lambda state: state) # Dummy node
workflow.add_edge("process_answer", "router_after_answer")
workflow.add_conditional_edges(
    "router_after_answer",
    should_continue_quiz,
    {"ask_question": "ask_question", "grade_quiz": "grade_and_save"}
)
workflow.add_edge("ask_question", END) # í€´ì¦ˆ ì§ˆë¬¸ í›„ ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë‹¤ë¦¼
workflow.add_edge("grade_and_save", "format_final_report")
workflow.add_edge("format_final_report", END)

# Professor(êµìˆ˜) ì›Œí¬í”Œë¡œìš° ì—£ì§€ ì—°ê²°
workflow.add_conditional_edges(
    "extract_report_request",  # ì‹œì‘ ë…¸ë“œ
    decide_to_generate_report, # íŒë‹¨ í•¨ìˆ˜
    {
        "generate_report": "generate_report", # íŒë‹¨ ê²°ê³¼ê°€ "generate_report"ì´ë©´ generate_report ë…¸ë“œë¡œ ì´ë™
        "display_report": "display_report",   # íŒë‹¨ ê²°ê³¼ê°€ "display_report"ì´ë©´ display_report ë…¸ë“œë¡œ ì´ë™
    }
)
# ì´ì œ generate_reportëŠ” í•­ìƒ ìœ íš¨í•œ ìš”ì²­ì„ ë°›ì„ ë•Œë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤.
workflow.add_edge("generate_report", "display_report")
workflow.add_edge("display_report", END)

# ì•Œ ìˆ˜ ì—†ëŠ” ìš”ì²­ ì²˜ë¦¬
workflow.add_edge("handle_unknown_request", END)

# ê·¸ë˜í”„ ì»´íŒŒì¼
multi_agent_app = workflow.compile()


# ### ì´ˆê¸° ìƒíƒœ ì„¤ì • ë° UI ì¸í„°í˜ì´ìŠ¤ ë¡œì§

# In[50]:


def init_state():
    """ì´ˆê¸° ìƒíƒœë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    return {"system_state": {
        "chat_history": [],
        "user_input": "",
        "user_type": None
    }}

def chat_fn(user_input, state):
    """Gradio ìƒí˜¸ì‘ìš©ì„ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    system_state = state["system_state"]

    # 1. UI ìƒíƒœ(ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸)ì— ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
    # stateì— ì €ì¥ëœ chat_historyëŠ” í•­ìƒ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ë¼ê³  ê°€ì •
    chat_history_dicts = system_state.get("chat_history", [])
    if not isinstance(chat_history_dicts, list): # í˜¹ì‹œ ëª¨ë¥¼ ë¹„ì •ìƒ ìƒíƒœ ëŒ€ë¹„
        chat_history_dicts = []
    chat_history_dicts.append({"role": "user", "content": user_input})

    # 2. ë‚´ë¶€ ë¡œì§ìš© ìƒíƒœ(íŠœí”Œ ë¦¬ìŠ¤íŠ¸) ìƒì„±
    # ë‚´ë¶€ ë¡œì§(LangGraph)ì€ íŠœí”Œ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì˜ ê¸°ë¡ì„ ì‚¬ìš©
    internal_history_tuples = [(item['role'], item.get('content', '')) for item in chat_history_dicts]
    
    # ë‚´ë¶€ ë¡œì§ì— ì „ë‹¬í•  ìƒíƒœ ê°ì²´ ìƒì„±
    internal_state = {
        **system_state,
        "chat_history": internal_history_tuples,
        "user_input": user_input,
    }

    # 3. í€´ì¦ˆ ì§„í–‰ ì—¬ë¶€ì— ë”°ë¼ ë¶„ê¸°
    is_in_quiz = internal_state.get("questions") and not internal_state.get("final_report")
    if is_in_quiz:
        quiz_state = process_and_store_answer(internal_state)
        next_step = should_continue_quiz(quiz_state)
        if next_step == "ask_question":
            final_internal_state = ask_question(quiz_state)
        else: # "grade_quiz"
            graded_state = grade_and_save_results(quiz_state)
            final_internal_state = format_final_report(graded_state)
    else: # ìƒˆë¡œìš´ ìš”ì²­ (ë¼ìš°íŒ…ë¶€í„° ì‹œì‘)
        # ì´ì „ ìƒíƒœ ì´ˆê¸°í™” (ì±„íŒ… ê¸°ë¡ì€ ìœ ì§€)
        current_history = internal_state["chat_history"]
        clean_state = init_state()['system_state']
        clean_state['chat_history'] = current_history
        clean_state['user_input'] = user_input
        
        final_internal_state = multi_agent_app.invoke(clean_state)

    # 4. ìµœì¢… ìƒíƒœë¥¼ UI í˜•ì‹(ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸)ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥ ë° ë°˜í™˜
    final_chat_history_tuples = final_internal_state.get("chat_history", [])
    
    final_chat_display = []
    for role, content in final_chat_history_tuples:
        if role == "user":
            final_chat_display.append({"role": "user", "content": content})
        elif role == "assistant":
            final_chat_display.append({"role": "assistant", "content": content})
    
    # UIì— í‘œì‹œë  ê¸°ë¡ê³¼ ë‹¤ìŒ stateì— ì €ì¥ë  ê¸°ë¡ì„ ëª¨ë‘ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ìœ¼ë¡œ í†µì¼
    final_internal_state["chat_history"] = final_chat_display
    state["system_state"] = final_internal_state

    return final_chat_display, state


# ### Gradio UI êµ¬ì„±

# In[51]:


with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ë©€í‹° ì—ì´ì „íŠ¸ í€´ì¦ˆ ì‹œìŠ¤í…œ")
    gr.Markdown(
        " **ì‘ì‹œì(í•™ìƒ)** : `1ë°˜ í™ê¸¸ë™ S25B001 010-1234-5678` í˜•ì‹ìœ¼ë¡œ ì •ë³´ë¥¼ ì…ë ¥í•˜ì—¬ í€´ì¦ˆë¥¼ ì‹œì‘í•˜ì„¸ìš”.\n\n "
        " **êµìˆ˜** : `2025-07-07 1ë°˜ ì„±ì  ìˆœìœ„ ë¦¬í¬íŠ¸` í˜•ì‹ìœ¼ë¡œ ë¦¬í¬íŠ¸ë¥¼ ìš”ì²­í•˜ì„¸ìš”."
    )

    chatbot = gr.Chatbot(
        label="í€´ì¦ˆ ë° ë¦¬í¬íŠ¸ ì±—ë´‡",
        height=400,
        type="messages"
    )
    
    chatbot_display = gr.JSON(visible=False)

    txt = gr.Textbox(placeholder="ì •ë³´ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ë¦¬í¬íŠ¸ë¥¼ ìš”ì²­í•˜ì„¸ìš”...", show_label=False)
    state = gr.State(init_state())

    def update_chatbot_ui(json_data):
        return json_data

    chatbot_display.change(update_chatbot_ui, chatbot_display, chatbot)

    txt.submit(chat_fn, inputs=[txt, state], outputs=[chatbot_display, state])
    txt.submit(lambda: "", None, txt)

demo.launch()


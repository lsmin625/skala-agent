import uuid
from typing import Annotated, Optional
from typing_extensions import TypedDict

import gradio as gr
from dotenv import load_dotenv

from langchain.schema import HumanMessage, AIMessage, SystemMessage, BaseMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_teddynote.tools import GoogleNews

from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.types import Command, interrupt
from langgraph.checkpoint.memory import InMemorySaver

# =============================================================================
# 1) ì¤€ë¹„
# =============================================================================
load_dotenv()
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

google_news = GoogleNews()

@tool
def news_search(query: str) -> str:
    """Search news articles by keyword."""
    print(f"[Tool] news_search í˜¸ì¶œ: {query}")
    results = google_news.search_by_keyword(query, k=5)
    text = "\n".join(
        f"- {r.get('content','(ë‚´ìš©ì—†ìŒ)')} | {r.get('url','')}" for r in results
    ) or "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
    return text

@tool
def human_assistance(query: str) -> str:
    """Request assistance from a human (HITL)."""
    print(f"[Tool] human_assistance í˜¸ì¶œ: {query}")
    human_response = interrupt({"query": query})
    print(f"[Tool] human_assistance ì‘ë‹µ ìˆ˜ì‹ : {human_response}")
    return human_response["data"]

tools = [news_search, human_assistance]
llm_with_tools = llm.bind_tools(tools)

# =============================================================================
# 2) LangGraph ì •ì˜
# =============================================================================
class State(TypedDict):
    messages: Annotated[list, "ëŒ€í™” ë©”ì‹œì§€ ëª©ë¡", add_messages]
    interrupted: Annotated[bool, "HITLë¡œ ì¸í•´ ì¤‘ë‹¨ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€"] = False

def chatbot(state: State):
    """LLM í˜¸ì¶œ ë…¸ë“œ (íˆ´ ì½œ í¬í•¨)."""
    messages = state.get("messages", [])
    if not messages:
        return {"messages": []}
    response = llm_with_tools.invoke(messages)
    if hasattr(response, "tool_calls"):
        assert len(response.tool_calls) <= 1
    return {"messages": [response]}

graph_builder = StateGraph(State)
graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=tools)
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges("chatbot", tools_condition)
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")

memory = InMemorySaver()
graph = graph_builder.compile(checkpointer=memory)

def ensure_thread_id(thread_id: Optional[str]) -> str:
    """thread_idê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±."""
    return thread_id or str(uuid.uuid4())

def last_ai_text_from_state_output(state_output: dict) -> str:
    """ë°˜í™˜(dict)ì—ì„œ ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ."""
    msgs = state_output.get("messages", [])
    last_ai_content = None
    for m in reversed(msgs):
        print(f"[Debug] ë©”ì‹œì§€: {m}")
        if isinstance(m, AIMessage) or getattr(m, "type", "") == "ai":
            last_ai_content = m.content
            break
    return last_ai_content or ""

SYSTEM_PROMPT = SystemMessage(
    content=(
        "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³ , "
        "ì‚¬ëŒì—ê²Œ 'ì „ì²´ ëª©ë¡ ìš”ì•½', 'íŠ¹ì • ê¸°ì‚¬ ìš”ì•½' ë“±ì˜ ì¶”ê°€ ì‘ì—…ì„ ìš”ì²­(human_assistance)í•©ë‹ˆë‹¤."
    )
)

def chat_fn(user_text: str, thread_id: Optional[str], history: Optional[list[dict]]):
    """í•œ ë²ˆ ì‹¤í–‰: ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë°›ì•„ graphë¥¼ í•œ ë²ˆ ì‹¤í–‰."""
    thread_id = ensure_thread_id(thread_id)
    history = history or []
    history.append({"role": "user", "content": user_text})

    inputs = {"messages": [SYSTEM_PROMPT, HumanMessage(content=user_text)]}
    config = {"configurable": {"thread_id": thread_id}}

    try:
        # ì •ìƒ ê²½ë¡œ
        out = graph.invoke(inputs, config=config)
        ai_text = last_ai_text_from_state_output(out) or "(ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤)"
        history.append({"role": "assistant", "content": ai_text})
        return history, thread_id, None, gr.update(visible=False), gr.update(visible=True)

    except Exception as e:
        print(f"[HITL] ì˜ˆì™¸ ë°œìƒ: {type(e).__name__}: {e}")
        hitl_notice = (
            "ğŸ”” **ìŠ¹ì¸ í•„ìš”(HITL)**\n\n"
            "ì—ì´ì „íŠ¸ê°€ ì‚¬ëŒì˜ ë„ì›€ì´ í•„ìš”í•©ë‹ˆë‹¤.\n"
            "ì˜¤ë¥¸ìª½ íŒ¨ë„ì— ë‹µë³€ì„ ì…ë ¥í•˜ê³  **ì¬ê°œ(Resume)** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
        )
        history.append({"role": "assistant", "content": hitl_notice})
        # ëŒ€ê¸° ìƒíƒœ ì§„ì…(pending_queryëŠ” Noneìœ¼ë¡œ ë‘ )
        return history, thread_id, None, gr.update(visible=True), gr.update(visible=False)

def resume_with_human_input(human_text: str, thread_id: str, pending_query: Optional[str], history: Optional[list[dict]]):
    """ì¬ê°œ(Command.resume): ì‚¬ëŒì˜ ì…ë ¥ì„ resume payloadë¡œ ì „ë‹¬."""
    print(f"[HITL] ì¬ê°œ í˜¸ì¶œ: thread_id={thread_id}, pending_query={pending_query}, human_text={human_text}")

    history = history or []
    history.append({"role": "user", "content": f"[HITL ìŠ¹ì¸] {human_text}"})

    config = {"configurable": {"thread_id": thread_id}}

    try:
        resume_command = Command(resume={"data": human_text})
        out = graph.invoke(
            None,
            config=config,
            command=resume_command,
        )
        ai_text = last_ai_text_from_state_output(out) or "(ì¬ê°œ í›„ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤)"
        history.append({"role": "assistant", "content": ai_text})
    except Exception as e:
        history.append({"role": "assistant", "content": f"(ì¬ê°œ ì¤‘ ì˜¤ë¥˜) {type(e).__name__}: {e}"})

    # ì¬ê°œ ì™„ë£Œ â†’ HITL íŒ¨ë„ ë‹«ê¸°
    return history, thread_id, None, gr.update(visible=False), gr.update(visible=True)

def clear_all():
    """ëŒ€í™”/ìƒíƒœ ì´ˆê¸°í™”"""
    return [], None, None, gr.update(visible=False), gr.update(visible=True)

# =============================================================================
# 5) Gradio UI
# =============================================================================
with gr.Blocks(title="LangGraph HITL Demo") as demo:
    gr.Markdown("## LangGraph Human-in-the-Loop")
    gr.Markdown(
        "- **ë©”ì‹œì§€ ì „ì†¡**ìœ¼ë¡œ ì—ì´ì „íŠ¸ì™€ ëŒ€í™”í•©ë‹ˆë‹¤.\n"
        "- ì—ì´ì „íŠ¸ê°€ ì‚¬ëŒ ë„ì›€(`human_assistance`)ì„ ìš”ì²­í•˜ë©´ **ì¼ì‹œì¤‘ì§€**ë˜ê³ , "
        "**ìŠ¹ì¸ ì…ë ¥** í›„ **ì¬ê°œ(Resume)** ë²„íŠ¼ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.\n"
        "- **ëŒ€í™” ì´ˆê¸°í™”**ë¡œ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    with gr.Row():
        with gr.Column(scale=3):
            chat = gr.Chatbot(label="ëŒ€í™”", height=420, type="messages")
            user_input = gr.Textbox(label="ë©”ì‹œì§€ ì…ë ¥", placeholder="ì˜ˆ) ìµœì‹  AI ë‰´ìŠ¤ ê²€ìƒ‰ í•´ì¤˜")
            with gr.Row():
                send_btn = gr.Button("ë©”ì‹œì§€ ì „ì†¡", variant="primary")
                clear_btn = gr.Button("ëŒ€í™” ì´ˆê¸°í™”")
        with gr.Column(scale=2):
            hitl_panel = gr.Group(visible=False)
            with hitl_panel:
                gr.Markdown("### ğŸ”” ìŠ¹ì¸ í•„ìš” (HITL)")
                hitl_input = gr.Textbox(
                    label="ì‚¬ëŒì˜ ë‹µë³€(ìŠ¹ì¸/ì •ì •/ì¶”ê°€ì •ë³´)",
                    placeholder="ì—ì´ì „íŠ¸ì—ê²Œ ì „ë‹¬í•  ë‚´ìš©ì„ ì…ë ¥"
                )
                resume_btn = gr.Button("ì¬ê°œ (Resume)", variant="primary")

            # ìƒíƒœ ë³€ìˆ˜
            thread_id_state = gr.State(value=None)  # str | None
            pending_query_state = gr.State(value=None)  # str | None

            done_panel = gr.Group(visible=True)
            with done_panel:
                gr.Markdown("âœ… **ëŒ€ê¸° ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤.** ì¼ë°˜ ëŒ€í™”ë¥¼ ê³„ì†í•´ë„ ë©ë‹ˆë‹¤.")

    # ë°”ì¸ë”©
    user_input.submit(
        fn=chat_fn,
        inputs=[user_input, thread_id_state, chat],
        outputs=[chat, thread_id_state, pending_query_state, hitl_panel, done_panel],
    )
    user_input.submit(lambda: "", None, user_input)

    send_btn.click(
        fn=chat_fn,
        inputs=[user_input, thread_id_state, chat],
        outputs=[chat, thread_id_state, pending_query_state, hitl_panel, done_panel],
    )
    send_btn.click(lambda: "", None, user_input)

    resume_btn.click(
        fn=resume_with_human_input,
        inputs=[hitl_input, thread_id_state, pending_query_state, chat],
        outputs=[chat, thread_id_state, pending_query_state, hitl_panel, done_panel],
    )

    clear_btn.click(
        fn=clear_all,
        inputs=None,
        outputs=[chat, thread_id_state, pending_query_state, hitl_panel, done_panel],
    )

demo.launch(debug=True)

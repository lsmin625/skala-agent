import uuid
from typing import Annotated, Optional
from typing_extensions import TypedDict

import gradio as gr
from dotenv import load_dotenv

# âœ… ìµœì‹  ê²½ë¡œë¡œ êµì²´
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_teddynote.tools import GoogleNews

from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.types import Command, interrupt
from langgraph.checkpoint.memory import InMemorySaver

load_dotenv()
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

google_news = GoogleNews()

@tool
def news_search(query: str) -> str:
    """Search news articles by keyword."""
    print(f"[Tool] news_search í˜¸ì¶œ: {query}")
    results = google_news.search_by_keyword(query, k=5)
    text = "\n".join(
        f"- {r.get('content','(ë‚´ìš©ì—†ìŒ)')} | {r.get('url','')}" for r in results
    ) or "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
    return text

@tool
def human_assistance(query: str) -> str:
    """Request assistance from human."""
    human_response = interrupt({"query": query})
    return human_response["data"]

tools = [news_search, human_assistance]
llm_with_tools = llm.bind_tools(tools)

# âœ… LangGraphì˜ ë©”ì‹œì§€ ëˆ„ì ì„ ìœ„í•´ add_messages ì‚¬ìš©
class State(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]
    thread_id: Annotated[Optional[str], "ëŒ€í™” ìŠ¤ë ˆë“œ ID"]
    interrupted: Annotated[bool, "HITLë¡œ ì¸í•´ ì¤‘ë‹¨ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€"]

def chatbot(state: State):
    """LLM í˜¸ì¶œ ë…¸ë“œ (íˆ´ ì½œ í¬í•¨)."""
    messages = state.get("messages", [])
    if not messages:
        return {"messages": []}
    response = llm_with_tools.invoke(messages)
    # ë‹¤ì¤‘ íˆ´ì½œì„ í—ˆìš©í•˜ë ¤ë©´ ì´ assert ì œê±° ê°€ëŠ¥
    if hasattr(response, "tool_calls"):
        assert len(response.tool_calls) <= 1, "ì—¬ëŸ¬ ê°œì˜ íˆ´ì½œì€ ì´ ë°ëª¨ì—ì„œ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    return {"messages": [response]}

graph_builder = StateGraph(State)
graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=tools)
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges("chatbot", tools_condition)
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")

memory = InMemorySaver()
graph = graph_builder.compile(checkpointer=memory)

def ensure_thread_id(thread_id: Optional[str]) -> str:
    """thread_idê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±."""
    return thread_id or str(uuid.uuid4())

def last_ai_text_from_state_output(state_output: dict) -> str:
    msgs = state_output.get("messages", [])
    last_ai_content = None
    for m in reversed(msgs):
        if isinstance(m, AIMessage) or getattr(m, "type", "") == "ai":
            last_ai_content = getattr(m, "content", None)
            break
        if isinstance(m, dict) and m.get("type") == "ai":
            last_ai_content = m.get("content")
            break
    return last_ai_content or ""

def play_chat(user_text: str, state: dict):
    state["thread_id"] = ensure_thread_id(state.get("thread_id"))
    messages = state.get("messages", [])
    chat_history = []

    if not messages:
        persona = (
            "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³ , "
            "ì‚¬ëŒì—ê²Œ 'ì „ì²´ ëª©ë¡ ìš”ì•½', 'íŠ¹ì • ê¸°ì‚¬ ìš”ì•½' ë“±ì˜ ì¶”ê°€ ì‘ì—…ì„ ìš”ì²­(human_assistance)í•©ë‹ˆë‹¤."
        )
        messages.append(SystemMessage(content=persona))
    else:
        for m in messages:
            role = "user" if isinstance(m, HumanMessage) else "assistant"
            chat_history.append({"role": role, "content": getattr(m, "content", "")})

    # âœ… ì‚¬ìš©ì ì…ë ¥ë§Œ ì¶”ê°€
    messages.append(HumanMessage(content=user_text))
    chat_history.append({"role": "user", "content": user_text})

    config = {"configurable": {"thread_id": state["thread_id"]}}
    out = graph.invoke({"messages": messages}, config=config)
    state["messages"] = out.get("messages", messages)

    ai_text = last_ai_text_from_state_output(out)

    # âœ… ì¤‘ë‹¨ ì—¬ë¶€(íˆ´ì½œ ì¡´ì¬)ë¡œ íŒ¨ë„ í† ê¸€
    last_msg = state["messages"][-1] if state["messages"] else None
    has_tool_call = bool(getattr(last_msg, "tool_calls", None))

    if ai_text and not has_tool_call:
        chat_history.append({"role": "assistant", "content": ai_text})
        return chat_history, state, gr.update(visible=False), gr.update(visible=True)
    else:
        # ì¤‘ë‹¨ë˜ì—ˆê±°ë‚˜(íˆ´ì½œ ëŒ€ê¸°) ai_textê°€ ì—†ìœ¼ë©´ HITL íŒ¨ë„ ì˜¤í”ˆ
        if ai_text:
            chat_history.append({"role": "assistant", "content": ai_text})
        else:
            chat_history.append({"role": "assistant", "content": "(HITL ì‘ë‹µ ëŒ€ê¸° ì¤‘)"})
        return chat_history, state, gr.update(visible=True), gr.update(visible=False)

def resume_chat(user_text: str, state: dict):
    """ì¬ê°œ(Command.resume): ì‚¬ëŒì˜ ì…ë ¥ì„ resume payloadë¡œ ì „ë‹¬."""
    state["thread_id"] = ensure_thread_id(state.get("thread_id"))

    # âœ… ê¸°ì¡´ messagesë¥¼ ê±´ë“œë¦¬ì§€ ì•ŠëŠ”ë‹¤ (HumanMessage ì¶”ê°€ ê¸ˆì§€)
    messages = state.get("messages", [])
    chat_history = []
    for m in messages:
        role = "user" if isinstance(m, HumanMessage) else "assistant"
        chat_history.append({"role": role, "content": getattr(m, "content", "")})

    # UXìš© ë¡œê·¸ë§Œ ì¶”ê°€(ì±„íŒ…ì°½ì—ë§Œ ë³´ì„), ì‹¤ì œ messagesì—ëŠ” ì¶”ê°€í•˜ì§€ ì•ŠìŒ
    chat_history.append({"role": "user", "content": f"[HITL ìŠ¹ì¸] {user_text}"})

    config = {"configurable": {"thread_id": state["thread_id"]}}

    # âœ… input=None, command=resume ë¡œë§Œ í˜¸ì¶œ
    resume_command = Command(resume={"data": user_text})
    out = graph.invoke(
        None,
        config=config,
        command=resume_command,
    )

    # âœ… ì¬ê°œ í›„ state ê°±ì‹ 
    state["messages"] = out.get("messages", messages)

    ai_text = last_ai_text_from_state_output(out) or "(ì¬ê°œ í›„ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤)"
    chat_history.append({"role": "assistant", "content": ai_text})

    # ì¬ê°œ ì™„ë£Œ â†’ HITL íŒ¨ë„ ë‹«ê¸°
    return chat_history, state, gr.update(visible=False), gr.update(visible=True)

def init_state():
    thread_id = str(uuid.uuid4())
    return {"messages": [], "interrupted": False, "thread_id": thread_id}

with gr.Blocks(title="LangGraph HITL Demo") as demo:
    gr.Markdown("## LangGraph Human-in-the-Loop")
    gr.Markdown(
        "- **ë©”ì‹œì§€ ì „ì†¡**ìœ¼ë¡œ ì—ì´ì „íŠ¸ì™€ ëŒ€í™”í•©ë‹ˆë‹¤.\n"
        "- ì—ì´ì „íŠ¸ê°€ ì‚¬ëŒ ë„ì›€(`human_assistance`)ì„ ìš”ì²­í•˜ë©´ **ì¼ì‹œì¤‘ì§€**ë˜ê³ , "
        "**ìŠ¹ì¸ ì…ë ¥** í›„ **ì¬ê°œ(Resume)** ë²„íŠ¼ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤."
    )

    with gr.Row():
        with gr.Column(scale=3):
            chatbot_ui = gr.Chatbot(label="ëŒ€í™”", height=420, type="messages")
            user_input = gr.Textbox(label="ë©”ì‹œì§€ ì…ë ¥", placeholder="ì˜ˆ) ìµœì‹  AI ë‰´ìŠ¤ ê²€ìƒ‰ í•´ì¤˜")
        with gr.Column(scale=2):
            hitl_panel = gr.Group(visible=False)
            with hitl_panel:
                gr.Markdown("### ğŸ”” ìŠ¹ì¸ í•„ìš” (HITL)")
                hitl_input = gr.Textbox(
                    label="ì‚¬ëŒì˜ ë‹µë³€(ìŠ¹ì¸/ì •ì •/ì¶”ê°€ì •ë³´)",
                    placeholder="ì—ì´ì „íŠ¸ì—ê²Œ ì „ë‹¬í•  ë‚´ìš©ì„ ì…ë ¥"
                )
                resume_btn = gr.Button("ì¬ê°œ (Resume)", variant="primary")
            done_panel = gr.Group(visible=True)
            with done_panel:
                gr.Markdown("### âœ… ì¼ë°˜ ëŒ€í™” ì§„í–‰ì¤‘")

    state = gr.State(init_state())
    user_input.submit(
        fn=play_chat,
        inputs=[user_input, state],
        outputs=[chatbot_ui, state, hitl_panel, done_panel],
    )
    user_input.submit(lambda: "", None, user_input)

    resume_btn.click(
        fn=resume_chat,
        inputs=[hitl_input, state],
        outputs=[chatbot_ui, state, hitl_panel, done_panel],
    )

demo.launch(debug=True)

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì˜¬ë“œí•œ ëª¨ë¦¬ ì½”ê³ ë¡œ íƒì •ê³¼ ëŒ€í™”í•˜ê¸° (LCEL)\n",
    "\n",
    "ì²´ì¸ íŒŒì´í”„ë¼ì¸(LCEL)ì„ ì‚¬ìš©."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI LLM ì¤€ë¹„ ë° í€´ì¦ˆ íŒŒì¼ ì§€ì •\n",
    "* í™˜ê²½ ë³€ìˆ˜(`.env` íŒŒì¼)ì—ì„œ API Key ë¡œë”©\n",
    "* ê°œë°œ í™˜ê²½ì—ì„œëŠ” `gpt-4o-mini` ë˜ëŠ” `gpt-3.5-turbo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import random\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‹œìŠ¤í…œ ë©”ì‹œì§€ (í˜ë¥´ì†Œë‚˜) ì§€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. ëª¨ë¦¬ ì½”ê³ ë¡œ í˜ë¥´ì†Œë‚˜ ì •ì˜\n",
    "persona = \"\"\"\n",
    "ë‹¹ì‹ ì€ ì• ë‹ˆë©”ì´ì…˜ 'ëª…íƒì • ì½”ë‚œ'ì˜ ë“±ì¥ì¸ë¬¼ 'ëª¨ë¦¬ ì½”ê³ ë¡œ'ì…ë‹ˆë‹¤. \n",
    "ë‹¹ì‹ ì€ ìì¹­ ëª…íƒì •ì´ë©°, ê²‰ìœ¼ë¡œëŠ” í—ˆì„¸ì™€ ìì‹ ê°ì´ ë„˜ì¹˜ì§€ë§Œ ì‚¬ì‹¤ì€ í—ˆë‹¹ì— ê°€ê¹Œìš´ ë©´ëª¨ë„ ìˆëŠ” ì¸ë¬¼ì…ë‹ˆë‹¤. \n",
    "ì—¬ì„±ì—ê²Œ ì•½í•˜ê³ , ìˆ ê³¼ ë„ë°•ì„ ì¦ê¸°ë©°, í‰ì†Œì—ëŠ” ê²Œìœ¼ë¥´ì§€ë§Œ ê°€ì¡±ì´ ìœ„í—˜ì— ì²˜í•˜ë©´ ëˆ„êµ¬ë³´ë‹¤ ì§„ì‹¬ ì–´ë¦° ëª¨ìŠµì„ ë³´ì…ë‹ˆë‹¤. \n",
    "ë‹¹ì‹ ì€ ê²½ì°° ì¶œì‹ ìœ¼ë¡œ ìœ ë„ì™€ ì‚¬ê²© ì‹¤ë ¥ì´ ë›°ì–´ë‚˜ë©°, ê³¼ê±°ì˜ ëª…ì„±ì„ ì€ê·¼íˆ ìë‘í•˜ê³¤ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë§íˆ¬ëŠ” ë‹¤ì†Œ ê±°ì¹ ê³  ì§ì„¤ì ì´ë©°, ìì‹ ê° ë„˜ì¹˜ëŠ” í‘œí˜„ì„ ìì£¼ ì‚¬ìš©í•©ë‹ˆë‹¤. \n",
    "ì˜ˆë¥¼ ë“¤ì–´, \"ì´ ëª¸ì´ ë°”ë¡œ ëª…íƒì • ëª¨ë¦¬ ì½”ê³ ë¡œë‹¤!\", \"í â€¦ ì´ê±´ ë¶„ëª…íˆ ë²”ì¸ì˜ ì†Œí–‰ì´êµ°!\", \"í•«í•«í•˜, ê·¸ëŸ° ê±´ ë‚´ê²Œ ë§¡ê¸°ë¼ê³ !\" ì™€ ê°™ì€ ë§ì„ ì¦ê²¨ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "ì¶”ë¦¬ ìƒí™©ì—ì„œëŠ” ì§„ì§€í•˜ë©´ì„œë„ ê³¼ì¥ëœ í‘œí˜„ì„ ì¦ê¹ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¹ì‹ ì€ ì§€ê¸ˆë¶€í„° ì–´ë–¤ ì§ˆë¬¸ì—ë„ ëª¨ë¦¬ ì½”ê³ ë¡œë‹µê²Œ ë‹µë³€í•´ì•¼ í•˜ë©°, ì§ˆë¬¸ìì—ê²Œ ë‹¹ì‹ ì´ ì§„ì§œ ëª…íƒì •ì´ë¼ëŠ” ì¸ìƒì„ ì£¼ê¸° ìœ„í•´ ë…¸ë ¥í•©ë‹ˆë‹¤. \n",
    "ê°€ë” \"ê·¸ ê¼¬ë§¹ì´ëŠ” ë˜ ì–´ë””ì„œ ë­˜ í•˜ê³  ìˆëŠ” ê±°ì•¼?\"ë¼ë©° ì½”ë‚œì—ê²Œ ì–„ë°‰ê²Œ íˆ´íˆ´ëŒ€ëŠ” ë“¯í•œ ë©˜íŠ¸ë„ í—ˆìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¹ì‹ ì€ ì§€ê¸ˆë¶€í„° 'ëª¨ë¦¬ ì½”ê³ ë¡œ' ê·¸ ìì²´ì…ë‹ˆë‹¤. ë‹µë³€ì˜ ì£¼ìš”í•œ ë‹¨ì–´ ë’¤ì—ëŠ” ì ì ˆí•œ ìœ ë‹ˆì½”ë“œ ì´ëª¨ì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", persona),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UI ì¸í„°í˜ì´ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mori_fillers = [\n",
    "    \"ğŸ˜ ê·¸ê±´ ë§ì´ì§€... ë‚˜ ëª¨ë¦¬ ì½”ê³ ë¡œê°€ ë³´ê¸°ì—” ë§ì´ì•¼. ğŸ·\",\n",
    "    \"ğŸ§ í â€¦ ì˜ ë“¤ì–´ë´. ì¤‘ìš”í•œ ê±´ ë§ì´ì§€â€¦ ğŸ”\",\n",
    "    \"ğŸ˜ ì—í—´, ê·¸ëŸ¬ë‹ˆê¹Œ ë§ì´ì§€â€¦ ì´ê±´ ì¢€ ìˆ˜ìƒí•˜ë‹¨ ë§ì´ì•¼. ğŸ’­\",\n",
    "    \"ğŸ’¼ ê·¸ì•¼ ë‹¹ì—°í•˜ì§€! í•˜ì§€ë§Œ ë§ì´ì•¼, ì§„ì‹¤ì€ í•­ìƒ í•˜ë‚˜ê±°ë“ . ğŸ¯\",\n",
    "    \"ğŸ•µï¸â€â™‚ï¸ í›„í›„, ì´ì œì•¼ ê°ì´ ì˜¤ëŠ”êµ°. ê·¸ê±´ ë§ì´ì•¼â€¦ ğŸ’¡\"\n",
    "]\n",
    "\n",
    "def play_caht(message, history):\n",
    "    history.append({\"role\": \"user\", \"content\": message})\n",
    "    history.append({\"role\": \"assistant\", \"content\": random.choice(mori_fillers)})\n",
    "    yield history\n",
    "\n",
    "    chain_response = chain.invoke({\"question\": message})\n",
    "    history[-1][\"content\"] = chain_response\n",
    "    yield history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UI ì±„íŒ… í™”ë©´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio UI ë ˆì´ì•„ì›ƒ\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"## ëª…íƒì • ëª¨ë¦¬ ì½”ê³ ë¡œ ğŸ•µï¸â€â™‚ï¸\")\n",
    "    gr.Markdown(\"ì´ ëª¸ì´ ë°”ë¡œ ì ìëŠ” ì½”ê³ ë¡œ, ëª…íƒì • ëª¨ë¦¬ ì½”ê³ ë¡œë‹¤! ë¬´ìŠ¨ ì‚¬ê±´ì´ë“  ë¬¼ì–´ë³´ë¼ê³ . í•«í•«í•˜!\")\n",
    "\n",
    "    chatbot = gr.Chatbot(label=\"ëŒ€í™”ì°½\", height=300, type=\"messages\")\n",
    "    user_input = gr.Textbox(placeholder=\"ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ë¼êµ¬...ìŒí•«í•«í•«!\", show_label=False)\n",
    "\n",
    "    # ì…ë ¥ ì˜ˆì‹œë¥¼ examplesë¡œ ì„¤ì •\n",
    "    gr.Examples(\n",
    "        examples=[[\"ëª¨ë¦¬ ì•„ì €ì”¨, ë‹¹ì‹ ë„ ëª…íƒì •ì¸ê°€ìš”?\"], [\"ìµœê·¼ì— í•´ê²°í•œ ì‚¬ê±´ì— ëŒ€í•´ ë§í•´ ì£¼ì„¸ìš”.\"], [\"ì½”ë‚œì€ ì–´ë””ì— ìˆì–´ìš”?\"]],\n",
    "        inputs=user_input,\n",
    "        cache_examples=False\n",
    "    )\n",
    "\n",
    "    user_input.submit(\n",
    "        fn=play_caht,\n",
    "        inputs=[user_input, chatbot],\n",
    "        outputs=[chatbot]\n",
    "    )\n",
    "\n",
    "    user_input.submit(lambda: \"\", None, user_input)\n",
    "\n",
    "# ì›¹ ì„œë²„ ì‹¤í–‰\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toolì„ ì‚¬ìš©í•˜ëŠ” ì±—ë´‡ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI LLM ì¤€ë¹„\n",
    "* í™˜ê²½ ë³€ìˆ˜(`.env` íŒŒì¼)ì—ì„œ API Key ë¡œë”©\n",
    "* ê°œë°œ í™˜ê²½ì—ì„œëŠ” `gpt-4o-mini` ë˜ëŠ” `gpt-3.5-turbo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ ë° API í‚¤ í™•ì¸\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI LLM ì¤€ë¹„\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ë‹¨ê³„ - ë„êµ¬ êµ¬ì„±\n",
    "@tool\n",
    "def tranquilizer_watch(target: str) -> str:\n",
    "    \"\"\"ë§ˆì·¨ ì‹œê³„: ì§€ì •ëœ ëŒ€ìƒì„ ì ì¬ìš¸ í•„ìš”ê°€ ìˆì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì¶”ë¦¬ ì„¤ëª… ë“±ì„ ëŒ€ì‹ í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "    Args:\n",
    "        target (str): ë§ˆì·¨ì‹œí‚¬ ëŒ€ìƒì˜ ì´ë¦„ì´ë‚˜ ì¸ìƒì°©ì˜. ì˜ˆ: 'ì•ˆê²½ ì“´ ë²”ì¸', 'ìœ ëª…í•œ íƒì •ë‹˜'\n",
    "    \"\"\"\n",
    "    return f\"âŒš ë§ˆì·¨ ì‹œê³„: '{target}'ì„(ë¥¼) ì„±ê³µì ìœ¼ë¡œ ë§ˆì·¨ì‹œì¼°ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def voice_changer_bowtie(target: str) -> str:\n",
    "    \"\"\"ìŒì„± ë³€ì¡° ë‚˜ë¹„ë„¥íƒ€ì´: ë‹¤ë¥¸ ì‚¬ëŒì˜ ëª©ì†Œë¦¬ë¡œ ì¶”ë¦¬ë¥¼ ì„¤ëª…í•˜ê±°ë‚˜, ë‹¤ë¥¸ ì‚¬ëŒì¸ ì²™ ì—°ê¸°í•´ì•¼ í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    Args:\n",
    "        target (str): ëª©ì†Œë¦¬ë¥¼ í‰ë‚´ ë‚¼ ëŒ€ìƒ. ì˜ˆ: 'ë¸Œë¼ìš´ ë°•ì‚¬ë‹˜', 'ìœ ëª…í•œ íƒì •ë‹˜'\n",
    "    \"\"\"\n",
    "    return f\"ğŸ¤ ìŒì„± ë³€ì¡° ë‚˜ë¹„ë„¥íƒ€ì´: '{target}'ì˜ ëª©ì†Œë¦¬ë¡œ ë³€ì¡°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def detective_glasses(target: str) -> str:\n",
    "    \"\"\"íƒì • ì•ˆê²½: íŠ¹ì • ëŒ€ìƒì„ ì¶”ì í•˜ê±°ë‚˜ ë©€ë¦¬ ìˆëŠ” ê²ƒì„ í™•ëŒ€í•´ì„œ ë³¼ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ë²”ì¸ ì¶”ì ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤.\n",
    "    Args:\n",
    "        target (str): ì¶”ì í•˜ê±°ë‚˜ í™•ëŒ€í•  ëŒ€ìƒ. ì˜ˆ: 'ë²”ì¸ì˜ ìë™ì°¨', 'ë¨¼ ê³³ì˜ ë‹¨ì„œ'\n",
    "    \"\"\"\n",
    "    return f\"ğŸ•¶ï¸ íƒì • ì•ˆê²½: '{target}'ì— ëŒ€í•œ ì¶”ì  ë° í™•ëŒ€ ê¸°ëŠ¥ì„ í™œì„±í™”í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def soccer_shoes(target: str) -> str:\n",
    "    \"\"\"í‚¥ë ¥ ê°•í™” ì¶•êµ¬í™”: ê°•ë ¥í•œ í˜ìœ¼ë¡œ ë¬´ì–¸ê°€ë¥¼ ê±·ì–´ì°¨ ë²”ì¸ì„ ì œì••í•˜ê±°ë‚˜ ìœ„ê¸° ìƒí™©ì„ íƒˆì¶œí•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    Args:\n",
    "        target (str): ê°•í•˜ê²Œ ì°° ëŒ€ìƒ. ì˜ˆ: 'ë²”ì¸ì„ ìœ„í˜‘í•  ëŒë©©ì´', 'ë§‰ë‹¤ë¥¸ ê¸¸ì˜ ë¬¸'\n",
    "    \"\"\"\n",
    "    return f\"âš½ í‚¥ë ¥ ê°•í™” ì¶•êµ¬í™”: '{target}'ì„(ë¥¼) í–¥í•´ ê°•ë ¥í•œ í‚¥ì„ ì¤€ë¹„í•©ë‹ˆë‹¤!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë„êµ¬ ëª©ë¡ ì •ë¦¬\n",
    "tools = [tranquilizer_watch, voice_changer_bowtie, detective_glasses, soccer_shoes]\n",
    "\n",
    "# ë„êµ¬ ëª©ë¡ì„ LLMì— ì—°ê²°\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, AIMessage, ToolMessage\n",
    "\n",
    "class AgentState(TypedDict, total=False):\n",
    "    messages: Annotated[list, \"LLM ë©”ì‹œì§€ ëª©ë¡\", add_messages]\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"ë‹¹ì‹ ì€ ëª…íƒì • ì½”ë‚œì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ìƒí™©ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¹ì‹ ì´ ê°€ì§„ ë„êµ¬ë“¤ì„ ì ì ˆí•˜ê²Œ ì‚¬ìš©í•˜ì„¸ìš”. ìƒí™©ì— ë”°ë¼ ì—¬ëŸ¬ ë„êµ¬ë¥¼ ë™ì‹œì— ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\"\"\"\n",
    "def ensure_system_once(msgs: list[BaseMessage]) -> list[BaseMessage]:\n",
    "    \"\"\"SystemMessageê°€ ê³„ì† ëˆ„ì ë˜ëŠ” ê²ƒì„ ë°©ì§€\"\"\"\n",
    "    if not msgs or not isinstance(msgs[0], SystemMessage):\n",
    "        return [SystemMessage(content=SYSTEM_PROMPT)] + msgs\n",
    "    return msgs\n",
    "\n",
    "def agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"LLMì— ìƒíƒœì˜ ë©”ì‹œì§€ë“¤ì„ ì „ë‹¬í•˜ê³  ì‘ë‹µì„ ë°›ì•„ ìƒíƒœì— ì¶”ê°€\"\"\"\n",
    "    messages = ensure_system_once(state.get(\"messages\", []))\n",
    "    ai = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [ai]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"agent\", agent_node)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "graph.add_edge(START, \"agent\")\n",
    "graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\": \"tools\",   # tool_calls ìˆìœ¼ë©´ ToolNodeë¡œ\n",
    "        \"__end__\": END,     # ì—†ìœ¼ë©´ ì¢…ë£Œ\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio UI êµ¬ì„±\n",
    "### Gradio ì²˜ë¦¬ í•¨ìˆ˜ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_chat(user_input: str) -> str:\n",
    "    \n",
    "    if not user_input:\n",
    "        return \"ìƒí™©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\"\n",
    "\n",
    "    result_state =  app.invoke({\"messages\": [HumanMessage(content=user_input)]})\n",
    "    messages = result_state[\"messages\"]\n",
    "    output = []\n",
    "    for i, msg in enumerate(messages):\n",
    "        if isinstance(msg, ToolMessage):\n",
    "            output.append(f\"(ë„êµ¬ ì‚¬ìš©) {msg.content}\")\n",
    "    return \"\\n\".join(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradio UI êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### ğŸ•µï¸ ëª…íƒì • ì½”ë‚œ ë„êµ¬ ì¶”ì²œê¸°\")\n",
    "    gr.Markdown(\"ìƒí™©ì„ ì…ë ¥í•˜ë©´ ì½”ë‚œì´ ìƒí™©ì— ì ì ˆí•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê²Œ ë©ë‹ˆë‹¤.\")\n",
    "\n",
    "    user_input = gr.Textbox(label=\"ìƒí™© ì„¤ëª…\", placeholder=\"ì˜ˆ: ëª¨ë¦¬ íƒì •ì„ ê¸°ì ˆì‹œí‚¤ê³ , ëª¨ë¦¬ íƒì • ëª©ì†Œë¦¬ë¡œ ì‚¬ê±´ì„ ì„¤ëª…í•˜ê³  ì‹¶ì–´ìš”\")\n",
    "    ai_output = gr.Textbox(label=\"ì¶”ì²œ ë„êµ¬\", lines=5)\n",
    "    user_input.submit(play_chat, inputs=user_input, outputs=ai_output)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain 프롬프트 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI LLM 준비 \n",
    "* 환경 변수(`.env` 파일)에서 API Key 로딩\n",
    "* 개발 환경에서는 `gpt-4o-mini` 또는 `gpt-3.5-turbo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "open_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"{open_api_key[:9]}***\")\n",
    "\n",
    "# OpenAI LLM 준비\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "print(llm.model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 역할 기반 메시지 구성\n",
    "\n",
    "Role 메시지는 BaseMessage가 부모 클래스\n",
    "\n",
    "| 역할 (Role)       | 클래스명                              | 설명                                              |\n",
    "| --------------- | --------------------------------- | ----------------------------------------------- |\n",
    "| system          | `SystemMessage`                   | 모델의 행동 지침이나 문맥을 설정하는 초기 메시지                     |\n",
    "| user            | `HumanMessage`                    | 사용자의 입력을 나타냄 (사람이 입력한 메시지)                      |\n",
    "| assistant       | `AIMessage`                       | LLM의 응답을 나타냄                                    |\n",
    "| function/tool   | `FunctionMessage` / `ToolMessage` | 도구 실행 결과나 함수 응답을 나타냄 (OpenAI tool 사용 시)         |\n",
    "| generic (역할 없음) | `ChatMessage`                     | 역할을 문자열로 직접 지정하여 유연하게 사용 (예: \"critic\", \"coach\") |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "question = \"코난이 작아진 이유가 뭐죠?\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"당신은 '명탐정 코난' 전문가입니다. 질문에 친절하고 정확하게 답해 주세요.\"),\n",
    "    HumanMessage(content=question)\n",
    "]\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ messages 출력에서 `additional_kwargs={}`의 의미\n",
    "kwargs는 Python에서 흔히 사용되는 약어로, \"keyword arguments\" (키워드 인자)를 의미 - 함수 정의 시 **kwargs는 이름이 지정된 임의의 개수의 인자를 딕셔너리 형태로 받겠다는 의미\n",
    "```python\n",
    "def example(**kwargs):\n",
    "    print(kwargs)\n",
    "\n",
    "example(name=\"코난\", age=7)\n",
    "# 출력: {'name': '코난', 'age': 7}\n",
    "```\n",
    "\n",
    "LangChain 또는 OpenAI SDK 등에서 additional_kwargs는 기본 구조에 포함되지 않는 키-값 데이터를 임시 저장할 수 있는 확장용 필드\n",
    "```python\n",
    "message = HumanMessage(\n",
    "    content=\"코난이 작아진 이유가 뭐죠?\",\n",
    "    additional_kwargs={\"example_id\": \"Q1\", \"topic\": \"약물\"}\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM으로 역할 기반 메시지 주고 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(messages)\n",
    "\n",
    "# 응답 출력\n",
    "print(f\"AI 응답: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프롬프트(`ChatPromptTemplate`) 활용 메시지 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 '명탐정 코난' 전문가입니다. 질문에 친절하고 정확하게 답해 주세요.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question = \"블랙 조직의 리더는 누구인가요?\"\n",
    "prompt_messages = prompt.format_messages(question=question)\n",
    "\n",
    "print(prompt_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM으로 프롬프트 메시지 주고 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(prompt_messages)\n",
    "\n",
    "# 응답 출력\n",
    "print(f\"AI 응답: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
